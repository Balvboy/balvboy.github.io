[{"content":"Redis的线程 从接触到Redis开始，就了解到Redis的一个重要特性就是单线程。 带着这个特性，我通过命令top -H -p 2582查看了Redis Server内部开启的线程，发现Redis中并非只有1个线程，而是有4个。 这里面肯定有一主线程是负责Redis的操作的，那剩下的3个线程是负责什么的呢。\n我们在Redis的源码中寻找一下答案\nRedis源码分析 1.main方法 server.supervised = redisIsSupervised(server.supervised_mode); int background = server.daemonize \u0026amp;\u0026amp; !server.supervised; //判断Redis的启动模式 if (background) daemonize(); initServer(); //初始化server服务 if (background || server.pidfile) createPidFile(); redisSetProcTitle(argv[0]); redisAsciiArt(); checkTcpBacklogSettings(); 2.initServer函数 if (server.cluster_enabled) clusterInit(); replicationScriptCacheInit(); scriptingInit(1); slowlogInit(); latencyMonitorInit(); //初始化 background io bioInit(); server.initial_memory_usage = zmalloc_used_memory(); 这里我们主要关注bioInit(); 方法，bio这里就是background IO的简写\n3.BIO  /* Background I/O service for Redis. * * This file implements operations that we need to perform in the background. * Currently there is only a single operation, that is a background close(2) * system call. This is needed as when the process is the last owner of a * reference to a file closing it means unlinking it, and the deletion of the * file is slow, blocking the server. * * In the future we'll either continue implementing new things we need or * we'll switch to libeio. However there are probably long term uses for this * file as we may want to put here Redis specific background tasks (for instance * it is not impossible that we'll need a non blocking FLUSHDB/FLUSHALL * implementation). 从上面的描述可以看出BIO目前只包括一个操作，就是后台 close内核函数操作，因为这个操作牵扯到很重的文件IO，文件IO会严重阻塞redis-server，所以需要开辟线程来单独处理这些操作。\nvoid bioInit(void) { pthread_attr_t attr; pthread_t thread; size_t stacksize; int j; /* Initialization of state vars and objects */ for (j = 0; j \u0026lt; BIO_NUM_OPS; j++) { pthread_mutex_init(\u0026amp;bio_mutex[j],NULL); pthread_cond_init(\u0026amp;bio_newjob_cond[j],NULL); pthread_cond_init(\u0026amp;bio_step_cond[j],NULL); bio_jobs[j] = listCreate(); bio_pending[j] = 0; } /* Set the stack size as by default it may be small in some system */ pthread_attr_init(\u0026amp;attr); pthread_attr_getstacksize(\u0026amp;attr,\u0026amp;stacksize); if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */ while (stacksize \u0026lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2; pthread_attr_setstacksize(\u0026amp;attr, stacksize); /* Ready to spawn our threads. We use the single argument the thread * function accepts in order to pass the job ID the thread is * responsible of. */ for (j = 0; j \u0026lt; BIO_NUM_OPS; j++) { //循环创建bio线程  void *arg = (void*)(unsigned long) j; if (pthread_create(\u0026amp;thread,\u0026amp;attr,bioProcessBackgroundJobs,arg) != 0) { serverLog(LL_WARNING,\u0026#34;Fatal: Can\u0026#39;t initialize Background Jobs.\u0026#34;); exit(1); } bio_threads[j] = thread; } } 这个函数，从名字就可以看出它的主要功能是完成BIO的初始化操作，在源代码中我们找到了线程开辟操作，这里的思路是线程池，那么问题来了，BIO线程池中到底开辟几个线程呢？\n通过观察第121行，可以看到BIO_NUM_OPS参数影响了BIO线程池的线程量，那么这个数值到底为多少呢，我们稍微跟踪一下就可以获取：\n42 #define BIO_NUM_OPS 3 //bio.h文件 现在可以看出BIO_NUM_OPS默认数值为3，这个数值加上1个主线程，正好是图片中的4个线程。\n4. BIO线程执行的操作 while(1) { listNode *ln; /* The loop always starts with the lock hold. */ if (listLength(bio_jobs[type]) == 0) { pthread_cond_wait(\u0026amp;bio_newjob_cond[type],\u0026amp;bio_mutex[type]); continue; } /* Pop the job from the queue. */ ln = listFirst(bio_jobs[type]); //从任务队列中获取任务  job = ln-\u0026gt;value; /* It is now possible to unlock the background system as we know have * a stand alone job structure to process.*/ pthread_mutex_unlock(\u0026amp;bio_mutex[type]); /* Process the job accordingly to its type. */ if (type == BIO_CLOSE_FILE) { //文件关闭操作  close((long)job-\u0026gt;arg1); } else if (type == BIO_AOF_FSYNC) { //异步文件同步操作  redis_fsync((long)job-\u0026gt;arg1); } else if (type == BIO_LAZY_FREE) { //redis内存懒释放  /* What we free changes depending on what arguments are set: * arg1 -\u0026gt; free the object at pointer. * arg2 \u0026amp; arg3 -\u0026gt; free two dictionaries (a Redis DB). * only arg3 -\u0026gt; free the skiplist. */ if (job-\u0026gt;arg1) lazyfreeFreeObjectFromBioThread(job-\u0026gt;arg1); //懒释放对象  else if (job-\u0026gt;arg2 \u0026amp;\u0026amp; job-\u0026gt;arg3) lazyfreeFreeDatabaseFromBioThread(job-\u0026gt;arg2,job-\u0026gt;arg3);//懒释数据库  else if (job-\u0026gt;arg3) lazyfreeFreeSlotsMapFromBioThread(job-\u0026gt;arg3);//懒释放槽位型Map内存  } else { serverPanic(\u0026#34;Wrong job type in bioProcessBackgroundJobs().\u0026#34;); } zfree(job); 通过最初的现象，我们可以看出Redis-server开辟了四个线程，并通过源代码分析，我们可以看出后三个线程是BIO线程，这三个线程完成的功能是一样的，主要包括：从BIO任务队列中取出任务，文件描述符关闭、磁盘文件同步、内存对象懒释放操作。 其他的任务均由主线程完成。\nRedis单线程的优势 我们看到Redis在处理大多数命令的时候，是通过单线程来处理的这可能给Redis带来下面的优势\n 使用单线程模型也能并发的处理客户端的请求； 使用单线程模型能带来更好的可维护性，方便开发和调试； Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU；  单线程也能并发 这里首先要说一下一个老生常谈的问题，并发和并行的区别。 这里用一个例子来说明\n 例如，一个调酒师能够照顾几个顾客，而一次只能准备一种饮料。因此，他可以在没有并行的情况下提供并发。\n 所以说并发是，在一个时间段内能够处理多个请求即可，而并行是在同一个时刻能够处理多个请求。\n而Redis就可以理解为，上面的例子中提到的调酒师，Redis通过IO 多路复用技术就能够方便的实现同时照看成百上千个顾客,但是Redis在同一时刻只能处理一个顾客的请求。\n但是因为Redis几乎所有操作都是在内存中完成，所以他的每个操作的耗时都非常短，这里有一个计算机各个硬件执行时间的对比。 我们看到内存的读取访问时间是在纳秒级别，而到了硬盘就到了毫秒级。所以Redis这样的以内存操作为主的服务，能够达到每秒 10W甚至100W的并发都是有可能的(当然这个和很多情况有关，比如key的大小，命令的时间复杂度等等)。 同样在这种主要针对内存操作的情况下，Redis对于CPU的消耗是相对比较小的。所以CPU通常并不会成为Redis的瓶颈。\n It’s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU. FAQ\n 如果说你想更好的让Redis利用CPU，或者说Redis的并发量还不能满足你的要求，Redis给出的官方建议是，使用分片的方式将不同的请求交给不同的 Redis 服务器来处理，而不是在同一个 Redis 服务中引入大量的多线程操作。\n However, to maximize CPU usage you can start multiple instances of Redis in the same box and treat them as different servers. At some point a single box may not be enough anyway, so if you want to use multiple CPUs you can start thinking of some way to shard earlier. FAQ\n 可维护性 可维护性对于一个项目来说非常重要，如果代码难以调试和测试，问题也经常难以复现，这对于任何一个项目来说都会严重地影响项目的可维护性。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，代码的执行过程不再是串行的，多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。\n性能瓶颈 上面也提到了，CPU一般不会成为Redis的瓶颈，Redis 并不是 CPU 密集型的服务，如果不开启 AOF 备份，所有 Redis 的操作都会在内存中完成不会涉及任何的 I/O 操作，这些数据的读写由于只发生在内存中，所以处理速度是非常快的；整个服务的瓶颈在于网络传输带来的延迟和等待客户端的数据传输，也就是网络 I/O，所以使用多线程模型处理全部的外部请求可能不是一个好的方案。\n AOF 是 Redis 的一种持久化机制，它会在每次收到来自客户端的写请求时，将其记录到日志中，每次 Redis 服务器启动时都会重放 AOF 日志构建原始的数据集，保证数据的持久性。\n 多线程虽然会帮助我们更充分地利用 CPU 资源，但是操作系统上线程的切换也不是免费的，线程切换其实会带来额外的开销，其中包括：\n 保存线程 1 的执行上下文； 加载线程 2 的执行上下文；  频繁的对线程的上下文进行切换可能还会导致性能地急剧下降，这可能会导致我们不仅没有提升请求处理的平均速度，反而进行了负优化，所以这也是为什么 Redis 对于使用多线程技术非常谨慎。\n引入多线程  However with Redis 4.0 we started to make Redis more threaded. For now this is limited to deleting objects in the background, and to blocking commands implemented via Redis modules. For the next releases, the plan is to make Redis more and more threaded.\n 从4.0版本开始，Redis加入了一些可以被其他线程异步处理的删除操作。\n删除操作 我们可以在 Redis 在中使用 DEL 命令来删除一个键对应的值，如果待删除的键值对占用了较小的内存空间，那么哪怕是同步地删除这些键值对也不会消耗太多的时间。\n但是对于 Redis 中的一些超大键值对，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，影响 Redis 服务处理请求的 PCT99 和可用性。\n总结 Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；（因为单线程的Redis已经这么快了，而且瓶颈不在CPU，并且开发起来更简单，所以顺理成章的使用了单线程） 而 Redis 引入多线程操作也是出于性能上的考虑(目前只是针对一些大键的删除)，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。\n参考 [Redis-Server 线程模型源码剖析]\n[为什么Redis使用单线程模型]\n[Redis is single-threaded, then how does it do concurrent I/O?]\n[为什么说Redis是单线程的以及Redis为什么这么快！]\n","permalink":"https://balvboy.github.io/blog/redis/","summary":"Redis的线程 从接触到Redis开始，就了解到Redis的一个重要特性就是单线程。 带着这个特性，我通过命令top -H -p 2582查看了Redis Server内部开启的线程，发现Redis中并非只有1个线程，而是有4个。 这里面肯定有一主线程是负责Redis的操作的，那剩下的3个线程是负责什么的呢。\n我们在Redis的源码中寻找一下答案\nRedis源码分析 1.main方法 server.supervised = redisIsSupervised(server.supervised_mode); int background = server.daemonize \u0026amp;\u0026amp; !server.supervised; //判断Redis的启动模式 if (background) daemonize(); initServer(); //初始化server服务 if (background || server.pidfile) createPidFile(); redisSetProcTitle(argv[0]); redisAsciiArt(); checkTcpBacklogSettings(); 2.initServer函数 if (server.cluster_enabled) clusterInit(); replicationScriptCacheInit(); scriptingInit(1); slowlogInit(); latencyMonitorInit(); //初始化 background io bioInit(); server.initial_memory_usage = zmalloc_used_memory(); 这里我们主要关注bioInit(); 方法，bio这里就是background IO的简写\n3.BIO  /* Background I/O service for Redis. * * This file implements operations that we need to perform in the background.","title":"Redis为何使用单线程 "},{"content":"什么是HTTPS HTTPS简单的说就是安全版的HTTP。 因为HTTP协议的数据都是明文进行传输的，所以对于一些敏感信息的传输就很不安全，为了安全传输敏感数据，网景公司设计了SSL（Secure Socket Layer），在HTTP的基础上添加了一个安全传输层，对所有的数据都加密后再进行传输，客户端和服务器端收到加密数据后按照之前约定好的秘钥解密。\nHTTPS是如何保证安全的 HTTPS的安全性是建立在密码学的基础之上的，有很多算法起到了至关重要的作用。\nHTTPS的交互过程 通过上面的描述，我们已经能大概知道HTTPS是使用加密算法在浏览器和服务器之前传递秘钥，然后再使用秘钥完成信息的加解密。所以这个秘钥是如何生成的，还有秘钥是如何在浏览器和服务器之间传递的就成了HTTPS的关键，下面我们来详细的了解一下这个过程。\n1.交互流程  Client Hello 客户端（通常是浏览器）先向服务器发出加密通信的请求,请求大概中包括下面内容  支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数 Random Number-RNc，稍后用于生成\u0026quot;对话密钥\u0026quot;。 支持的加解密方法，比如对称加密支持AES，秘钥交换算法支持RSA、DH，签名算法支持sha256等。(在更高版本的TLS协议中，交换的是密码学套件，所谓的套件就是一整套的加解密，秘钥交换方案)。 支持的压缩方法。   服务器收到请求,然后响应  确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数Random Number-RNs，稍后用于生成\u0026quot;对话密钥\u0026quot;。 确认使用的加密方法、秘钥交换算法、签名算法等等。 把服务器证书发送给客户端。 服务器要求验证客户端(浏览器)的证书(可选，大部分的服务器都不会要求)。   客户端收到服务器证书之后，会检查证书的有效性，如果服务器证书并不是经过CA机构认证的，浏览器就会在这个时候给用户提出警告。 客户端收到服务器验证客户端证书的请求，会将自己证书发送给服务器。客户端如果没有证书，则需要发送一个不包含证的证书消息。如果服务器需要客户端身份验证才能继续握手，则可能会使用致命的握手失败警报进行响应。(双向认证一般只存在于银行等一些安全性要求比较高的场景中，像早些时候我们使用的网银，里面存储的就是证书，用来在交易的时候和服务器端进行双向认证，保证安全) 服务器收到客户端证书，校验客户端证书是否有效 客户端把把上面流程中发送的所有消息(除了Client Hello)，使用客户端的私钥进行签名，然后发送给服务器。 服务器也保存着之前客户端发送的消息，然后用客户端发送过来的公钥，进行验签。 客户端生成一个Pre-Master-Secret随机数，然后使用服务器证书中的公钥加密，发送给服务器端。 服务器端收到Pre-Master-Secret的加密数据，因为是使用它的公钥加密的，所以可以使用私钥解密得到Pre-Master-Secret。 这时候客户端和服务端都同时知道了，RNc、RNs、Pre-Master-Secret这三个随机数，然后客户端和服务器端使用相同的PRF算法计算得到一个Master-Secret。然后可以从Master-Secret中再生成作为最终客户端和服务器端消息对称加密的秘钥，和对消息进行认证的MAC秘钥。  参考:TLS协议 TLS RFC\n2.Pre-Master-Secret Pre-Master-Secret前两个字节是TLS的版本号，这是一个比较重要的用来核对握手数据的版本号，因为在Client Hello阶段，客户端会发送一份加密套件列表和当前支持的SSL/TLS的版本号给服务端，而且是使用明文传送的，如果握手的数据包被破解之后，攻击者很有可能串改数据包，选择一个安全性较低的加密套件和版本给服务端，从而对数据进行破解。 所以，服务端需要对密文中解密出来对的Pre-Master-Secret中的版本号跟之前Client Hello阶段的版本号进行对比，如果版本号变低，则说明被篡改，则立即停止发送任何消息。\n参考：pre-master secret \n3.Master-Secret 客户端和服务端在生成Master-Secret的之后，会把Master-Secret作为PRF的参数，继续运算，最终得到下面6个秘钥，分别用于MAC算法和加解密算法。\n   秘钥名称 秘钥作用     client write MAC key 客户端对发送数据进行MAC计算使用的秘钥，服务端使用同样的秘钥确认数据的完整性   server write MAC key 服务端对返回数据进行MAC计算使用的秘钥，客户端使用同一个秘钥验证完整性   client write key 对称加密key，客户端数据加密，服务端解密   server write key 服务端加密，客户端解密   client write IV 初始化向量，运用于分组对称加密   server write IV 初始化向量，运用于分组对称加密    参考: TLS 中的密钥计算\n4.PRF算法 PRF表示（Pseudo-random Function）伪随机函数\nMaster-secret和最终的6个秘钥都是依靠PRF来生成的。\nPRF是利用hash函数来实现，然后依赖递归可以生成无限长度的序列。具体使用哪种hash算吗，在TLS1.2之后需要的密码学套件中指定。\n然后master-secret和6个秘钥只需要PRF生成满足他们所需要的长度即可。\n比如Master-Secret的长度一直都是48位。\n参考: TLS 中的密钥计算\n5.双向认证 其实我们日常访问的绝大多数网站，都是单向认证的(也就是说并没有上面流程中的3、4、5、6步骤)，这里为例展示HTTPS的完整交互流程，所以分析的是双向认证。 服务器可以选择是否要真正客户端的证书。这里以使用NGINX配置HTTPS为例。 如果我们在NGINX的HTTPS相关配置中添加了下面这个配置，就表示需要验证客户端的证书。\nssl_verify_client on; 6.密码学套件 密码学套件是TLS发展了一段时间积累了很多密码学使用的经验之后提出的一整套的解决方案。一个套件中包含了应用于整个握手和传输使用到的所有非对称加密，对称加密和哈希算法，甚至包括证书的类型。\n密码学套件是SSLv3开始提出的概念，从此，零散的密码学选择问题变成了一个整体的密码学套件选择的问题。后续的版本在升级的时候会产生新的安全强度更高的密码学套件，同时抛弃比较弱的密码学套件\n密码套件分为三大部分：密钥交换算法，数据加密算法，消息验证算法。\n下面来分析一个密码学套件的名称，来解释一下它包含的意思\nTLS_DHE_RSA_WITH_AES_256_CBC_SHA226\n WITH前面表示使用的非对称加密算法，WITH后面表示使用的对称加密和完整性校验算法   TLS:表示TLS协议，如果未来TLS改名，这个名字可能会变，否则会一直是这个名字 DHE_RSA:这里又两个算法，表示第一个是约定密钥交换的算法，第二个是约定证书的验证算法。如果只有一个，表示这两中操作都是用同一个算法。 AES_256_CBC:指的是AES这种对称加密算法的256位算法的CBC模式，AES本身是一类对称加密算法的统称，实际的使用时要指定位数和计算模式，CBC就是一种基于块的计算模式。 SHA:表示用来校验数据完整性生成MAC，使用的算法，在TLS1.2之后也表示PRF算法使用的算法。  除了这种比较好理解的密码学套件，还有见到一些比较奇怪的，比如 ALL:!EXPORT:!LOW:!aNULL:!SSLv2 我来解释一下，上面出现的字段，更为详细的大家可以去查看下面的文章。\n ALL:表示所有除了明文(eNULL)传递意外的密码学套件 !EXPORT:EXPORT表示有出口限制的密码学算法，前面加上!,就表示排除掉包含这些算法的密码学套件。 !LOW:表示排除掉标记为密码强度比较低的算法。 !aNULL:表示排除不提供身份验证算法的套件。 !SSLv2:表示排除所有SSLv2的套件。  大家可以使用openssl ciphers xxx命令查看套件表达式，所包含的密码学套件\n参考: 密码学套件 密码学套件表达式\nHTTPS中的算法 除了了解HTTPS的交互流程，HTTPS中使用的算法及算法的作用，也是我们必须要了解的一部分。 下面会按照算法的作用进行分类，并简单的介绍其中比较常见算法的作用，单并不会对算法的原理做过多的说明(主要是我也弄不明白)，会把相关的讲解原理的文章链接提供出来，大家有兴趣的可以自行去了解。\nHTTPS中算法，根据算法的用途可以分为几大类\n 加密算法 - 加密传递的信息，包括对称加密和非对称加密 秘钥传递算法 - 在客户端和服务器端传递加密使用的key，当然通过上面的流程我们知道并不是直接传递加密的key 信息摘要/签名算法 - 对传递的信息摘要，确保信息在传递过程中不会被篡改  1.加密算法 加密算法基本可以分为两种 对称加密和非对称加密\n对称加密 顾名思义就是加密和解密都是用一个同样的秘钥，它的优点就行加解密的速度很快，缺点就是尤其需要注意秘钥的传输，不能泄露。 包含的算法有 AES DES RC4等，常用的是AES\n非对称加密-RSA 非对称加密有一对秘钥公钥和私钥。使用公钥加密，然后使用私钥解密。公钥可以公开的发送给任何人。使用公钥加密的内容，只有私钥可以解开。安全性比对称加密大大提高。缺点是和对称加密相比速度较慢，加解密耗费的计算资源较多。\n这里我们先只需要了解RSA之所以安全的原因是，大整数的因数分解，是一件非常困难的事情。目前，除了暴力破解，还没有发现别的有效方法。\n所以这个大整数越大，RSA被破解的难度也就越高。\n具体的算法可以了解下面的两篇文章。\nRSA算法原理1 RSA算法原理2\n2.秘钥交换算法 常见的秘钥交换算法有下面几种：\n  RSA：算法实现简单，诞生于 1977 年，历史悠久，经过了长时间的破解测试，安全性高。缺点就是需要比较大的素数（目前常用的是 2048 位）来保证安全强度，很消耗 CPU 运算资源。RSA 是目前唯一一个既能用于密钥交换又能用于证书签名的算法。\n  DH：diffie-hellman 密钥交换算法，诞生时间比较早（1977 年），但是 1999 年才公开。缺点是比较消耗 CPU 性能。\n  ECDHE：使用椭圆曲线（ECC）的 DH 算法，优点是能用较小的素数（256 位）实现 RSA 相同的安全等级。缺点是算法实现复杂，用于密钥交换的历史不长，没有经过长时间的安全攻击测试。\n  ECDH：不支持 PFS，安全性低，同时无法实现 false start。\n  DHE：不支持 ECC。非常消耗 CPU 资源 。\n  因为这些算法都用到了数论的一些知识，我自己也是似懂非懂。但是他们有一个共同点就是都是运用了质数和模运算相关的数学原理和公式，感觉他们之间应该也是有一定的关联和关系。(后悔没有好好学数学呀)\n参考： RSA和DH算法 ECDHE-wiki DH-wiki Nginx SSL 性能优化\n3.摘要/签名算法 HTTPS中常见的有MD5、SHA256、MAC、HMAC等，下面主要说明一下这些算法的区别和联系。\n1. MD5 是一种消息摘要算法(Message-Digest Algorithm),一种被广泛使用的密码散列函数(Hash Function)，针对任意长度的输入，可以产生出一个定长128位（16字节）的散列值。\n2. SHA SHA表示安全哈希算法(Secure Hash Algorithm)，经过了很长时间的发展SHA算法已经发展成了一个拥有众多算法的SHA家族。常见的有SHA0、SHA1、SHA2(包含SHA224、SHA256等)、SHA3。0，1，2，3表示SHA算法大的版本，每个大版本中又根据输出字节长度的不同分为和不同的算法。比如SHA256 使用的是SHA2，输出的是256字节。更详细的大家可以看下面wiki百科中的内容，很详细。\nSHA称作安全哈希算法的原因是，它相比MD5算法，需要更多的计算次数，最终的输出长度也要长，(SHA0和SHA1是160字节。SHA256是256字节)。如果想要破解需要付出比MD5高的多的计算次数。\n经过长时间的发展，MD5和SHA0、SHA1已经被认为不安全，已经不再建议使用。 SHA2是目前被最常使用的算法，目前还没有针对SHA2的有效攻击。 SHA3是2015年才发布的，还没有大规模的取代SHA2。\n参考 SHA算法家族\n3. MAC 和 HMAC 相对于上面的MD5和SHA，这两种算法对于我算是比较陌生的。\nMAC是消息认证码(Message Authentication Code)的简称。它和上面两种算法的区别是MAC的计算需要一个Key(上面HTTPS流程中就生了计算MAC的KEY)。只有知道了KEY才能正确的计算出对应的MAC。\nHMAC的全称是密钥散列消息认证码(Keyed-hash message authentication code)。是指用秘钥并使用Hash散列算法生成认证码的一类算法的总称。\n那么MAC算法和HMAC算法是什么关系呢？\n我觉得可以这么理解。 MAC只是定义了一个概念\u0026mdash;使用一个key，给一段消息生成一个授权码；但是生成这个授权码的算法它并没有定义。所以如果你使用SHA256这种Hash散列算法来生成授权码，那么这种算法就可以被称为HMAC-SHA256。 所以HMAC是MAC的一类实现方式，就像快排是排序算法中的一种实现方式一样。\n参考： MAC-Wiki Difference between MAC and HMAC?\n4. Salted Hash 和 HMAC 加盐Hash和HMAC在某种程度上很相似，但是在使用场景上还是有很大的区别。目前还有没找到解释的比较好的文章，后面再进行补充\n todo  HTTPS证书 现在HTTPS基本已经成为了一个网站的标配。想要给一个网站添加对HTTPS的支持，就需要针对这个网站的域名申请证书。\nHTTPS证书类型 这里顺便说明一下目前的HTTPS证书大概分为3类。\n 域名型HTTPS 证书（DVSSL）：信任等级一般，只需验证网站的真实性便可颁发证书保护网站； 企业型HTTPS 证书（OVSSL）：信任等级强，须要验证企业的身份，审核严格，安全性更高； 增强型HTTPS 证书（EVSSL）：信任等级最高，一般用于银行证券等金融机构，审核严格，安全性最高，同时可以激活绿色网址栏。  我们看到越是高等级的证书，审核的严格程度也就越高。并在浏览器中会有一定程度的展示，也会给用户一种更为安全的感觉，当然价格也是更加昂贵。\nHTTPS证书内容和结构  Certificate  Version Number（证书版本） Serial Number(序列号) Signature Algorithm ID（该和客户端使用的签名算法） Issuer Name(证书签发者 DN) Validity period(有效期)  Not Before(生效开始时间) Not After(有效结束时间)   Subject name(证书使用者) Subject Public Key Info(证书)  Public Key Algorithm(公钥算法) Subject Public Key(证书公钥)   Issuer Unique Identifier (optional)(签发者唯一身份信息，可选) Subject Unique Identifier (optional)(使用者唯一身份信息，可选) Extensions (optional)(扩展字段)  \u0026hellip;   Signature(CA机构对证书的签名)    参考 X.509 wiki X.509 数字证书的基本原理及应用 X.509证书的读取与解释\n如何获得HTTPS证书 简单来说获的HTTPS证书有两种方式\n 在有CA认证的机构申请 自己生成  1.通过CA机构申请 申请CA机构认证的证书大致需要以下步骤\n1.1 生成CSR(Certificate Signing Request)文件 主要方式有两种，本地生成和在线生成\n 通过openssl命令本地生成CSR  openssl req -new -nodes -sha256 -newkey rsa:2048 -keyout myprivate.key -out mydomain.csr -new 指定生成一个新的CSR， nodes指定私钥文件不被加密, sha256 指定摘要算法， keyout生成私钥, newkey rsa:2048 指定私钥类型和长度， 最终生成CSR文件mydomain.csr。  通过线上网站生成，一般需要填写下面的内容。   线上的工具会把公钥加入到CSR文件中，并同时生成私钥。\n参考:在线CSR申请\n1.2 CA机构对证书签名 接下来就需要按照CA机构的要求，和想要申请的证书类型，提交相关材料。\nCA收到CSR并验证相关材料，并审核通过之后。需要进行的很重要的一个步骤就是:使用CA机构的私钥对提供证书中的内容进行签名，并把签名的结果存放在证书的数字签名部分。\nCA机构签名完，并发送给我们之后，我们就能够把证书部署在我们的服务器中了。\n2.自己生成证书 参考 自己生成HTTPS证书\n大家可以参考上面的文章自己创建一个证书试试。 自己创建的证书同样可以完成上面的步骤。只不过有一点就是，因为自己生成的证书没有得到CA机构的私钥签名，所以当浏览器通过HTTPS握手获得服务器证书的时候，没有办法确定这个证书是否就是来自请求的服务器。 这个时候浏览器就会给出该网站不安全的提示。\n如果客户端不能确认证书是安全，但是却贸然使用，就会有受到中间人攻击的风险。\n中间人攻击 具体的概念大家可以去下面的文章中了解一下，我们这里直接举例说明一下。\n这种中间人攻击的方式，常见于公共的未加密的WIFI。\n A想和B通讯，建立连接，并请求了B的证书。 C通过提供公共WIFI的方式，监听了A和B的通讯，拦截了B发送给A的证书，并把证书替换成自己的。 如果A没有证书检验机制的话，那么A并不能发现证书已经被替换了。 A还是以为在和B通讯。就会使用已经被替换了的证书中的公钥(也就是C的公钥)进行加密。 C拦截到消息，使用自己的私钥解密，获得原始的请求数据。然后就能随意篡改，然后使用B的公钥加密，在发送给B，达到了攻击的目的。  中间人攻击还有另外一种方式，危害性更大。 如果有恶意程序在我们的手机或者浏览器中安装了一个证书，并且诱导我们把这书设置为信任证书。 那么如果有其他恶意程序，在和我们的终端进行HTTPS握手的时候，发送给我们使用上面的证书签名的证书，那么我们的终端将无法识别这个恶意证书。导致中间人攻击的发生。\n要抵御中间人攻击的一个有效方式就是，充分利用证书的认证机制，还有对于证书的安装和信任要各位谨慎。\n参考：中间人攻击-Wiki\n证书认证链 上面的HTTPS流程中提到，客户端收到服务端证书之后，会进行验证。HTTPS证书的认证是链状的，每一个证书都需要它上级的证书来验证是否有效。\n链式结构 目前我们常见的证书链中一般分为3级。不过中间证书这部分，也有可能又分为多级。但是也是保持这样的链式结构。\n 根证书(Root CA)  中介(中间)证书(Intermediates)  终端实体证书(End-user)      终端证书的签发者是中间证书。 中间证书的签发者是上级中间或者根证书。 根证书的签发者是他自己。\nHTTPS的证书链，是一个自顶向下的信任链，每一个证书都需要它的上级证书来验证有效。所以根证书的作用就尤为重要，如果系统根证书被篡改，系统的安全性就受到威胁。\n根证书一般是通过系统，或者浏览器内置到我们的电脑的中的。系统更新或者浏览器更新的时候，也有可能会添加新的根证书。\n所以不要轻易的信任根证书，除非你是开发者，了解自己的所作所为。\n参考: 数字证书\n验证证书 我们以wiki百科的证书链来举例 当我们和wiki的服务器建立HTTPS连接的时候，会获得wiki的(End-User)证书(后面简称为WK证书)。\n服务器获得WK证书后，会用下面的几个方式来验证证书。\n1.证书有效性时间验证 CA在颁发证书时，都为每个证书设定了有效期，包括开始时间与结束时间。系统当前时间不在证书起止时间的话，都认为证书是无效的。\n2.证书完整性验证 上面证书链的时候说到每个证书需要他的上级证书来确保证书的有效性。这个确保的方式就是数字签名。\n所以我们只需要，使用CA证书中的公钥和对应的签名算法来验证一下签名，就能够确认证书的有效性。\n那么现在有一个问题就是，如何获取WK证书的上一级证书呢？ 这里两种可能\n 这个证书已经存在于你的电脑中了，直接使用就可以 你的电脑中还没有这个证书，需要下载(这里有个疑问就是，根据什么区下载这个证书，很有可能是签发者的DN，但是查了很多资料，并没有找到证据)  拿到CA证书之后，就能够使用CA证书中的公钥对WK证书验签了。\n一样的道理，CA证书的有效性需要CA的上级证书，也就是Root证书来证明。验证的过程是基本一致的。\n参考: HTTPS 精读之 TLS 证书校验 证书有效性验证、根证书\n3.IP/域名验证 在申请域名的时候，都会指定证书所针对的域名。所以这里就是验证，当前请求的域名，是否在这个证书所包含的域名列表中。\n证书里面的域名范围通常使用通配符来表示。 但是以*.example.com的二级域名范围就不能包含a.b.example.com这个三级域名。\n4.证书吊销验证 浏览器获取到服务器证书后，需要判断该证书是不是已经被CA机构吊销。如果已经吊销需要浏览器给出提示。\n这里只大概说一下证书的吊销校验主要分2种\n 通过CRL(Certificate Revocation List) 证书吊销列表 需要定时的去更新CA机构提供的CRL文件，这个里面记录了改CA机构下所有被吊销的证书。CRL目前正在被OCSP取代，因为CRL不及时，并且每个CRL文件，比较大，影响用户体验。 通过OCSP(Online Certificate Status Protocol) 在线证书状态协议 这是一个实时的通过证书的序列号去查询证书状态的协议，但是这个有一个问题是，因为每次建立HTTPS链接都需要请求这个接口，所以如果这个接口响应慢的话，十分影响用户的体验。所以需要浏览器这边有一个策略，就是如果在一定时间内OCSP没有响应，那怎么处理。 如果强依赖OCSP的话，会容易引起OCSP的单点故障。  详细的胡啊 参考： 你不在意的证书吊销机制 PKI体系中的证书吊销\n总结 HTTPS的相关总结就先到这里，不知道有没有解决大家的疑问。如果有疑问或者问题，欢迎大家在评论区继续沟通。\n参考 HTTPS 基本过程\nTLS 协议\n数字证书\n你不在意的证书吊销机制\nPKI体系中的证书吊销\nHTTPS 精读之 TLS 证书校验\n证书有效性验证、根证书\n数字证书\n中间人攻击-Wiki\n自己生成HTTPS证书\n在线CSR申请\nX.509 wiki\nX.509 数字证书的基本原理及应用\nX.509证书的读取与解释\nMAC-Wiki\nDifference between MAC and HMAC?\nSHA算法家族\nRSA和DH算法\nECDHE-wiki\nDH-wiki\nRSA算法原理1\nRSA算法原理2\n密码学套件\n密码学套件表达式\nTLS 中的密钥计算\npre-master secret \nTLS协议\nTLS RFC\nNginx SSL 性能优化\n","permalink":"https://balvboy.github.io/blog/https%E8%AF%A6%E8%A7%A3/","summary":"什么是HTTPS HTTPS简单的说就是安全版的HTTP。 因为HTTP协议的数据都是明文进行传输的，所以对于一些敏感信息的传输就很不安全，为了安全传输敏感数据，网景公司设计了SSL（Secure Socket Layer），在HTTP的基础上添加了一个安全传输层，对所有的数据都加密后再进行传输，客户端和服务器端收到加密数据后按照之前约定好的秘钥解密。\nHTTPS是如何保证安全的 HTTPS的安全性是建立在密码学的基础之上的，有很多算法起到了至关重要的作用。\nHTTPS的交互过程 通过上面的描述，我们已经能大概知道HTTPS是使用加密算法在浏览器和服务器之前传递秘钥，然后再使用秘钥完成信息的加解密。所以这个秘钥是如何生成的，还有秘钥是如何在浏览器和服务器之间传递的就成了HTTPS的关键，下面我们来详细的了解一下这个过程。\n1.交互流程  Client Hello 客户端（通常是浏览器）先向服务器发出加密通信的请求,请求大概中包括下面内容  支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数 Random Number-RNc，稍后用于生成\u0026quot;对话密钥\u0026quot;。 支持的加解密方法，比如对称加密支持AES，秘钥交换算法支持RSA、DH，签名算法支持sha256等。(在更高版本的TLS协议中，交换的是密码学套件，所谓的套件就是一整套的加解密，秘钥交换方案)。 支持的压缩方法。   服务器收到请求,然后响应  确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数Random Number-RNs，稍后用于生成\u0026quot;对话密钥\u0026quot;。 确认使用的加密方法、秘钥交换算法、签名算法等等。 把服务器证书发送给客户端。 服务器要求验证客户端(浏览器)的证书(可选，大部分的服务器都不会要求)。   客户端收到服务器证书之后，会检查证书的有效性，如果服务器证书并不是经过CA机构认证的，浏览器就会在这个时候给用户提出警告。 客户端收到服务器验证客户端证书的请求，会将自己证书发送给服务器。客户端如果没有证书，则需要发送一个不包含证的证书消息。如果服务器需要客户端身份验证才能继续握手，则可能会使用致命的握手失败警报进行响应。(双向认证一般只存在于银行等一些安全性要求比较高的场景中，像早些时候我们使用的网银，里面存储的就是证书，用来在交易的时候和服务器端进行双向认证，保证安全) 服务器收到客户端证书，校验客户端证书是否有效 客户端把把上面流程中发送的所有消息(除了Client Hello)，使用客户端的私钥进行签名，然后发送给服务器。 服务器也保存着之前客户端发送的消息，然后用客户端发送过来的公钥，进行验签。 客户端生成一个Pre-Master-Secret随机数，然后使用服务器证书中的公钥加密，发送给服务器端。 服务器端收到Pre-Master-Secret的加密数据，因为是使用它的公钥加密的，所以可以使用私钥解密得到Pre-Master-Secret。 这时候客户端和服务端都同时知道了，RNc、RNs、Pre-Master-Secret这三个随机数，然后客户端和服务器端使用相同的PRF算法计算得到一个Master-Secret。然后可以从Master-Secret中再生成作为最终客户端和服务器端消息对称加密的秘钥，和对消息进行认证的MAC秘钥。  参考:TLS协议 TLS RFC\n2.Pre-Master-Secret Pre-Master-Secret前两个字节是TLS的版本号，这是一个比较重要的用来核对握手数据的版本号，因为在Client Hello阶段，客户端会发送一份加密套件列表和当前支持的SSL/TLS的版本号给服务端，而且是使用明文传送的，如果握手的数据包被破解之后，攻击者很有可能串改数据包，选择一个安全性较低的加密套件和版本给服务端，从而对数据进行破解。 所以，服务端需要对密文中解密出来对的Pre-Master-Secret中的版本号跟之前Client Hello阶段的版本号进行对比，如果版本号变低，则说明被篡改，则立即停止发送任何消息。\n参考：pre-master secret \n3.Master-Secret 客户端和服务端在生成Master-Secret的之后，会把Master-Secret作为PRF的参数，继续运算，最终得到下面6个秘钥，分别用于MAC算法和加解密算法。\n   秘钥名称 秘钥作用     client write MAC key 客户端对发送数据进行MAC计算使用的秘钥，服务端使用同样的秘钥确认数据的完整性   server write MAC key 服务端对返回数据进行MAC计算使用的秘钥，客户端使用同一个秘钥验证完整性   client write key 对称加密key，客户端数据加密，服务端解密   server write key 服务端加密，客户端解密   client write IV 初始化向量，运用于分组对称加密   server write IV 初始化向量，运用于分组对称加密    参考: TLS 中的密钥计算","title":"HTTPS详解 "},{"content":"字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会把字符编码放到一边，很少有机会或者会想到去专门系统的了解一下字符编码知识。\n我之前也写过一些编码的文章，但是回过头在去看的时候，发现这也不对，那也不对，主要就是因为当时了解的比较片面。这次希望能够把常见的几种编码，和在编程中常见的编码问题搞清楚。\n字符编码和字符集  字符集 字符集的意思就是所有字符的集合，并且每一个字符都有一个唯一的编号。 字符编码 字符编码就是把字符集内字符的编号转换成二进制数据的一种规则。  所以说字符集和字符编码并不是一个东西，字符编码需要依赖于字符集。但是大多数字符编码的名称就是它对应字符集的名称，比如\n ASCII字符集和ASCII字符编码 GBK字符集和GBK字符编码  但是有一个例外就是基于Unicode字符集的UTF系列的字符编码，这个我们后面会重点说。 下面简单介绍几个我们比较熟悉的字符集，不会详细讨论设计细节，如果大家有需要可以去查看字符集的维基百科。后面后给出链接。\nASCII ASCII可以认为是最早的字符集，它定义了128个字符，其中包括32个不可见字符(比如一些控制字符 换行，回车等)，还有96个可见字符(大写小写字母，标点符号等)。 ASCII的字符编码也比较简单，就是用二进制来表示字符的序号，因为它一共只有128个，所以只需要用到一个字节的后7位。\nASCII维基百科\nISO 8859-1 ISO 8859-1 这个也是我们很熟悉的字符集，这个字符集是以ASCII为基础，并扩充了一些拉丁字母，也被叫做Latin-1字符集。 因为拉丁国家众多，有很多国家都对这个字符集进行了修改或者扩充。 虽然有这么多的字符集，但是他们有一个共同点，他们都是采用的单字节的编码方式。\nISO-8859-1维基百科\nGBK GBK的全称是汉字内码扩展规范。 其中\n GB是国标的首字母 K 是扩展的首字母  GBK的其他信息，我们不做太多说明，有兴趣的可以去维基百科查看\nGBK维基百科\nGBK的编码方式 GBK分为单字节和双字节编码，单字节编码兼容ASCII字符集。 这张图片是GBK的编码分区图。\n 首字节 0-128(不包括128)，都是单字节的编码区域 首字节 128-255，第二字节 0-64，这部分区域没有字符，如果出现在这个区域，会被解析为� 首字节 128-255，第二字节 64-255，这部分主要是中文符号。  根据上面的编码分区图，我们可以知道GBK是如何区分一个字节是是单字节编码，还是双字节编码的第一个字节，这个很重要，在下面乱码的解析中，我们会分析。\n 如果小于128，则表示是单字节编码 如果大于128，则表示是双字节编码  Unicode 因为世界上的国家有很多，使用的语言和文字也大相径庭，每个国家都有自己使用的字符集和编码，所以有必要使用一个统一的字符集来解决字符集分裂的问题。Unicode就是为了解决这个问题而诞生的。\nUnicode中，是为每种语言都分配了一个区域，并且可以说是涵盖了世界上的所有的字符。  比如Unicode中的前128个字符和ASCII中的字符位置保持一致。 比如中文在Unicode的位置是 4E00-9FFF (19968-40959)  Unicode字符列表\nUnicode和UCS UCS是Universal Multiple-Octet Coded Character Set的简称\nUnicode和UCS的关系可以这么理解。\n 在历史中，有两个机构想要统一世界上的所有字符  国际标准化组织(ISO),设计出来的字符集就是UCS 统一码联盟，设计出来的是Unicode   后来，他们认识到，世界不需要两个不兼容的字符集，所以开始对这两个字符集进行合并。 从Unicode 2.0开始，Unicode采用了与UCS相同的字库和字码使两个字符集互相兼容。 但是各自依然保持独立。  UCS维基百科 Unicode维基百科\nUTF字符编码 需要明白的是，Unicode只是一个符号集，它只规定了符号的序号。字符集中的符号序号涵盖了1个字节，2个字节，3个字节，4个字节。\n 比如汉字的序号范围是 4E00到9FFF，在两字节的范围内。  那这里就有两个问题，\n 第一个问题是，如何有3个字节计算机怎么知道这3个字节是表示一个符号，还是表示3个单字节符号呢？ 第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用3个或4个字节表示，那么每个英文字母前都必然有2到3个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。  为了解决这两个问题，就出现了基于Unicode字符集的字符编码，UTF(Unicode/UCS Transformation Format)。 UTF编码又可以分为\n UTF-8  最小可以用一个字节来表示字符，以单字节（8位）为单位对Unicode进行编码   UTF-16  最小需要用2个字节来表示，以2个字节（16位）为单位对Unicode进行编码   UTF-32  最小需要4个字节来表示。以4个字节（32位）为单位对Unicode进行编码    UTF-8是使用最多的编码方式，下面我们会详细分析一下。 UTF-16和UTF-32我们使用较少，所以就不做分析了，有兴趣的同学可以自行了解一下。\n冷知识：Java的String中保存字符的value字段，使用的是UTF-16编码来存储的 Unicode转换格式维基百科 UTF-8维基百科 UTF-16维基百科 UTF-32维基百科\nUTF-8 UTF-8可以说是目前互联网中最常用的字符编码方式了。 截止到2019年11月， 在所有网页中，UTF-8编码应用率高达94.3%（其中一些仅是ASCII编码，因为它是UTF-8的子集），而在排名最高的1000个网页中占96％。\nUTF-8编码规则  若果Unicode值小于128，则字节的第一位为0，后面的7位为这个符号的Unicode码。比如字母 “A” 的Unicode值是 65。这个规则只试用于 ASCII中定义的字符。所以也解决了上面中的因为字符空间占用问题。使用UTF-8表示英文字符同样只需要1个字节。 对于Unicode值大于128的字符（所有的非ASCII中定于的字符）。假定表示该自己在Unicode中的值，需要n(n\u0026gt;=1)个字节，则使用UTF-8编码是，第一个字节的前n+1位都设置为1，第n+2位设置为0，后面字节的前2位都设置为10。剩下没有设置的二进制位，全部为这个符号的Unicode值。 所以UTF-8表示ASCII字符 需要一个字节。 表示其他的非ASCII 字符，主要用改字符在Unicode中的位置转成2进制所占用的字节数+1个 字节。 也就是说，如果这个字符在Unicde中的位置，需要1个字节来表示，那么UTF-8需要2个字节来表示这个字符，以此类推。  总结一下规则就是； 所以这里总结一个UTF-8的规则就是，用第一个字节的前N位 有几个连续的1来表示，这个字符占了几个字节，然后后面紧连着几个字节如果以10开头则表示，这个字节适合第一个字节一起表示一个字符\n 如果一个字节是0开头，则表示是一个单字节字符 如果是11开头，则表示是一个双字节字符 如果是111开头，则表示是一个3字节字符，  比如汉字中它的UTF-8编码是 1110 0100，10 111000，10 101101   如果是1111开头，则表示是一个4字节字符  UTF-8能够被广为使用的一个原因就是它兼容ASCII。 ASCII是UTF-8的一个子集。因为一个纯ASCII字符串也是一个合法的UTF-8字符串，所以现存的ASCII文本不需要转换。为传统的扩展ASCII字符集设计的软件通常可以不经修改或很少修改就能与UTF-8一起使用。 因为在Unicode出现之前，ASCII就是使用最广的语言。\nUTF-8编码转换分析 我们还以汉字中为例,它的UTF-8编码是 11100100，10111000，10101101,我们下面来分析一下，如何计算出来的这个结果\n 我们先去网上查一下“中”对应的Unicode码：\\u4e2d 对应的10进制 是 20013，也就是表示中是Unicode中的第20013个字符。 对应的二进制是 ：100111000101101（15位）为了方便转在前面加一个0，转为16位 01001110，00101101。 表示“中”在Unicode中的值，需要2个字节，所以参照上面规则，UTF-8表示这个“中”需要2+1 = 3 个字节 按照上面的规则 n =2 ,所以第一个字节的前2+1位设置为1 ，第4位设置为0，后面2个字节的前两位 都设置为 10 得到1110 **** , 10 ****** , 10 ******  剩下的位置填写 中的Unicode码的二进制 。剩下的位置共 4+6+6 = 16位，中的Unicode码的二进制也为16位，填入剩余的位置即可。 得到 1110 0100，10 111000，10 101101。  代码中的乱码问题 乱码的出现 下面我们来聊一聊代码中经常遇到的乱码问题。 先说结论，乱码就是对字符编码(字符转成二进制)和解码(二进制转成字符)使用的编码不同。\n举例说明一下： 计算机A 给 计算机B发送消息,内容为 \u0026ldquo;中国\u0026rdquo;。\n 计算机A中使用的编码是UTF-8,中国这两个字对应的UTF-8编码是E4B8AD E59BBD,对应的二进制是111001001011100010101101111001011001101110111101 计算机B，使用的编码是GBK,它收到网络中的数据，按照GBK的编码方式去解码。 然后结果必然是和期望的结果不同,解码的结果是涓浗;  上面的过程，我们可以用一段代码来表示 @Test public void testConvert(){ String str = \u0026#34;中国\u0026#34;; byte[] utfBytes =str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); String gbkStr = new String(utfBytes,Charset.forName(\u0026#34;GBK\u0026#34;)); System.out.println(gbkStr); } 下面我们来分析一下这个乱码是如何产生的。\n 计算机B收到的二进制数据是 11100100 10111000 10101101 11100101 10011011 10111101 B是使用GBK编码进行解码，所以我们按照上面的解码规则来解析   首先看第一个字节，大于128，所以是一个双字节编码，则读取前两个字节11100100 10111000\n 转换为16进制是E4B8，在GBK中对应的符号是涓    然后看第3个字节，同样大于128，所以也是双字节，然后读取第3和第4的字节10101101 11100101\n 转换为16进制是ADE5,查询GBK码表，显示这个位置并没有字符，所以显示为，但是其实这里是有一个特殊的填充字符的。和找不到字符的情况还是有区别的。下面我们会分析。     然后查询第5个字节，同样大于128，所以也是双字节，然后读取第5和第6的字节10011011 10111101\n 转换为16进制是9BBD,查询GBK码表，对应的字符时浗。      从乱码变回正常字符 通过上面的分析，我们知道我们接受到的字节数据是没有问题的，只要我们使用正确的编码对字节进行解码，就可以了。\n 但是一般在开发过程中，框架都帮我们完成了解码的工作，比如Tomcat。就是说我们获得就已经是乱码了。\n 所以说，如果我们能通过乱码，按照相同的编码方式来编码，就能拿到原始的字节数据，然后在使用正确的解码方式来解码，就能够得到正确的数据。\n我们同样用程序来模拟一下上面的过程。（代码中使用的是Hutool的HexUtil工具类）\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;中国\u0026#34;; byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 一般情况下，我们使用获得乱码的编码方式，再对乱码进行编码，就能获得原始的字节数据。然后在使用正确的编码方式来解码，就能获得正确的字符。\n例外情况 但是也有一种例外情况，如果你变成了乱码，然后在重新编码回来，是无法获得原始的字节数据的，也就没有办法再变成正确的字符了。\n下面还是举例来说明一下\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); System.out.println(\u0026#34;gbk编码字节\u0026#34;+HexUtil.encodeHexStr(gbksBytes)); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;干\u0026#34;; System.out.println(\u0026#34;原字符:\u0026#34; + str); byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(\u0026#34;utf8编码字节:\u0026#34;+HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 我们发现，和上面一样的代码，对于不同的原字符，就出现了截然不同的结果。\n我们来分析一下原因。\n 首先我们使用UTF-8对原字符干编码，得到的结果是e5b9b2,转为二进制是11100101 10111001 10110010 使用GBK编码，对这段数据进行解码  首先读取第一个字节，大于128，认定是一个双字节字符，所以读取前两个字节11100101 10111001，对应的16进制是e5b9。 查询GBK码表，对应的字符是骞。 然后读取第三个字节，大于128，认定是一个双字节字符，但是这个只有一个字节，所以是有问题的，就被解析成�。   然后使用GBK编码对乱码重新编码，得到的字节数据是e5b93f 我们看到�,这个字符被编码成了3f。 使用UTF8编码对e5b93f解码，得到�?。  所以说，这里失败的原因是，当转换成GBK编码的时候，因为字节数为3个，所以最后1个字节被认为是错误的编码，被转成了通用错误字符�,导致再转成UTF-8的时候，无法还原成原始的字节数据。\n总结一下  GBK编码图中有一部分非法编码区，落在这个编码区的字符，或者不符合GBK编码规则的字符(比如大于128，但是只有一个字节)，会被解析成�。那么就会造成数据丢失，就无法转换成正确的数据了。 如果原始字节数据，是偶数字节，那么有很大可能都能被GBK正确解码，那么还是能够通过GBK编码获得原始数据的，那就能够重新获得正确的字符 有一种比较常见的情况是，发送方使用UTF-8格式的编码，接收方默认使用ISO-8859-1(Tomcat在不指定解码的时候，默认就是)。因为ISO-8859-1是单字节编码，所以虽然会是转换成乱码，但是每个字节都会有对应的字符，所以当再次使用ISO-8859-1编码，就不回发生数据丢失的情况，会原原本本的得到原始的字节数据，在按照UTF-8解码就可以了。 所以说如果一段字节数据，在使用某种编码解码A时，出现了不在该编码类型A的编码区中的数据。那么再次使用编码类型A编码时，就会出现数据丢失，导致无法还原会正确的字符。  GBK偶数字节乱码修复测试  我们看到原始字符是干哈哈哈，4个字符，使用UTF-8编码16进制是e5b9b2e59388e59388e59388，一共12字节。 使用GBK解码，正好2个自己对应一个字符，得到6个字符。 虽然文字看起来像乱码。 但是每个字节都有用到，没有发生数据丢失，这样我们再次使用gbk编码之后，就能重新得到e5b9b2e59388e59388e59388，原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈哈了。  ISO-8859-1乱码修复测试  这次测试的原始字符换成了干哈哈，UTF-8编码后16进制是e5b9b2e59388e59388 9个字节。 使用ISO-8859-1解码，得到了乱码，我们选中得到的字符，看到其实是9个字符 所以每个每个字节都对应了1个字符，没有数据丢失。 再使用ISO-8859-1对乱码编码，就重新得到了e5b9b2e59388e59388原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈了。  ","permalink":"https://balvboy.github.io/blog/%E7%BC%96%E7%A0%81%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","summary":"字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会把字符编码放到一边，很少有机会或者会想到去专门系统的了解一下字符编码知识。\n我之前也写过一些编码的文章，但是回过头在去看的时候，发现这也不对，那也不对，主要就是因为当时了解的比较片面。这次希望能够把常见的几种编码，和在编程中常见的编码问题搞清楚。\n字符编码和字符集  字符集 字符集的意思就是所有字符的集合，并且每一个字符都有一个唯一的编号。 字符编码 字符编码就是把字符集内字符的编号转换成二进制数据的一种规则。  所以说字符集和字符编码并不是一个东西，字符编码需要依赖于字符集。但是大多数字符编码的名称就是它对应字符集的名称，比如\n ASCII字符集和ASCII字符编码 GBK字符集和GBK字符编码  但是有一个例外就是基于Unicode字符集的UTF系列的字符编码，这个我们后面会重点说。 下面简单介绍几个我们比较熟悉的字符集，不会详细讨论设计细节，如果大家有需要可以去查看字符集的维基百科。后面后给出链接。\nASCII ASCII可以认为是最早的字符集，它定义了128个字符，其中包括32个不可见字符(比如一些控制字符 换行，回车等)，还有96个可见字符(大写小写字母，标点符号等)。 ASCII的字符编码也比较简单，就是用二进制来表示字符的序号，因为它一共只有128个，所以只需要用到一个字节的后7位。\nASCII维基百科\nISO 8859-1 ISO 8859-1 这个也是我们很熟悉的字符集，这个字符集是以ASCII为基础，并扩充了一些拉丁字母，也被叫做Latin-1字符集。 因为拉丁国家众多，有很多国家都对这个字符集进行了修改或者扩充。 虽然有这么多的字符集，但是他们有一个共同点，他们都是采用的单字节的编码方式。\nISO-8859-1维基百科\nGBK GBK的全称是汉字内码扩展规范。 其中\n GB是国标的首字母 K 是扩展的首字母  GBK的其他信息，我们不做太多说明，有兴趣的可以去维基百科查看\nGBK维基百科\nGBK的编码方式 GBK分为单字节和双字节编码，单字节编码兼容ASCII字符集。 这张图片是GBK的编码分区图。\n 首字节 0-128(不包括128)，都是单字节的编码区域 首字节 128-255，第二字节 0-64，这部分区域没有字符，如果出现在这个区域，会被解析为� 首字节 128-255，第二字节 64-255，这部分主要是中文符号。  根据上面的编码分区图，我们可以知道GBK是如何区分一个字节是是单字节编码，还是双字节编码的第一个字节，这个很重要，在下面乱码的解析中，我们会分析。\n 如果小于128，则表示是单字节编码 如果大于128，则表示是双字节编码  Unicode 因为世界上的国家有很多，使用的语言和文字也大相径庭，每个国家都有自己使用的字符集和编码，所以有必要使用一个统一的字符集来解决字符集分裂的问题。Unicode就是为了解决这个问题而诞生的。\nUnicode中，是为每种语言都分配了一个区域，并且可以说是涵盖了世界上的所有的字符。  比如Unicode中的前128个字符和ASCII中的字符位置保持一致。 比如中文在Unicode的位置是 4E00-9FFF (19968-40959)  Unicode字符列表\nUnicode和UCS UCS是Universal Multiple-Octet Coded Character Set的简称","title":"字符集和字符编码 "},{"content":"一、cron介绍  crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。 通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\n 我理解cron是一个表达式，用来表示一个任务的周期性执行时间。\n二、cron格式 2.1、完整格式 ┌─秒(0-59) | ┌─分鐘(0-59) | │ ┌─小時(0-23) | | │ ┌─日 day of month(1-31) | | | | ┌─月(1-12) | | | | | ┌─星期 day of week(0-7，0和7都表示星期日) | | | | | | ┌─年(可以省略不写) * * * * * * * 开始的时候我把cron的格式分为了两种，分别是Linux crontab中的格式和Java中使用的格式。后面想了想，觉得cron的格式应该只有一种，就是上面的这种包含 7个字段的格式。然后不同的cron实现对于cron格式的实现程度不同。\n比如Linux的crontab，它只能支持5个字段，不能支持秒和年\n2.2、crontab格式 ┌─分鐘（0 - 59） │ ┌─小時（0 - 23） | │ ┌─日 day of month(1-31) | | | ┌─月（1 - 12） | | | | ┌─星期 day of week(0-7，0和7都表示星期日) * * * * * linux-crontab-校验\n2.3、cron格式总结 因为在网上一直没有找到准确的官方的cron的定义，所以上面的都是我自己的理解。我认为cron这种很通用的表达式，它的定义应该不会太分裂\n三、day of week中数字的定义 在查看文档和测试的过程中发现，同样的一个表达式，会得出不同的执行结果，后来发现是因为对于day-of-week的定义大致分为两种\n3.1、crontab中的定义 在类Unix的系统中的crontab命令中，数字0和7都代表周日,然后1-6分别表示MON-SAT(周一到周六)；\n这里0和7都表示周日，是有一定的历史原因的，是为了兼容之前不同版本的Unix系统。\n This is a matter of portability. In early Unices, some versions of cron accepted 0 as Sunday, and some accepted 7 as Sunday \u0026ndash; this format is an attempt to be portable with both.\n Day of week {0-7} in crontab has 8 options, but we have only 7 days in a week\n3.2、Java中的定义 在Java的不同实现中,我找到了2个，分别是Spring的实现和Quartz的实现\n  Spring的CronSequenceGenerator和Linux保持一致；顺便说一下这个类是Spring中@Scheduled注解的默认cron解析类\n  Quartz的CronExpression的实现CronExpression和Linux不同，它不支持0，然后1-7分别是SUN-SAT(周日-周六)\n  3.3、解决办法 鉴于不同的实现中，对于day of week数字的定义的区别，最好的办法就是使用星期的简写来代替数字，例如SUN,MON,TUE等等，这样就能保证你的cron不管在哪个Java的cron实现中都能正确运行。\n四、cron每个字段支持的输入    Field Name Allowed Values Allowed Special Characters     Seconds 0-59 , - * /   Minutes 0-59 , - * /   Hours 0-23 , - * /   Day-of-month 1-31 , - * ? / L W   Month 1-12 or JAN-DEC , - * /   Day-of-Week 0-7 or SUN,MON,TUE,WED,THU,FRI,SAT , - * ? / L #   Year (Optional) empty, 1970-2199 , - * /    五、cron特殊字符说明 这里先说一下我的理解，对于cron中的特殊字符，应该是有一套比较统一的规则定义，只不过在在不同的cron的实现里，有的只选择实现了一部分的规则。\n就像Linux中的crontab命令，只实现了下面的几种基本特殊字符。\nJava的实现中，Quartz算是实现的功能比较全的，基本上完全实现了所有的特殊字符的功能。\n所以在我们写cron表达式的时候，一定要清楚，我们的表示是会用在什么地方，支持什么样的写法，像我工作中比较常用的就是在Spring中@Scheduled注解，和elastic-job创建定时任务（cron解析使用Quartz）\n5.1、基本特殊字符    字符 描述 举例 解释     , 表示几个会生效的值 1,2,3 in Minutes 表示在第1和第2和第3分钟 都会生效   - 表示生效的范围 1-10 in Minutes 表示在第1到第10分钟会生效   * 表示所有的值都会生效， * in Minutes 表示每分钟都会生效   / 表示增量，可以理解为每隔多长时间 0/30 in Minutes 表示第0分钟生效，然后每隔30分钟生效一次    5.2、? 字符说明  The \u0026lsquo;?\u0026rsquo; character is allowed for the day-of-month and day-of-week fields. It is used to specify \u0026lsquo;no specific value\u0026rsquo;. This is useful when you need to specify something in one of the two fields, but not the other.\n  ?号只能用在day-of-month和day-of-week字段中。通常用来表示为\u0026rsquo;没有指定的值'。当你需要在两个字段之一中指定某些内容而不是另一个字段时，这非常有用。\n 我们使用cron的初衷是想让这个任务定期的执行，比如每个月1日执行什么，或者每周1执行什么。当一个任务在每个月1日，执行的时候，我们通常不会要求它是星期几，同样每周1执行的任务，我们也不会关心当天是几月几号。也就是说，在极大多数的情况下，我们不需要这两个字段同时满足。\n所以说，通常情况下，我们在指定了这两个其中一个字段之后，会把另一个字段设置为'?'。\n或许有人说，我就要每个月1号、并且还必须得是星期一的0点0分0秒，它才能执行，当然我们也能实现(这种同时制定month和week的表达式，不是所有的都支持,比如Quartz就不支持week和month同时设置)\n0 0 0 1 * 1 接下来7次的执行时间 -------------------------- 2020-06-01 00:00:00 2021-02-01 00:00:00 2021-03-01 00:00:00 2021-11-01 00:00:00 2022-08-01 00:00:00 2023-05-01 00:00:00 2024-01-01 00:00:00 spring-cron-online\n那这个时间真的是你想要的吗？\n5.3、L 字符说明 L其实是LAST的简写，就是最后的意思，它可以用在 day-of-month和day-of-week字段中。 它在两个字段中的意思有一些不同\n day-of-month：直接使用L表示这个月的最后一天，如果是1月那就是31号，如果是平年的2月，那就是28号 day-of-month: 使用 L-3,表示这个月的倒数第3天 day-of-week：如果直接使用L,则表示星期六（是从周日开始的，所以周六是最后一天） day-of-week: MONL(为了避免数字造成的混淆直接使用字母)，表示这个月的最后一个周一  5.4、W 字符说明 W在这里代表的是WeekDay(工作日的意思)，它只能使用在day-of-month字段中。 在表达式的使用中，它的作用是指定在同一个月内，离指定日期最近的工作日。\n举例1\n0 0 0 15W * ? 这个表达式字面意思是，在离每个月15号最近的工作日的 0点0分0秒触发 1. 如果15号是 周一到周五中的某一天，那么就在当天触发 2. 如果15号是 周六，那么离周六最近的工作日就是周五(前一天)，那么就会在周五触发； 3. 如果15号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 这个有一个大前提就是，必须是同一个月内的。通过下面的例子来说明一下\n举例2\n0 0 0 1W * ? 这个表达式字面意思是，在离每个月1号最近的工作日的 0点0分0秒触发 1. 如果1号是 周一到周五中的某一天，那么就在当天触发（这个没问题） 2. 如果1号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 3. 如果1号是 周六，关键在这里，距离周六最近的工作日是周五(前一天，1号的前一天已经是上个月了)，但是因为大前提是必须是同一个月的，所以只能在后两天的周一触发 5.5、# 字符说明  The \u0026lsquo;#\u0026rsquo; character is allowed for the day-of-week field. This character is used to specify \u0026ldquo;the nth\u0026rdquo; XXX day of the month.\nIf the \u0026lsquo;#\u0026rsquo; character is used, there can only be one expression in the day-of-week field (\u0026ldquo;3#1,6#3\u0026rdquo; is not valid, since there are two expressions).\n # 号只能用在 day-of-week字段中，表示某个月的第几个星期几; 同时说明一下 #前面的是表示星期几，#后面的数字表示第几，还有如果day-of-week使用了#。\n如果day-of-week字段中出现了#,那么day-of-week中就只能有且只有这一种表达式。\n举例\n0 0 0 ? * MON#2 每个月的第二个星期一 0点0分0秒 六、常见cron 每个月的工作日上午9点0分0秒\n0 0 9 ? * MON-FRI 每个月的最后一个周一上午9点0分0秒\n0 0 9 ? * MONL 每个月的最后一个工作日上午9点0分0秒\n0 0 9 LW * ? 这里需要注意的就是 W必须要写在后面 在工作日每隔10分钟执行一次\n0 */10 * ? * MON-FRI 六、参考文章 Quartz-CronExpression\nquartz-cron-校验\nlinux-man-crontab\nlinux-easycron\ncron-wiki\n","permalink":"https://balvboy.github.io/blog/cron/","summary":"\u003ch1 id=\"一cron介绍\"\u003e一、cron介绍\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003ecrontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。\n通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"cron表达式 "},{"content":"微信公众号 ","permalink":"https://balvboy.github.io/wechat/","summary":"微信公众号 ","title":""},{"content":"","permalink":"https://balvboy.github.io/search/","summary":"search","title":"Search"}]