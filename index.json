[{"content":"字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会把字符编码放到一边，很少有机会或者会想到去专门系统的了解一下字符编码知识。\n我之前也写过一些编码的文章，但是回过头在去看的时候，发现这也不对，那也不对，主要就是因为当时了解的比较片面。这次希望能够把常见的几种编码，和在编程中常见的编码问题搞清楚。\n字符编码和字符集  字符集 字符集的意思就是所有字符的集合，并且每一个字符都有一个唯一的编号。 字符编码 字符编码就是把字符集内字符的编号转换成二进制数据的一种规则。  所以说字符集和字符编码并不是一个东西，字符编码需要依赖于字符集。但是大多数字符编码的名称就是它对应字符集的名称，比如\n ASCII字符集和ASCII字符编码 GBK字符集和GBK字符编码  但是有一个例外就是基于Unicode字符集的UTF系列的字符编码，这个我们后面会重点说。 下面简单介绍几个我们比较熟悉的字符集，不会详细讨论设计细节，如果大家有需要可以去查看字符集的维基百科。后面后给出链接。\nASCII ASCII可以认为是最早的字符集，它定义了128个字符，其中包括32个不可见字符(比如一些控制字符 换行，回车等)，还有96个可见字符(大写小写字母，标点符号等)。 ASCII的字符编码也比较简单，就是用二进制来表示字符的序号，因为它一共只有128个，所以只需要用到一个字节的后7位。\nASCII维基百科\nISO 8859-1 ISO 8859-1 这个也是我们很熟悉的字符集，这个字符集是以ASCII为基础，并扩充了一些拉丁字母，也被叫做Latin-1字符集。 因为拉丁国家众多，有很多国家都对这个字符集进行了修改或者扩充。 虽然有这么多的字符集，但是他们有一个共同点，他们都是采用的单字节的编码方式。\nISO-8859-1维基百科\nGBK GBK的全称是汉字内码扩展规范。 其中\n GB是国标的首字母 K 是扩展的首字母  GBK的其他信息，我们不做太多说明，有兴趣的可以去维基百科查看\nGBK维基百科\nGBK的编码方式 GBK分为单字节和双字节编码，单字节编码兼容ASCII字符集。 这张图片是GBK的编码分区图。\n 首字节 0-128(不包括128)，都是单字节的编码区域 首字节 128-255，第二字节 0-64，这部分区域没有字符，如果出现在这个区域，会被解析为� 首字节 128-255，第二字节 64-255，这部分主要是中文符号。  根据上面的编码分区图，我们可以知道GBK是如何区分一个字节是是单字节编码，还是双字节编码的第一个字节，这个很重要，在下面乱码的解析中，我们会分析。\n 如果小于128，则表示是单字节编码 如果大于128，则表示是双字节编码  Unicode 因为世界上的国家有很多，使用的语言和文字也大相径庭，每个国家都有自己使用的字符集和编码，所以有必要使用一个统一的字符集来解决字符集分裂的问题。Unicode就是为了解决这个问题而诞生的。\nUnicode中，是为每种语言都分配了一个区域，并且可以说是涵盖了世界上的所有的字符。  比如Unicode中的前128个字符和ASCII中的字符位置保持一致。 比如中文在Unicode的位置是 4E00-9FFF (19968-40959)  Unicode字符列表\nUnicode和UCS UCS是Universal Multiple-Octet Coded Character Set的简称\nUnicode和UCS的关系可以这么理解。\n 在历史中，有两个机构想要统一世界上的所有字符  国际标准化组织(ISO),设计出来的字符集就是UCS 统一码联盟，设计出来的是Unicode   后来，他们认识到，世界不需要两个不兼容的字符集，所以开始对这两个字符集进行合并。 从Unicode 2.0开始，Unicode采用了与UCS相同的字库和字码使两个字符集互相兼容。 但是各自依然保持独立。  UCS维基百科 Unicode维基百科\n####UTF字符编码 需要明白的是，Unicode只是一个符号集，它只规定了符号的序号。字符集中的符号序号涵盖了1个字节，2个字节，3个字节，4个字节。\n 比如汉字的序号范围是 4E00到9FFF，在两字节的范围内。  那这里就有两个问题，\n 第一个问题是，如何有3个字节计算机怎么知道这3个字节是表示一个符号，还是表示3个单字节符号呢？ 第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用3个或4个字节表示，那么每个英文字母前都必然有2到3个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。  为了解决这两个问题，就出现了基于Unicode字符集的字符编码，UTF(Unicode/UCS Transformation Format)。 UTF编码又可以分为\n UTF-8  最小可以用一个字节来表示字符，以单字节（8位）为单位对Unicode进行编码   UTF-16  最小需要用2个字节来表示，以2个字节（16位）为单位对Unicode进行编码   UTF-32  最小需要4个字节来表示。以4个字节（32位）为单位对Unicode进行编码    UTF-8是使用最多的编码方式，下面我们会详细分析一下。 UTF-16和UTF-32我们使用较少，所以就不做分析了，有兴趣的同学可以自行了解一下。\n冷知识：Java的String中保存字符的value字段，使用的是UTF-16编码来存储的 Unicode转换格式维基百科 UTF-8维基百科 UTF-16维基百科 UTF-32维基百科\nUTF-8 UTF-8可以说是目前互联网中最常用的字符编码方式了。 截止到2019年11月， 在所有网页中，UTF-8编码应用率高达94.3%（其中一些仅是ASCII编码，因为它是UTF-8的子集），而在排名最高的1000个网页中占96％。\nUTF-8编码规则  若果Unicode值小于128，则字节的第一位为0，后面的7位为这个符号的Unicode码。比如字母 “A” 的Unicode值是 65。这个规则只试用于 ASCII中定义的字符。所以也解决了上面中的因为字符空间占用问题。使用UTF-8表示英文字符同样只需要1个字节。 对于Unicode值大于128的字符（所有的非ASCII中定于的字符）。假定表示该自己在Unicode中的值，需要n(n\u0026gt;=1)个字节，则使用UTF-8编码是，第一个字节的前n+1位都设置为1，第n+2位设置为0，后面字节的前2位都设置为10。剩下没有设置的二进制位，全部为这个符号的Unicode值。 所以UTF-8表示ASCII字符 需要一个字节。 表示其他的非ASCII 字符，主要用改字符在Unicode中的位置转成2进制所占用的字节数+1个 字节。 也就是说，如果这个字符在Unicde中的位置，需要1个字节来表示，那么UTF-8需要2个字节来表示这个字符，以此类推。  总结一下规则就是； 所以这里总结一个UTF-8的规则就是，用第一个字节的前N位 有几个连续的1来表示，这个字符占了几个字节，然后后面紧连着几个字节如果以10开头则表示，这个字节适合第一个字节一起表示一个字符\n 如果一个字节是0开头，则表示是一个单字节字符 如果是11开头，则表示是一个双字节字符 如果是111开头，则表示是一个3字节字符，  比如汉字中它的UTF-8编码是 1110 0100，10 111000，10 101101   如果是1111开头，则表示是一个4字节字符  UTF-8能够被广为使用的一个原因就是它兼容ASCII。 ASCII是UTF-8的一个子集。因为一个纯ASCII字符串也是一个合法的UTF-8字符串，所以现存的ASCII文本不需要转换。为传统的扩展ASCII字符集设计的软件通常可以不经修改或很少修改就能与UTF-8一起使用。 因为在Unicode出现之前，ASCII就是使用最广的语言。\nUTF-8编码转换分析 我们还以汉字中为例,它的UTF-8编码是 11100100，10111000，10101101,我们下面来分析一下，如何计算出来的这个结果\n 我们先去网上查一下“中”对应的Unicode码：\\u4e2d 对应的10进制 是 20013，也就是表示中是Unicode中的第20013个字符。 对应的二进制是 ：100111000101101（15位）为了方便转在前面加一个0，转为16位 01001110，00101101。 表示“中”在Unicode中的值，需要2个字节，所以参照上面规则，UTF-8表示这个“中”需要2+1 = 3 个字节 按照上面的规则 n =2 ,所以第一个字节的前2+1位设置为1 ，第4位设置为0，后面2个字节的前两位 都设置为 10 得到1110 **** , 10 ****** , 10 ******  剩下的位置填写 中的Unicode码的二进制 。剩下的位置共 4+6+6 = 16位，中的Unicode码的二进制也为16位，填入剩余的位置即可。 得到 1110 0100，10 111000，10 101101。  代码中的乱码问题 乱码的出现 下面我们来聊一聊代码中经常遇到的乱码问题。 先说结论，乱码就是对字符编码(字符转成二进制)和解码(二进制转成字符)使用的编码不同。\n举例说明一下： 计算机A 给 计算机B发送消息,内容为 \u0026ldquo;中国\u0026rdquo;。\n 计算机A中使用的编码是UTF-8,中国这两个字对应的UTF-8编码是E4B8AD E59BBD,对应的二进制是111001001011100010101101111001011001101110111101 计算机B，使用的编码是GBK,它收到网络中的数据，按照GBK的编码方式去解码。 然后结果必然是和期望的结果不同,解码的结果是涓浗;  上面的过程，我们可以用一段代码来表示 @Test public void testConvert(){ String str = \u0026#34;中国\u0026#34;; byte[] utfBytes =str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); String gbkStr = new String(utfBytes,Charset.forName(\u0026#34;GBK\u0026#34;)); System.out.println(gbkStr); } 下面我们来分析一下这个乱码是如何产生的。\n 计算机B收到的二进制数据是 11100100 10111000 10101101 11100101 10011011 10111101 B是使用GBK编码进行解码，所以我们按照上面的解码规则来解析   首先看第一个字节，大于128，所以是一个双字节编码，则读取前两个字节11100100 10111000\n 转换为16进制是E4B8，在GBK中对应的符号是涓    然后看第3个字节，同样大于128，所以也是双字节，然后读取第3和第4的字节10101101 11100101\n 转换为16进制是ADE5,查询GBK码表，显示这个位置并没有字符，所以显示为，但是其实这里是有一个特殊的填充字符的。和找不到字符的情况还是有区别的。下面我们会分析。     然后查询第5个字节，同样大于128，所以也是双字节，然后读取第5和第6的字节10011011 10111101\n 转换为16进制是9BBD,查询GBK码表，对应的字符时浗。      从乱码变回正常字符 通过上面的分析，我们知道我们接受到的字节数据是没有问题的，只要我们使用正确的编码对字节进行解码，就可以了。\n 但是一般在开发过程中，框架都帮我们完成了解码的工作，比如Tomcat。就是说我们获得就已经是乱码了。\n 所以说，如果我们能通过乱码，按照相同的编码方式来编码，就能拿到原始的字节数据，然后在使用正确的解码方式来解码，就能够得到正确的数据。\n我们同样用程序来模拟一下上面的过程。（代码中使用的是Hutool的HexUtil工具类）\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;中国\u0026#34;; byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 一般情况下，我们使用获得乱码的编码方式，再对乱码进行编码，就能获得原始的字节数据。然后在使用正确的编码方式来解码，就能获得正确的字符。\n例外情况 但是也有一种例外情况，如果你变成了乱码，然后在重新编码回来，是无法获得原始的字节数据的，也就没有办法再变成正确的字符了。\n下面还是举例来说明一下\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); System.out.println(\u0026#34;gbk编码字节\u0026#34;+HexUtil.encodeHexStr(gbksBytes)); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;干\u0026#34;; System.out.println(\u0026#34;原字符:\u0026#34; + str); byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(\u0026#34;utf8编码字节:\u0026#34;+HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 我们发现，和上面一样的代码，对于不同的原字符，就出现了截然不同的结果。\n我们来分析一下原因。\n 首先我们使用UTF-8对原字符干编码，得到的结果是e5b9b2,转为二进制是11100101 10111001 10110010 使用GBK编码，对这段数据进行解码  首先读取第一个字节，大于128，认定是一个双字节字符，所以读取前两个字节11100101 10111001，对应的16进制是e5b9。 查询GBK码表，对应的字符是骞。 然后读取第三个字节，大于128，认定是一个双字节字符，但是这个只有一个字节，所以是有问题的，就被解析成�。   然后使用GBK编码对乱码重新编码，得到的字节数据是e5b93f 我们看到�,这个字符被编码成了3f。 使用UTF8编码对e5b93f解码，得到�?。  所以说，这里失败的原因是，当转换成GBK编码的时候，因为字节数为3个，所以最后1个字节被认为是错误的编码，被转成了通用错误字符�,导致再转成UTF-8的时候，无法还原成原始的字节数据。\n总结一下  GBK编码图中有一部分非法编码区，落在这个编码区的字符，或者不符合GBK编码规则的字符(比如大于128，但是只有一个字节)，会被解析成�。那么就会造成数据丢失，就无法转换成正确的数据了。 如果原始字节数据，是偶数字节，那么有很大可能都能被GBK正确解码，那么还是能够通过GBK编码获得原始数据的，那就能够重新获得正确的字符 有一种比较常见的情况是，发送方使用UTF-8格式的编码，接收方默认使用ISO-8859-1(Tomcat在不指定解码的时候，默认就是)。因为ISO-8859-1是单字节编码，所以虽然会是转换成乱码，但是每个字节都会有对应的字符，所以当再次使用ISO-8859-1编码，就不回发生数据丢失的情况，会原原本本的得到原始的字节数据，在按照UTF-8解码就可以了。 所以说如果一段字节数据，在使用某种编码解码A时，出现了不在该编码类型A的编码区中的数据。那么再次使用编码类型A编码时，就会出现数据丢失，导致无法还原会正确的字符。  GBK偶数字节乱码修复测试  我们看到原始字符是干哈哈哈，4个字符，使用UTF-8编码16进制是e5b9b2e59388e59388e59388，一共12字节。 使用GBK解码，正好2个自己对应一个字符，得到6个字符。 虽然文字看起来像乱码。 但是每个字节都有用到，没有发生数据丢失，这样我们再次使用gbk编码之后，就能重新得到e5b9b2e59388e59388e59388，原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈哈了。  ISO-8859-1乱码修复测试  这次测试的原始字符换成了干哈哈，UTF-8编码后16进制是e5b9b2e59388e59388 9个字节。 使用ISO-8859-1解码，得到了乱码，我们选中得到的字符，看到其实是9个字符 所以每个每个字节都对应了1个字符，没有数据丢失。 再使用ISO-8859-1对乱码编码，就重新得到了e5b9b2e59388e59388原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈了。  ","permalink":"https://balvboy.github.io/blog/%E7%BC%96%E7%A0%81%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/","summary":"字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会把字符编码放到一边，很少有机会或者会想到去专门系统的了解一下字符编码知识。\n我之前也写过一些编码的文章，但是回过头在去看的时候，发现这也不对，那也不对，主要就是因为当时了解的比较片面。这次希望能够把常见的几种编码，和在编程中常见的编码问题搞清楚。\n字符编码和字符集  字符集 字符集的意思就是所有字符的集合，并且每一个字符都有一个唯一的编号。 字符编码 字符编码就是把字符集内字符的编号转换成二进制数据的一种规则。  所以说字符集和字符编码并不是一个东西，字符编码需要依赖于字符集。但是大多数字符编码的名称就是它对应字符集的名称，比如\n ASCII字符集和ASCII字符编码 GBK字符集和GBK字符编码  但是有一个例外就是基于Unicode字符集的UTF系列的字符编码，这个我们后面会重点说。 下面简单介绍几个我们比较熟悉的字符集，不会详细讨论设计细节，如果大家有需要可以去查看字符集的维基百科。后面后给出链接。\nASCII ASCII可以认为是最早的字符集，它定义了128个字符，其中包括32个不可见字符(比如一些控制字符 换行，回车等)，还有96个可见字符(大写小写字母，标点符号等)。 ASCII的字符编码也比较简单，就是用二进制来表示字符的序号，因为它一共只有128个，所以只需要用到一个字节的后7位。\nASCII维基百科\nISO 8859-1 ISO 8859-1 这个也是我们很熟悉的字符集，这个字符集是以ASCII为基础，并扩充了一些拉丁字母，也被叫做Latin-1字符集。 因为拉丁国家众多，有很多国家都对这个字符集进行了修改或者扩充。 虽然有这么多的字符集，但是他们有一个共同点，他们都是采用的单字节的编码方式。\nISO-8859-1维基百科\nGBK GBK的全称是汉字内码扩展规范。 其中\n GB是国标的首字母 K 是扩展的首字母  GBK的其他信息，我们不做太多说明，有兴趣的可以去维基百科查看\nGBK维基百科\nGBK的编码方式 GBK分为单字节和双字节编码，单字节编码兼容ASCII字符集。 这张图片是GBK的编码分区图。\n 首字节 0-128(不包括128)，都是单字节的编码区域 首字节 128-255，第二字节 0-64，这部分区域没有字符，如果出现在这个区域，会被解析为� 首字节 128-255，第二字节 64-255，这部分主要是中文符号。  根据上面的编码分区图，我们可以知道GBK是如何区分一个字节是是单字节编码，还是双字节编码的第一个字节，这个很重要，在下面乱码的解析中，我们会分析。\n 如果小于128，则表示是单字节编码 如果大于128，则表示是双字节编码  Unicode 因为世界上的国家有很多，使用的语言和文字也大相径庭，每个国家都有自己使用的字符集和编码，所以有必要使用一个统一的字符集来解决字符集分裂的问题。Unicode就是为了解决这个问题而诞生的。\nUnicode中，是为每种语言都分配了一个区域，并且可以说是涵盖了世界上的所有的字符。  比如Unicode中的前128个字符和ASCII中的字符位置保持一致。 比如中文在Unicode的位置是 4E00-9FFF (19968-40959)  Unicode字符列表\nUnicode和UCS UCS是Universal Multiple-Octet Coded Character Set的简称","title":"字符集和字符编码 "},{"content":"一、cron介绍  crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。 通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\n 我理解cron是一个表达式，用来表示一个任务的周期性执行时间。\n二、cron格式 2.1、完整格式 ┌─秒(0-59) | ┌─分鐘(0-59) | │ ┌─小時(0-23) | | │ ┌─日 day of month(1-31) | | | | ┌─月(1-12) | | | | | ┌─星期 day of week(0-7，0和7都表示星期日) | | | | | | ┌─年(可以省略不写) * * * * * * * 开始的时候我把cron的格式分为了两种，分别是Linux crontab中的格式和Java中使用的格式。后面想了想，觉得cron的格式应该只有一种，就是上面的这种包含 7个字段的格式。然后不同的cron实现对于cron格式的实现程度不同。\n比如Linux的crontab，它只能支持5个字段，不能支持秒和年\n2.2、crontab格式 ┌─分鐘（0 - 59） │ ┌─小時（0 - 23） | │ ┌─日 day of month(1-31) | | | ┌─月（1 - 12） | | | | ┌─星期 day of week(0-7，0和7都表示星期日) * * * * * linux-crontab-校验\n2.3、cron格式总结 因为在网上一直没有找到准确的官方的cron的定义，所以上面的都是我自己的理解。我认为cron这种很通用的表达式，它的定义应该不会太分裂\n三、day of week中数字的定义 在查看文档和测试的过程中发现，同样的一个表达式，会得出不同的执行结果，后来发现是因为对于day-of-week的定义大致分为两种\n3.1、crontab中的定义 在类Unix的系统中的crontab命令中，数字0和7都代表周日,然后1-6分别表示MON-SAT(周一到周六)；\n这里0和7都表示周日，是有一定的历史原因的，是为了兼容之前不同版本的Unix系统。\n This is a matter of portability. In early Unices, some versions of cron accepted 0 as Sunday, and some accepted 7 as Sunday \u0026ndash; this format is an attempt to be portable with both.\n Day of week {0-7} in crontab has 8 options, but we have only 7 days in a week\n3.2、Java中的定义 在Java的不同实现中,我找到了2个，分别是Spring的实现和Quartz的实现\n  Spring的CronSequenceGenerator和Linux保持一致；顺便说一下这个类是Spring中@Scheduled注解的默认cron解析类\n  Quartz的CronExpression的实现CronExpression和Linux不同，它不支持0，然后1-7分别是SUN-SAT(周日-周六)\n  3.3、解决办法 鉴于不同的实现中，对于day of week数字的定义的区别，最好的办法就是使用星期的简写来代替数字，例如SUN,MON,TUE等等，这样就能保证你的cron不管在哪个Java的cron实现中都能正确运行。\n四、cron每个字段支持的输入    Field Name Allowed Values Allowed Special Characters     Seconds 0-59 , - * /   Minutes 0-59 , - * /   Hours 0-23 , - * /   Day-of-month 1-31 , - * ? / L W   Month 1-12 or JAN-DEC , - * /   Day-of-Week 0-7 or SUN,MON,TUE,WED,THU,FRI,SAT , - * ? / L #   Year (Optional) empty, 1970-2199 , - * /    五、cron特殊字符说明 这里先说一下我的理解，对于cron中的特殊字符，应该是有一套比较统一的规则定义，只不过在在不同的cron的实现里，有的只选择实现了一部分的规则。\n就像Linux中的crontab命令，只实现了下面的几种基本特殊字符。\nJava的实现中，Quartz算是实现的功能比较全的，基本上完全实现了所有的特殊字符的功能。\n所以在我们写cron表达式的时候，一定要清楚，我们的表示是会用在什么地方，支持什么样的写法，像我工作中比较常用的就是在Spring中@Scheduled注解，和elastic-job创建定时任务（cron解析使用Quartz）\n5.1、基本特殊字符    字符 描述 举例 解释     , 表示几个会生效的值 1,2,3 in Minutes 表示在第1和第2和第3分钟 都会生效   - 表示生效的范围 1-10 in Minutes 表示在第1到第10分钟会生效   * 表示所有的值都会生效， * in Minutes 表示每分钟都会生效   / 表示增量，可以理解为每隔多长时间 0/30 in Minutes 表示第0分钟生效，然后每隔30分钟生效一次    5.2、? 字符说明  The \u0026lsquo;?\u0026rsquo; character is allowed for the day-of-month and day-of-week fields. It is used to specify \u0026lsquo;no specific value\u0026rsquo;. This is useful when you need to specify something in one of the two fields, but not the other.\n  ?号只能用在day-of-month和day-of-week字段中。通常用来表示为\u0026rsquo;没有指定的值'。当你需要在两个字段之一中指定某些内容而不是另一个字段时，这非常有用。\n 我们使用cron的初衷是想让这个任务定期的执行，比如每个月1日执行什么，或者每周1执行什么。当一个任务在每个月1日，执行的时候，我们通常不会要求它是星期几，同样每周1执行的任务，我们也不会关心当天是几月几号。也就是说，在极大多数的情况下，我们不需要这两个字段同时满足。\n所以说，通常情况下，我们在指定了这两个其中一个字段之后，会把另一个字段设置为'?'。\n或许有人说，我就要每个月1号、并且还必须得是星期一的0点0分0秒，它才能执行，当然我们也能实现(这种同时制定month和week的表达式，不是所有的都支持,比如Quartz就不支持week和month同时设置)\n0 0 0 1 * 1 接下来7次的执行时间 -------------------------- 2020-06-01 00:00:00 2021-02-01 00:00:00 2021-03-01 00:00:00 2021-11-01 00:00:00 2022-08-01 00:00:00 2023-05-01 00:00:00 2024-01-01 00:00:00 spring-cron-online\n那这个时间真的是你想要的吗？\n5.3、L 字符说明 L其实是LAST的简写，就是最后的意思，它可以用在 day-of-month和day-of-week字段中。 它在两个字段中的意思有一些不同\n day-of-month：直接使用L表示这个月的最后一天，如果是1月那就是31号，如果是平年的2月，那就是28号 day-of-month: 使用 L-3,表示这个月的倒数第3天 day-of-week：如果直接使用L,则表示星期六（是从周日开始的，所以周六是最后一天） day-of-week: MONL(为了避免数字造成的混淆直接使用字母)，表示这个月的最后一个周一  5.4、W 字符说明 W在这里代表的是WeekDay(工作日的意思)，它只能使用在day-of-month字段中。 在表达式的使用中，它的作用是指定在同一个月内，离指定日期最近的工作日。\n举例1\n0 0 0 15W * ? 这个表达式字面意思是，在离每个月15号最近的工作日的 0点0分0秒触发 1. 如果15号是 周一到周五中的某一天，那么就在当天触发 2. 如果15号是 周六，那么离周六最近的工作日就是周五(前一天)，那么就会在周五触发； 3. 如果15号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 这个有一个大前提就是，必须是同一个月内的。通过下面的例子来说明一下\n举例2\n0 0 0 1W * ? 这个表达式字面意思是，在离每个月1号最近的工作日的 0点0分0秒触发 1. 如果1号是 周一到周五中的某一天，那么就在当天触发（这个没问题） 2. 如果1号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 3. 如果1号是 周六，关键在这里，距离周六最近的工作日是周五(前一天，1号的前一天已经是上个月了)，但是因为大前提是必须是同一个月的，所以只能在后两天的周一触发 5.5、# 字符说明  The \u0026lsquo;#\u0026rsquo; character is allowed for the day-of-week field. This character is used to specify \u0026ldquo;the nth\u0026rdquo; XXX day of the month.\nIf the \u0026lsquo;#\u0026rsquo; character is used, there can only be one expression in the day-of-week field (\u0026ldquo;3#1,6#3\u0026rdquo; is not valid, since there are two expressions).\n # 号只能用在 day-of-week字段中，表示某个月的第几个星期几; 同时说明一下 #前面的是表示星期几，#后面的数字表示第几，还有如果day-of-week使用了#。\n如果day-of-week字段中出现了#,那么day-of-week中就只能有且只有这一种表达式。\n举例\n0 0 0 ? * MON#2 每个月的第二个星期一 0点0分0秒 六、常见cron 每个月的工作日上午9点0分0秒\n0 0 9 ? * MON-FRI 每个月的最后一个周一上午9点0分0秒\n0 0 9 ? * MONL 每个月的最后一个工作日上午9点0分0秒\n0 0 9 LW * ? 这里需要注意的就是 W必须要写在后面 在工作日每隔10分钟执行一次\n0 */10 * ? * MON-FRI 六、参考文章 Quartz-CronExpression\nquartz-cron-校验\nlinux-man-crontab\nlinux-easycron\ncron-wiki\n","permalink":"https://balvboy.github.io/blog/cron/","summary":"\u003ch1 id=\"一cron介绍\"\u003e一、cron介绍\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003ecrontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。\n通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"cron表达式 "},{"content":"微信公众号 ","permalink":"https://balvboy.github.io/wechat/","summary":"微信公众号 ","title":""},{"content":"","permalink":"https://balvboy.github.io/search/","summary":"search","title":"Search"}]