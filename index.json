[{"content":" 原码、补码和反码 原码、补码和反码是计算机中表示数字的几种方式，他们是为了达成不同的目的而被创建的。\n 我们根据数字的大小通常会使用不同的位数(8,16,32)来表示数字。下面的示例的话如果没有特殊说明，都使用8位的二进制来表示。\n 原码 True form\n计算规则 原码是人脑最容易理解和计算的表示方式。 表示规则是，使用最高位作为符号位，1表示负数，0表示正数，剩余的n-1位表示数字。\n1000 0001 = -1 0000 0001 = 1 1111 1111 = -127 0111 1111 = 127 表示范围 所以一个n位的原码二进制数表示的范围是 -($2^{n-1}$-1) 到 ($2^{n-1}$-1) 比如8位的范围是 -($2^{7}$-1) 到 ($2^{7}$-1) = -127 到 127 同理16和32位的也是这样。\n存在的问题 无法进行计算 原码存在的最大问题就是，计算机无法使用原码直接进行计算，就拿 1 + (-1) = 0 这个来说。在计算机中如果直接使用原码计算得到的结果是-2,和预期的结果并不一致。\n 1000 0001 + 0000 0001 ------------ 1000 0010 = -2 +0和-0的问题 通过原码的表示规则，我们得到一个+0和一个-0,这个明显不符合数学常识\n1000 0000 = -0 0000 0000 = +0 反码 ones' complement 反码的出现就是人们为了解决原码不能直接进行计算的问题的。\n计算规则 原码转反码 * 正数的反码是其本身,(正数的反码和其原码相同) * 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.\n反码转原码\n先看是不是负数，如果是负数除符号位外按位取反\n正数 0000 0001 = 1 负数 1000 0001[原] = -1 1111 1110[反] = -1 这时候我们再来计算 1 + (-1)\n 0000 0001[反] + 1111 1110[反] ------------ 1111 1111[反] = 1000 0000[原] = -0 所以反码的出现就解决的原码不能参与计算的问题。 但是+0和-0的问题还是没有解决。\n补码 补码又叫做 Two's Complement 补码就是上面的问题的解决方式。\n计算规则  正数的补码还是其本身,(正数的反码和其原码相同) 负数的补码:负数的补码则是将其对应正数按位取反再加1。或者说是负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)  转换过程\n0000 0001[原] = 0000 0001[补] = 1 1000 0001[原] = 1111 1111[补] = -1 计算过程 1. 对应的正数按位取反 1000 0001 (对应的正数)-\u0026gt; 0000 0001 (取反)-\u0026gt; 1111 1110 (加1)-\u0026gt; 1111 1111 补码解决运算问题 我们再来进行上面提到的 1 + (-1) 的操作,这次使用补码来计算\n 0000 0001 + 1111 1111 ------------ 10000 0000 我们看到结果得到是一个9位的二进制数，但是因为我们都是8位二进制数，所以在获取结果的时候会取低位的8位，忽略掉最高位的1，这样得到的结果就是 0000 0000，对应的就是0.\n负数的表示问题 十进制的数据符号有0、1、2、3、4、5、6、7、8、9,二进制有0、1，我们加入一个-负号对于人来说是很理所当然的事情，但是对于计算机来说并不是。 简单来说就是\n 一个数 减去一个负数，实际上应该是加上应该是加上这个数的真值(去掉了符号的值)。 一个数 加上一个负数，实际上应该是减去这个数的真值  这样的运算规则，会使得计算机运算电路的设计变得复杂很多。 所以最好的办法就是让计算机不要理会符号位，然后把减法转化为等价的加法；\n所以在这里就可以利用到补数可以把减法转化为加法的特性来解决上面的问题。\n重点来了\n拿8位二进制来说明，8位二进制可以表示 0-255共256个数字。 既然我们想要忽略掉符号位，那么就需要把这256个数字中的一部分，用来表示负数。 我们把这 256个数，已128为界分为2部分， [0 -\u0026gt; 127] 128 [129 -\u0026gt; 255] \n 0 就表示0， 1-127，表示本身， 129-255，表示 -127到-1。 128 表示 -128  为什么这么表示呢？ 首先只有一个0，所以我们就用 0来表示。\n然后我们用这个数对应的补数，表示和这个数绝对值相同的负数。\n 1表示 +1，1的补数是255，所以 255就用来表示 -1\n127表示 +127，127的补数是129，所以用129来表示 -127\n 这样当我们计算 7 - 1，就依赖补数的规则，完美的转换成了 7 + 255,然后忽略掉进位，依然还能得到正确的结果6\n 0000 0111 + 1111 1111 ------------ 忽略进位 1 0000 0110 =========\u0026gt; 0000 0110 = 6  抛去0之后，还剩下255个数，所以要么负数多一个，要么正数多一个。1到127 和-127到 -1是没有疑问的，多出来的这个数就是128。128这个数就比较特殊了，因为他的补数也是 128，所以其实这个数既可以表示+128，也可以表示-128。那么我们为什么人为规定让128来表示-128呢。那是因为让 128表示 -128我们正好可以得到一个便利，就是可以通过第一位是0还是1来分辨这个数是正数还是负数。\n我们通过二进制的分为来说明一下，就会比较明朗了\n1 127 0000 0001 到 0111 1111 表示 1 到 127 ---------------------------------------- 128 255 1000 0000 到 1111 1111 表示 -128到 -1 采用补码，虽然简化了计算机的运算，但是会导致一个不好的问题，就是无法让人们直接看出这个数的原码是多少，所以如果有这个便利能让人类直观的知道这个数是正数还是负数，也是好的。\n补码转原码 因为计算机中计算和存储都是使用的补码形式，所以在某些情况下的输出，会给我们造成一些误解。所以我们同时也需要掌握补码转原码的方式。\n因为根据上面的规则，我们可以知道虽然，补码计算的时候是忽略掉符号位的，但是我们依然可以使用补码的首位来，快速的判断这个补码对应的真实的数，是正数还是负数。\n 如果是正数，则不需要变 如果是负数，除去第一位其余各位取反，然后再整个数加1  比如计算补码 1111 1111，对应的原码\n 除符号位按位取反 1111 1111 ==========》 1000 0000 然后在加1 1000 0000 + 0000 0001 = 1000 0001 = -1  负数补码转原码再思考 首先我们已经明白，负数的补码，就是负数的绝对值的补数。\n 既 -1的补码就是 1的补数，就是 255\n 那现在反过来，我们现在有个补码 255(1111 1111),想要求出它对应的原码。\n我们先求出255所对应的补数 1(0000 0001)。这个1肯定就是他所对应的那个原码的绝对值。因为我们可以通过补码的首位来判断这个数的正负。所以我们这道这个数就是-1。而原码的规则就是通过首位来表示正负的，所以我们把首位在变成表示负数的1就得到了最终的原码 (1000 0001)。\n整个过程我们用算式来表述一下\n已知补码 x[补] = 255(1111 1111)，求对应的原码x[原] 1. 求x[补]的补数（一个数的补数，就是用模减去这个数） 1 0000 0000 1111 1111 - 1111 1111 - 1111 1111 ----------------- 等价于 -------------- + 1 = 0000 0001 0000 0001 0000 0000 2.把结果的符号位改为表示负数的1 =\u0026gt; 1000 0001  所以简单的来说就是，我们直接取这个补码本身所代表的无符号数的补数，然后转乘负数就可以了。 因为负数的补码和负数的绝对值是互为补数的。\n总结 补码就是采用一个数的补数，作为和这个数绝对值相同的负数的一种数值表示方式。 通过这种转换，我们可然去掉计算机的减法运算，简化计算电路的复杂度。\n可以这么认为，就是正式因为利用了补数的这个特性，所以把这种利用补数来表示负数的形式，称作补码。\n补码本身是没有符号位的，我们通过补码的首位来判断这个数的正负，只不过它恰好(有一部分也是出于人为的因素)满足这一个条件，这并不能算是补码的一个特性\n所以很多时候我们看到补码的时候会比较别扭，因为它和人们直接用原码计算，并且有正负概念的固有模式不一致。但是不可否认，这是最符合计算机的一种数字表达方式。那补码的可读性差，可能可以算作补码唯一的缺点了吧\n计算机中的补码 我们来看一段代码，这也是我想要了解补码的初衷\npublic static void main(String[] args) throws UnsupportedEncodingException { String str = \u0026#34;一\u0026#34;; byte[] bytes = str.getBytes(\u0026#34;utf-8\u0026#34;); for (byte b : bytes){ System.out.println(b); } } 这段代码最终的输出结果是\n-28 -72 -128 我们来分一下一下问什么会输出这样的结果。\n1.首先我们要获取汉字一的utf-8编码\n通过查询得知汉字一的unicode编码为\n 19968（十进制） 4E00 (16进制)\n  UTF-8编码为\n 14989440(十进制) E4B880(16进制) 00000000 11100100 10111000 10000000(二进制)  这里顺便说一下，utf-8是uncide的一种编码方式。作用是减少不必要的空间浪费\n2.把编码转成字节数组\nbyte[] bytes = str.getBytes(\u0026#34;utf-8\u0026#34;); 所以这段代码的操作就行，查询码表，得到一的UTF-8编码，然后忽略掉为0的高位，转换为字节数组\n[1110 0100] [1011 1000] [1000 0000] 3.输出字节 这里还涉及到一个问题，就是Java中的自动转型。所有的byte,short,char型的值将被提升为int型 所以这里打印的时候，是把每一个byte强转成int，然后输出的。\n因为计算机中存储和计算都是使用补码，所以会把字节，比如第一个字节[1110 0100],当做补码转换成int，然后在转为对应的十进制。 这里用我上面的补码转原码的规则转一下就ok了\n 除符号位按位取反 1110 0100 ========\u0026gt; 1001 1011 然后在加1 1001 1011 + 0000 0001 = 1001 1100 = -28 参考 补码计算\n补数到底是个什么玩意儿？从根儿上理解一下\nutf-8编码查询\n","permalink":"https://balvboy.github.io/blog/twoscomplement/","summary":"原码、补码和反码 原码、补码和反码是计算机中表示数字的几种方式，他们是为了达成不同的目的而被创建的。 我们根据数字的大小通常会使用不同的位数(8","title":"计算机基础-原码、反码、补码"},{"content":" Insert语句加锁分析 这里来单独分析一下 Insert 语句的加锁情况。\n前面提到了5种行锁 - 普通行锁 ：lock_mode X/S locks rec but not gap - 间隙锁 ：lock_mode X/S locks gap before rec - 邻间锁 ：lock_mode X/S - 插入意向锁 : Insert Intention Locks - 隐式锁\n其中和插入相关是后面两种 插入意向锁 和隐式锁\n插入意向锁 前面我们已经介绍了插入意向锁的概念。\n当一个事务想要向一个区间插入一条数据的时候，但是这个区间被另一个事务锁定了，这时候就需要插入一个插入意向锁。\n这时候如果有多个事务，想要向这个区间插入记录，那就会插入多个插入意向锁。\n插入意向锁分析 事务A执行\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where id \u0026gt;=214 for update; +-----+--------+------+------+------+ | id | number | age | sex | name | +-----+--------+------+------+------+ | 214 | NULL | NULL | NULL | NULL | +-----+--------+------+------+------+ 1 row in set (0.00 sec) 事务B执行,发现会被阻塞\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into user (id) values (215); 此时查看锁状态\n------------ TRANSACTIONS ------------ Trx id counter 6217 Purge done for trx\u0026#39;s n:o \u0026lt; 6214 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421847766411040, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421847766408520, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421847766407680, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421847766406840, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 6216, ACTIVE 5 sec inserting # 事务B产生的锁 mysql tables in use 1, locked 1 LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 20, OS thread handle 123145362980864, query id 3611 localhost 127.0.0.1 root update insert into user (id) values (215) # 事务B 已经等待下面的锁 5秒钟 ------- TRX HAS BEEN WAITING 5 SEC FOR THIS LOCK TO BE GRANTED: # 事务B 添加的 插入意向锁 RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6216 lock_mode X insert intention waiting Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; ------------------ # 事务B 添加的 独占意向锁 TABLE LOCK table `db_test`.`user` trx id 6216 lock mode IX RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6216 lock_mode X insert intention waiting Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; ---TRANSACTION 6214, ACTIVE 272 sec # 事务A 产生了3个锁结构 ，其中有2个行锁 3 lock struct(s), heap size 1136, 2 row lock(s) MySQL thread id 13, OS thread handle 123145362374656, query id 3612 localhost 127.0.0.1 root starting show engine innodb status Trx read view will not see trx with id \u0026gt;= 6214, sees \u0026lt; 6214 # 事务A 产生的独占意向锁 表锁 TABLE LOCK table `db_test`.`user` trx id 6214 lock mode IX # 事务A 产生的 普通行锁，锁住 id=214的主键索引 RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6214 lock_mode X locks rec but not gap Record lock, heap no 4 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000d6; asc ;; 1: len 6; hex 000000001841; asc A;; 2: len 7; hex 820000008e0110; asc ;; 3: SQL NULL; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; # 事务A 产生的next-key lock，锁住 从214 到最大值的区间 RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6214 lock_mode X Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; 隐式锁 在没有锁冲突的情况下，Insert操作是不加锁的，除了会加一个表级别的 独占意向锁。\n那么就会发生这种情况\n一个事务向表中插入了条记录，然后另一个事务\n 立即使用SELECT \u0026hellip; LOCK IN SHARE MODE语句读取这条事务，也就是在要获取这条记录的S锁，或者使用SELECT \u0026hellip; FOR UPDATE语句读取这条事务或者直接修改这条记录，也就是要获取这条。 记录的X锁，？ 立即修改这条记录，也就是要获取这条记录的X锁？  这中情况下，就会利用到隐式锁。之所以叫做隐式锁，那就是因为，在没有事务冲突的情况下，隐式锁可以认为是没有锁，当有事务冲突之后，隐式锁就会转化为显示锁。下面我们看一下这个转化的过程。\n隐式锁的转化 隐式锁的转化需要依赖 trx_id这个隐藏字段\n聚簇索引 对于聚簇索引记录来说，有一个trx_id隐藏列，该隐藏列记录着最后改动该记录的事务id。那么如果在当前事务A中新插入一条聚簇索引记录后，该记录的trx_id隐藏列代表的的就是当前事务的事务id。\n这是如果另一个事务B，想要对这条记录加锁，就会先看一下这条记录的trx_id,是否还在活跃列表中，如果还在活跃列表，那就表示Insert这条记录的事务还没有提交。\n那这时，想要加锁的事务B就会替事务A创建一个排他锁(isWaiting为false表示持有了锁)，然后给自己也创建一个锁结构(isWaiting为true表示等待锁)，然后进入等待状态\n二级索引 对于二级索引记录来说，本身并没有trx_id隐藏列， 但是在二级索引页面的Page Header部分有一个PAGE_MAX_TRX_ID属性，该属性代表对该页面做改动的最大的事务id，如 果PAGE_MAX_TRX_ID属性值小于当前最小的活跃事务id，那么 说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后回表找到它对应的聚簇索引记 录，然后再重复情景一的做法。\n隐式锁转化分析 事务A 首先我们在一个事务中 插入一条记录,然后查看锁状态\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; insert into user (id) values (225); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; show engine innodb status \\G 只有一个表级别的独占意向锁，没有任何的行锁\n---TRANSACTION 6217, ACTIVE 50 sec 1 lock struct(s), heap size 1136, 0 row lock(s), undo log entries 1 MySQL thread id 13, OS thread handle 123145362374656, query id 3618 localhost 127.0.0.1 root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 6217 lock mode IX 事务B ，尝试锁定这条记录所在的区间,\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select * from user where id = 225 for update; 发现会被阻塞，这是我们在事务A的窗口查看 锁状态\n# 事务B 一个锁结构 ---TRANSACTION 6218, ACTIVE 88 sec 1 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 20, OS thread handle 123145362980864, query id 3620 localhost 127.0.0.1 root TABLE LOCK table `db_test`.`user` trx id 6218 lock mode IX ---TRANSACTION 6217, ACTIVE 246 sec # 事务 A 现在持有了2个锁 2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 1 MySQL thread id 13, OS thread handle 123145362374656, query id 3621 localhost 127.0.0.1 root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 6217 lock mode IX RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6217 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000e1; asc ;; 1: len 6; hex 000000001849; asc I;; 2: len 7; hex 82000000910110; asc ;; 3: SQL NULL; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; 发现 6217事务，也就是 事务A，多持有了一个普通行锁，这个就是事务B替 事务A创建的锁。\n不过有一个问题是，并没有体现出来 事务B给自己创建的锁,我们上面的例子使用的数据库版本是 8.1.25\n下面我们在再使用5.x 版本测试一下\n---TRANSACTION 2331, ACTIVE 17 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 65, OS thread handle 22553189902080, query id 249 61.149.179.190 root statistics select * from user where id = 211 for update ------- TRX HAS BEEN WAITING 17 SEC FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 25 page no 3 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2331 lock_mode X locks rec but not gap waiting Record lock, heap no 13 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000d3; asc ;; 1: len 6; hex 00000000091a; asc ;; 2: len 7; hex b60000012a0110; asc * ;; 3: SQL NULL; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; ------------------ TABLE LOCK table `db_test`.`user` trx id 2331 lock mode IX # 事务B自己创建的锁结构，isWaiting 为true RECORD LOCKS space id 25 page no 3 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2331 lock_mode X locks rec but not gap waiting Record lock, heap no 13 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000d3; asc ;; 1: len 6; hex 00000000091a; asc ;; 2: len 7; hex b60000012a0110; asc * ;; 3: SQL NULL; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; # 事务B替事务A创建的锁 ---TRANSACTION 2330, ACTIVE 45 sec 2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 1 MySQL thread id 64, OS thread handle 22553181468416, query id 248 61.149.179.190 root Trx read view will not see trx with id \u0026gt;= 2330, sees \u0026lt; 2330 TABLE LOCK table `db_test`.`user` trx id 2330 lock mode IX RECORD LOCKS space id 25 page no 3 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2330 lock_mode X locks rec but not gap Record lock, heap no 13 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000d3; asc ;; 1: len 6; hex 00000000091a; asc ;; 2: len 7; hex b60000012a0110; asc * ;; 3: SQL NULL; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; 我们看到 5.x版本的MySQL和上面的描述比较一致\n 替事务A创建一个锁 然后在给自己创建一个锁  所以看来，MySQL的各个版本也是在对锁这部分在进行优化，但是基本的逻辑应该是没有变化的。\nInsert on duplicate key update加锁分析 begin; insert into user (id) values (214) ON DUPLICATE KEY UPDATE number = 214;2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 25, OS thread handle 123145362980864, query id 3710 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 6224 lock mode IX RECORD LOCKS space id 11 page no 4 n bits 88 index PRIMARY of table `db_test`.`user` trx id 6224 lock_mode X locks rec but not gap Record lock, heap no 19 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 800000d6; asc ;; 1: len 6; hex 00000000184e; asc N;; 2: len 7; hex 010000014c0af5; asc L ;; 3: len 4; hex 800000d6; asc ;; 4: SQL NULL; 5: SQL NULL; 6: SQL NULL; 当发生唯一键冲突的时候，Insert会加锁，加的锁和 执行Update一致\n参考 读 MySQL 源码再看 INSERT 加锁流程\n如何读懂 MySQL rw-lock 锁的统计信息\n","permalink":"https://balvboy.github.io/blog/mysql_insert_lock/","summary":"Insert语句加锁分析 这里来单独分析一下 Insert 语句的加锁情况。 前面提到了5种行锁 - 普通行锁 ：lock_mode X/S locks rec but not gap - 间隙锁 ：lock_","title":"MySQL Insert加锁分析"},{"content":" MySQL的存储引擎 MySQL有多种可选的存储引擎，常见的有\n InnoDB MyISAM Memory  其中InnoDB是最常用的存储引擎，并且也是目前MySQL的默认存储引擎。 其中最重要的原因就是，InnoDB支持事务，支持行级锁定。\n想了解更多的不同存储引擎的区别，可以查看 MySQL存储引擎的区别和比较\nMySQL的事务 事务是数据库执行过程中的一个逻辑单位，它可能由一条或多条数据库操作组成。\n开启事务 在MySQL中\n 对于单条SQL语句，数据库系统自动将其作为一个事务执行，并自动提交事务，这种事务被称为隐式事务。 对于多条操作，如果想要放到一个事务中，则需要手动开启事务，并提交\nbegin; UPDATE accounts SET balance = balance - 100 WHERE id = 1; UPDATE accounts SET balance = balance + 100 WHERE id = 2; commit;  事务的特性 ACID是我们非常熟悉的事务的特性，它指的是数据库管理系统（DBMS）在写入或更新资料的过程中，为保证事务（Transaction）是正确可靠的，所必须具备的四个特性:\n 原子性(Atomicity):  一个事务中的操作要么全部完成，要么全部不完成，不可分割\n 一致性(Consistency):  下面首先给出wiki中关于一致性行的定义\n 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等\n 但是我认为这个解释不够清晰，我个人更倾向于知乎如何理解数据库的一致性中的一个解释\n ACID里的AID都是数据库的特征,也就是依赖数据库的具体实现.而唯独这个C,实际上它依赖于应用层,也就是依赖于开发者.这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态.什么叫正确的状态呢?就是当前的状态满足预定的约束就叫做正确的状态.而事务具备ACID里C的特性是说通过事务的AID来保证我们的一致性.\n 既从一个正确的状态迁移到另一个正确的状态\n 隔离性(Isolation):  隔离性的原本意思是，保证事务之间的操作是互相不可见，也就是每个事务都是隔离开的。 但是实现最高的隔离性，性能很低，同时很多业务场景也并不需要最高的隔离性和一致性。 所以就提出了几种不同的隔离级别来适当的破坏一致性来提升性能与并行度。\n 持久性(Durability):  事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n关于事务的理解 同样还是在上面提到的那个知乎回答中如何理解数据库的一致性，提到了为什么会有事务的问题，我觉得挺对的。\n总结一下，意思大概是事务这个概念本身，并不是数据库天生就有的。而是伴随着应用开发出现的各种各样的问题，为了解决这样的问题，并简化应用程序的编程模型而逐渐产生，或者说被提炼出来的。\n对于这种概念性的知识确实比较容易搞偏，陷入不必要，所以我们打住，来看一下技术实现。\nInnoDB对事务特性的实现 可以说InnoDB中的锁、redo log、undo log、MVCC等机制，都是为了实现事务的特性而实现的。下面我们就来简单的分析一下他们都是如何实现的。\n原子性 MySQL原子性的保证–undo log\n原子性的概念是一个事务内的操作要么全执行，要么全不执行。为了解决这个问题，就有了事务回滚的操作。一旦事务执行过程中发生了异常，那么可以通过回滚，把数据回滚。\nundo log从字面意思就是撤销日志。负责撤销的日志。\n简单理解一下，就是undo log中存储的是和每条纪录相反的操作。比如\n 执行insert，undo log中就存储delete 执行delete，undo log中就存储insert 执行update，会记录一条相反的update  通过这样的方式，保证在事务中执行失败的时候，数据能够回滚。\n当然undo log的作用不仅于此，我们后面会继续分析。\n持久性 持久性保证的就是，一旦事务提交后，数据一定会保存下来，就算数据库发生错误也不会导致数据丢失。\n持久性是依赖 InnoDB的redo log 和 bin log来实现的。 下面我们分析一下MySQL存储一条数据到磁盘的可能方式。 1. 第一种就是每一次更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后在更新，整个过程IO成本，查找成本都很高 2. 第二种先写到内存中的一块区域也就是redo log，就是MySQL里面经常说到的WAL技术，WAL全称为Write-Ahead Logging，他的关键点就是先写日志，再写磁盘。等服务不太忙的时候再把数据写到磁盘。\n 执行器先找到引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行，如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎提交事务接口，引擎把刚刚写入的redo log改成提交状态，更新完成  参考MySQL原子性与持久性的保证\n隔离性 隔离性最简单的实现方式就是各个事务都串行执行，如果前面的事务还没有执行完毕，后面的事务就都等待。但是这样的实现方式很明显并发效率不高，并不适合在实际环境中使用。 为了解决上述问题，实现不同程度的并发控制，SQL的标准制定者提出了不同的隔离级别，其中最高级隔离级别就是序列化读，而在其他隔离级别中，由于事务是并发执行的，所以或多或少允许出现一些问题。\n 未提交读（read uncommitted）可能发生 脏读、不可重复读、幻读 提交读（read committed）可能发生 不可重复读、幻读 可重复读（repeatable read）可能发生 幻读 序列化读（serializable）没有问题  一致性 这个特性其实比较特殊，这个应该是事务的最终追求。所以也可以说是上面的三种特性的实现共同实现了一致性。\nMySQL中的锁 从锁的类型来分，可以分为\n 共享锁 Share Lock 排它锁 Exclusive Lock  从锁粒度来分可以分为\n 全局锁： 对整个数据库实例加锁，使用的不多  使用 flush tables with read lock加锁 使用 unlock tables解锁  表锁: 对整个表加锁 行锁: 对记录所在的索引加锁 页面锁: 页面锁接触不多，我们可以暂时忽略  还有几个比较特殊的表级锁\n AUTO-INC Locks 自增主键用到的锁 元数据锁(meta data lock) 处理增删改查和修改数据库结果之间的冲突 共享意向锁 排他意向锁  行锁从类型又有可以分为\n 普通行锁 (record lock) 间隙锁 (gap lock) 邻间锁 (next-key lock) 插入意向锁 (insert intention lock)  下面我们稍微来分析一下\n表锁 表锁，顾名思义直接锁定一张表，这个锁粒度比较大，但是优点是比较简单。\nMemory、MyISAM 引擎都只支持表锁。\nInnoDB在默认情况下不会使用普通的表锁，想要使用表锁的话需要使用lock table命令。\n我们发现锁表之后，右边插入操作被阻塞住了。\n接着我们使用下面命令查看一下锁状态，这个命令输出内容有很多，我们主要关注TRANSACTION部分\nshow engine innodb status\\G; 发现有一个表被锁定了。\n当我们执行解锁命令，右面的操作就完成了。\n表锁我们使用不多，所以不做过多了解，有兴趣的同学可以查看表锁命令，进行了解。\n意向锁 意向锁的作用很简单，就是为了平衡表锁和行锁之间的冲突。我们想一下这个场景\n 一个事务T1在表A中对某些记录加了独占行锁。 另一个事务T2，想要对表A添加表锁。  这时候T2怎么判断表中又没其他事务加了行锁呢？遍历所有的记录是一个方式，但是这样效率太慢了，所以就提出了意向锁的概念。\n 如果想要共享行锁，那么就现在表上添加一个共享意向锁IS，然后在行记录的索引上添加S锁 如果想要独占行锁，那么就现在表上添加一个独占意向锁IX，然后在行记录的索引上添加X锁  有了这个机制，上面的事务T2，就不需要遍历就能知道当前这个表中有记录被添加了独占锁，下面来操作一下\n 首先在一个事务中使用select * from user where id = 1 for update 给表中的一条记录添加独占锁 然后在另一个事务中尝试锁表，  结果发现锁表的这个操作被阻塞了。我们来看一下锁状态\n我们可以看到user表被添加了一个IX的意向锁。\n 接着我们提交事务 另一个事务中，获取表锁成功，说明在事务提交后，意向锁被释放了  接着我们测试一下共享行锁下的情况\n 首先我们使用 select * from user where id = 1 lock in share mode;给记录的索引添加共享行锁 接着分别使用 lock table user read 和 lock table user write 来分别尝试获取表级的读锁和写锁。  结果，在存在共享行锁的情况下，获取表级读锁可以成功，获取表级写锁会被阻塞。\n下面是各种类型表锁之间的兼容性\n    X IX S IS     X Conflict Conflict Conflict Conflict   IX Conflict Compatible Conflict Compatible   S Conflict Conflict Compatible Compatible   IS Conflict 1Compatible Compatible Compatible    AUTO-INC锁 顾名思义，AUTO-INC锁就是当表里有字段设置了自增之后，那么向表里插入数据时，就需要获得这个锁。AUTO-INC锁可以分为3中模式\n 传统模式(Traditonal) 连续模式(Consecutive) 交叉模式(Interleaved)  分别对应配置项 innodb_autoinc_lock_mode 的值0、1、2.\n 在MYSQL 5.1.22版本前，自增列使用AUTO_INC Locking方式来实现，即采用一种特殊的表锁机制来保证并发插入下自增操作依然是串行操作，为提高插入效率，该锁会在插入语句完成后立即释放，而不是插入语句所在事务提交时释放。(传统模式)  该设计并发性能太差，尤其在大批量数据在一条语句中插入时(INSERT SELECT ), 会导致该语句长时间持有这个“表锁”，从而阻塞其他事务的插入操作。  在MYSQL 5.1.22版本开始，InnoDB存储引使用一种轻量级互斥锁(Mutex)来控制自增列增长，并提供innodb_autoinc_lock_mode参数来控制。这种是5.1.22之后的默认插入模式。（连续模式）  在连续模式下，如果插入的数量是确定的(simple insert)，则使用轻量级互斥锁，因为只需要吧这次插入所需要的id，预留出来就好，不需要等待插入完成。 如果插入的数量不确定，比如select into xxx select * from xxx这种，则还需要使用自增锁  在MySQL8.0后，把默认插入模式修改为了2，也就是交叉模式。  在交叉模式中，所有insert语句都使用轻量级互斥锁。这是三种模式中并发度最高的，也是性能最好的。 但是这种模式有一个缺点，当多个insert语句并发的时候，会造成一个事务插入的id并不是连续的。因为 AUTO_INCREMENT 的值分配会在多个 INSERT 语句中来回交叉执行。   交叉模式的缺陷 要了解缺陷是什么，还得先了解一下 MySQL 的 Binlog。Binlog 一般用于 MySQL 的数据复制，通俗一点就是用于主从同步。在 MySQL 中 Binlog 的格式有 3 种，分别是：\n Statement 基于语句，只记录对数据做了修改的SQL语句，能够有效的减少binlog的数据量，提高读取、基于binlog重放的性能 Row 只记录被修改的行，所以Row记录的binlog日志量一般来说会比Statement格式要多。基于Row的binlog日志非常完整、清晰，记录了所有数据的变动，但是缺点是可能会非常多，例如一条update语句，有可能是所有的数据都有修改；再例如alter table之类的，修改了某个字段，同样的每条记录都有改动。 Mixed Statement和Row的结合，怎么个结合法呢。例如像alter table之类的对表结构的修改，采用Statement格式。其余的对数据的修改例如update和delete采用Row格式进行记录。  如果 Binlog 采用的格式为 Statement ，那么 MySQL 的主从同步实际上同步的就是一条一条的 SQL 语句。如果此时我们采用了交叉模式，那么并发情况下 INSERT 语句的执行顺序就无法得到保障，将会导致主从之间同行的数据主键 ID 不同。而这对主从同步来说是灾难性的。\n所以说如果想要提高插入性能，并且保证主从数据一致，那么可以使用 交叉模式+Row格式的Binlog。\n深入剖析 MySQL 自增锁\n元数据锁(MDL) 元数据锁的作用就是，防止在事务在进行增删改查的时候，另一个事务对表结构进行修改，所造成的问题。\n在 MySQL 5.5 之后加入了MDL，当事务对一个表做增删改查操作的时候，会加MDL读锁，当对表做结构变更操作的时候，加了MDL写锁。\n所有当有事务在进行增删改查的时候，修改表结构的语句会被阻塞。\n我们看到，当一个事务正在执行查询的时候，哪怕是没有加锁的正常查询，也会阻塞修改表结构的语句。\n我们看到，当事务提交之后，DDL语句也执行成功了。\n那么如果我们是先执行DDL语句呢，那么在事务提交之前会阻塞查询吗？\n这次我们先执行的DDL语句，然后并没有提交，然后在另一个事务中执行的查询操作，然后并没有阻塞,这也就说明，MDL写锁是在DDL语句执行完就释放了。\nMySQL 全局锁和表锁是什么\n行锁 行锁的种类 MySQL中为了实现不同的功能定义了多种行锁\n 普通行锁 ：lock_mode X/S locks rec but not gap 间隙锁 ：lock_mode X/S locks gap before rec 邻间锁 ：lock_mode X/S 插入意向锁 : Insert Intention Locks 隐式锁  普通行锁 普通行锁仅仅把一条记录锁锁住。\n普通行锁也可以分为\n S型 共享锁 X型 独占锁  当一个事务获取了一条记录的S型普通行锁后，其他事务也可以继续获取该记录的S型普通行锁，但不可以继续获取X型普通行锁； 当一个事务获取了一条记录的X型普通行锁后，其他事务既不可以继续获取该记录的S型普通行锁，也不可以继续获取X型普通行锁；\n间隙锁 Gap Lock  Gap locks in InnoDB are “purely inhibitive”, which means that their only purpose is to prevent other transactions from inserting to the gap\nInnoDB 中的间隙锁是“纯粹的抑制性”，这意味着它们的唯一目的是防止其他事务插入间隙\n MySQL中给Gap Lock的命名是：locks gap before rec，也就是锁住记录之前的间隙。\n需要注意的是，这个的之前，是指的指定索引顺序的之前之后，而不是表中记录的顺序。如果我们使用的主键索引，那么它的顺序会和表中数据一致，如果使用的是二级索引，那就不一定了。\n间隙锁锁的不是记录，而是记录和记录之间的间隙。举例来说明一下：\n现在user表有2条记录\n   id number age sex     1 1 18 1   5 5 17 0    我们现在给id=5的记录添加间隙锁，那么就会锁住id=5的记录和他前一条记录之前的间隙，也就是(1-5)这个区间(暂时不考虑开闭区间的问题)。 如果有事务向id(1,5)在这个区间内插入记录，那么将会阻塞。\n那么问题来了，如果我想锁住第一条记录之前的间隙，和最后一条记录之后的间隙那改怎么办呢？\n这时候就需要用到数据页中的两条伪记录\n Infimum记录，表示该页面中最小的记录。 给 id =1 加间隙锁，会锁住(-∞,1) Supremum记录，表示该页面中最大的记录。给 Supremum 加间隙锁，会锁住(5,+∞)  邻间锁 Next-Key Locks  A next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record.\nnext-key 锁是索引记录上的记录锁和索引记录之前的间隙上的间隙锁的组合。\n 所以邻间锁既会锁住记录，也会锁住这条记录和前面一条记录之间的间隙。(所以叫邻间锁，相邻的间隙的意思)。\n By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 15.7.4, “Phantom Rows”).\n默认情况下，InnoDB 在 REPEATABLE READ 事务隔离级别下运行。在这种情况下，InnoDB 使用 next-key 锁进行搜索和索引扫描，从而防止幻读。\n 邻间锁就可以理解为普通行锁和间隙锁的结合，既能锁住某一行，也能锁住记录之前的间隙。\n插入意向锁 一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了间隙锁，如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交。 但是设计InnoDB的大叔规定事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。\n所以插入意向锁的意思就是，有一个事务有意向往一个区间中插入记录，但是这个区间被其他事务锁定了，所以只能阻塞。\n这个我们在后面单独分析Insert语句的加锁情况时会单独分析\n隔离级别对行锁的影响 行锁和数据库使用的隔离界别有很大的关系\n 在读已提交下  只有普通记录锁这一种  在可重复读下有  普通记录锁 间隙锁 邻间锁 插入意向锁   RC隔离级别下，只能锁住某一行记录，但是不是锁住记录之间的间隙，所以不能防止幻读。\n修改隔离级别 MySQL 5.x版本\n-- 查看全局、会话隔离级别 select @@global.tx_isolation,@@tx_isolation; -- 设置会话隔离级别 set session transaction isolation level read committed; -- 设置全局隔离级别 set global transaction isolation level read committed; MySQL-8.0.3版本以后\n在MySQL 8.0.3 中，tx_isolation 变量被 transaction_isolation 变量替换了。\n/**查看当前会话级别**/ SELECT @@global.transaction_isolation,@@session.transaction_isolation; /**修改当前会话隔离级别**/ set session transaction isolation level repeatable read; 不同隔离级别下的加锁情况 下面我们通过例子来说明一下，我们分别在隔离级别RR和RC下都执行下面的SQL,然后使用show engine innodb status\\G查看锁状态。\nbegin; select * from user where age = 10 for update; 可重复读 我们看到这里出现了3种行锁类型\n读已提交 我们看到只有普通行锁一种锁类型\n加锁情况分析 因为读已提交级别下的几所情况比较简单，只会给查询出的记录加普通行锁。 所以我们下面的分析中，都会在可重复读级别下进行。\n开启MySQL锁监控 在分析之前，我们先解决一个问题。 有的同学可能也知道show engine innodb status这个命令，但是执行之后会发现，并没有输出这么多的锁信息。 这是因为innodb_status_output_locks 这个参数导致的。默认情况下是关闭的。我们需要打开它就可以看到详细的锁信息了。\nSET GLOBAL innodb_status_output_locks=ON; show engine innodb status分析 下面我们通过一个针对二级索引加锁的SQL来说明一下\n/** 查询一个二级索引 **/ mysql\u0026gt; begin ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where age = 15 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 15 | 15 | 15 | 1 | NULL | | 25 | 25 | 15 | 0 | NULL | +----+--------+------+------+------+ 2 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G 下面我们来逐行分析一下 TRANSACTION 部分\nTRANSACTIONS Trx id counter 1906 # - 下一个事务的id为1906 Purge done for trx\u0026#39;s n:o \u0026lt; 1900 undo n:o \u0026lt; 0 state: running but idle # Purge线程已经将trxid小于1900的事务都purge了，目前purge线程的状态为idle  History list length 0 # undo中未被清除的事务数量，如果这个值非常大，说明系统来不及回收undo，需要人工介入了。 LIST OF TRANSACTIONS FOR EACH SESSION: # 所有当前正在活跃的事务列表 ---TRANSACTION 422179967867392, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 422179967866552, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 1905, ACTIVE 14227 sec # 当前事务ID为 1905，活跃了 14227秒 4 lock struct(s), heap size 1136, 5 row lock(s) # 产生了4个锁对象结构，占用内存大小1136字节，5条记录被锁住 MySQL thread id 42, OS thread handle 123145566167040, query id 3222 localhost root starting show engine innodb status Trx read view will not see trx with id \u0026gt;= 1905, sees \u0026lt; 1905 # mvvc read view可见性，这个事务的read view 将不会看到事务id大于 1905的事务造成的变化，只能看到小于1905的 TABLE LOCK table `db_test`.`user` trx id 1905 lock mode IX # 在user表上面有一个表锁，这个锁的模式为IX（排他意向锁）  RECORD LOCKS space id 11 page no 6 n bits 80 index idx_age of table `db_test`.`user` trx id 1905 lock_mode X # 在space id=11（a表的表空间），page no=6的页上，对表user上的idx_age索引加了记录锁，锁模式为：lock_mode X 也就是邻间锁 next-key lock # 该页上面的位图锁占有80bits  Record lock, heap no 8 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 # heap no 8 的记录被锁住了  0: len 4; hex 8000000f; asc ;; # 这是第一条记录的二级索引，15被锁住 # 因为 next-key lock，所以会锁住记录本身，和它与上一条记录之间的间隙 # 所以这里锁定的是 (10,15] 1: len 4; hex 8000000f; asc ;; # 二级索引指向的主键是15，所以主键值15也会被锁住 Record lock, heap no 9 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 # heap no 9 的记录被锁住了，这是被锁住的第二条二级索引 0: len 4; hex 8000000f; asc ;; # 这是是第二条记录的二级索引，同样是15 1: len 4; hex 80000019; asc ;; # 二级索引指向的主键是25，所以主键25也会被锁住 RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 1905 lock_mode X locks rec but not gap # 在space id=11（a表的表空间），page no=4的页上，对表user上的 primary(主键)索引加了记录锁，锁模式为：lock_mode X locks rec but not gap也就是普通行锁 # 因为上面两条记录的二级所以被锁住，所以对应的他们的主键索引也会被锁住 Record lock, heap no 8 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 被锁住的主键为 15，长度为4 1: len 6; hex 0000000006e9; asc ;; # 该字段为6个字节的事务id，这个id表示最近一次被更新的事务id，6e9十进制为 1769，也就是这条记录最后一次是被1769这个事务修改的 2: len 7; hex 81000000c80137; asc 7;; # 这个是隐藏字段，为7个字节的回滚指针，用于mvcc 3: len 4; hex 8000000f; asc ;; # 这个是此记录的第2个字段 number，值为15，长度为4 4: len 4; hex 8000000f; asc ;; # 这个是此记录的第3个字段 age，值为15，长度为4 5: len 1; hex 81; asc ;; # 这个是此记录的第4个字段 sex，值为1，长度为1 6: SQL NULL; # 这个是此记录的第5个字段 name，为null Record lock, heap no 10 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 # 这个是第二条记录的主键，同样也被锁住 0: len 4; hex 80000019; asc ;; # 被锁住的主键为 25，长度为4 1: len 6; hex 000000000700; asc ;; # 次记录最后一次被修改的事务id 2: len 7; hex 82000000d00110; asc ;; # 回滚指针 3: len 4; hex 80000019; asc ;; # 这个是此记录的第2个字段 number，值为25，长度为4 4: len 4; hex 8000000f; asc ;; # 这个是此记录的第3个字段 age，值为15，长度为4 5: len 1; hex 80; asc ;; # 这个是此记录的第4个字段 sex，值为1，长度为1 6: SQL NULL; # 这个是此记录的第5个字段 name，为null RECORD LOCKS space id 11 page no 6 n bits 80 index idx_age of table `db_test`.`user` trx id 1905 lock_mode X locks gap before rec # # 在space id=11（a表的表空间），page no=6的页上，对表user上的 idx_age索引加了记录锁，锁模式为：lock_mode X locks gap before rec也就是间隙锁 Record lock, heap no 10 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000014; asc ;; # 这是对应记录的二级索引,为20, # 这里锁住的是20这个索引，和它上一个索引(也就是15)之间的间隙 # 所以这里的意思是锁住二级索引 idx_age (15,20)的这个区间，注意这个间隙锁，是不包括记录本身的 1: len 4; hex 80000014; asc ;; # 这是二级索引锁对应的主键,同样也为20 所以根据上面的情况分析，我们得出最终锁定的区间是\n idx_age 索引  (10,15] 邻间锁 (15,20) 间隙锁  主键索引  [15] 普通行锁 [25] 普通行锁   查询主键索引 主键等值查询 select * from user where id = 1 for update; /** in 也算作等值查询 **/ select * from user where id in (1,2,,3) for update; 这种是最简单一种情况，主键等值查询，会给查出记录的主键加普通行锁。\n主键范围查询 mysql\u0026gt; begin; mysql\u0026gt; select * from user where id \u0026lt; 10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 1 | 1 | 1 | 0 | NULL | | 3 | 3 | 3 | 1 | NULL | | 4 | 4 | 4 | 1 | NULL | | 5 | 5 | 5 | 1 | NULL | | 7 | 7 | 4 | 1 | NULL | +----+--------+------+------+------+ 5 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G3 lock struct(s), heap size 1136, 6 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3298 localhost root starting show engine innodb status Trx read view will not see trx with id \u0026gt;= 2008, sees \u0026lt; 2008 TABLE LOCK table `db_test`.`user` trx id 2008 lock mode IX # 首先是表上的 排他意向锁 RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2008 lock_mode X # 然后是主键上的邻间锁 Record lock, heap no 2 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000001; asc ;; # 对主键为1的索引加next-key lock，锁住的范围是 主键为1记录和上一条记录之间的间隙，和1这条记录本身。因为1之前没有记录了， # 所以锁住范围是 (-∞,1]。 # 这里因为1之前没有记录了，所以使用的数据页中一条虚拟的记录:Infimum，用来表示负无穷 1: len 6; hex 00000000073a; asc :;; # 最近更新的事务id 2: len 7; hex 01000000f00c66; asc f;; # 回滚指针 3: len 4; hex 80000001; asc ;; 4: len 4; hex 80000001; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; Record lock, heap no 3 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000003; asc ;; # 对主键为3的索引添加 next-key lock # 锁住的范围为(1,3] 1: len 6; hex 0000000006fc; asc ;; 2: len 7; hex 82000000ce0110; asc ;; 3: len 4; hex 80000003; asc ;; 4: len 4; hex 80000003; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 4 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000004; asc ;; # 对主键为4的索引添加 next-key lock # 锁住的范围为(3,4] 1: len 6; hex 0000000006f3; asc ;; 2: len 7; hex 81000000cb0110; asc ;; 3: len 4; hex 80000004; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 5 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000005; asc ;; # 对主键为5的索引添加 next-key lock # 锁住的范围为(4,5] 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8011d; asc ;; 3: len 4; hex 80000005; asc ;; 4: len 4; hex 80000005; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 6 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000007; asc ;; # 对主键为7的索引添加 next-key lock # 锁住的范围为(5,7] 1: len 6; hex 0000000006f4; asc ;; 2: len 7; hex 82000000cb0110; asc ;; 3: len 4; hex 80000007; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2008 lock_mode X locks gap before rec # 这里又对主键，添加了一个 gap lock Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; # 对主键为10的索引添加 gap lock # 锁住的范围是 (7,10) 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8012a; asc *;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; 综上，我们可以得出针对 select * from user where id \u0026lt; 10 for update;这个语句，锁住的区间是\n (-∞,1] (1,3] (3,4] (4,5] (5,7] (7,10)  其中 [1,3,4,5,7]都是sql查询出来的主键，所以我们大概可以得出一个结论就是\n 主键范围查询，会锁住查询出来的主键之间的间隙，以及查询出来的记录 另外还会锁住查询出来的最小的记录和上一条记录的间隙，以及最大的记录和下一条记录的间隙。  如果没有上一小记录，就是到负无穷 如果没有下一条，就是到正无穷   下面我们来验证一下\nmysql\u0026gt; begin; mysql\u0026gt; select * from user where id \u0026gt;7 and id \u0026lt; 20 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 10 | 10 | 10 | 1 | NULL | | 15 | 15 | 15 | 1 | NULL | +----+--------+------+------+------+ 根据上面的结论可以得出，最终锁定的区间是\n （7,10] (10,15] (15,20)  查后我们查看锁状态\n3 lock struct(s), heap size 1136, 3 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3358 localhost root starting show engine innodb status Trx read view will not see trx with id \u0026gt;= 2009, sees \u0026lt; 2009 TABLE LOCK table `db_test`.`user` trx id 2009 lock mode IX RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2009 lock_mode X # 首先是 next-key lock Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; # 主键10 添加 next-key lock # 区间为(7,10] 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8012a; asc *;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 8 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 主键15 添加 next-key lock # 区间为(10,15] 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80137; asc 7;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2009 lock_mode X locks gap before rec # 然后是 间隙锁 Record lock, heap no 9 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000014; asc ;; # 主键20 添加间隙锁 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80144; asc D;; 3: len 4; hex 80000014; asc ;; 4: len 4; hex 80000014; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; ok 全中！说明这个结论是符合的。\n查询唯一索引 唯一索引的等值查询 mysql\u0026gt; begin; Query OK, 0 rows affected (0.17 sec) mysql\u0026gt; select * from user where number = 10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 10 | 10 | 10 | 1 | NULL | +----+--------+------+------+------+ 1 row in set (0.03 sec) mysql\u0026gt; show engine innodb status\\G3 lock struct(s), heap size 1136, 2 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3362 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 2010 lock mode IX # 表上加一项排它锁 RECORD LOCKS space id 11 page no 5 n bits 80 index uk_number of table `db_test`.`user` trx id 2010 lock_mode X locks rec but not gap # 在唯一索引上添加 普通记录锁 Record lock, heap no 7 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; # 唯一索引 1: len 4; hex 8000000a; asc ;; # 唯一索引，对应的主键索引 RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2010 lock_mode X locks rec but not gap # 在主键上添加 普通记录锁 Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8012a; asc *;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; 我们看到唯一索引的等值查询和主键索引和相似，都是对记录所在的索引添加普通记录锁。 只不过会多添加一个对唯一索引的记录锁。\n通过这里我们可以发现，当我们使用不同的索引进行查询的时候，虽然查询的记录有可能是同一条，但是加锁情况是不尽相同的。原因就是InnoDB的锁时加载索引上，而不是记录上的。\n唯一索引的范围查询 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where number \u0026gt; 10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 15 | 15 | 15 | 1 | NULL | | 20 | 20 | 20 | 1 | NULL | | 25 | 25 | 15 | 0 | NULL | +----+--------+------+------+------+ 3 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G 在查看锁状态之前我们先做一个猜测\n 既然唯一索引的等值查询，是和主键基本类似，只是多加了一个对唯一索引的锁 那么范围查询会不会也是一样呢，只是在主键的基础上，添加对唯一索引一样的逻辑呢？  下面我们来验证一下\n3 lock struct(s), heap size 1136, 7 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3371 localhost root starting show engine innodb status Trx read view will not see trx with id \u0026gt;= 2012, sees \u0026lt; 2012 TABLE LOCK table `db_test`.`user` trx id 2012 lock mode IX # 表上添加意向排他锁 RECORD LOCKS space id 11 page no 5 n bits 80 index uk_number of table `db_test`.`user` trx id 2012 lock_mode X #在uk_number 上添加 next-key lock Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; # supremum 是数据页中虚拟的最大值,一定会大于所有记录的索引值，给这个索引值添加 next-key lock # 表示锁上的区间为查询出来的记录中索引最大值，到正无穷，也就是(25,+∞) Record lock, heap no 8 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 给查询出来的记录的唯一索引加锁，唯一索引为 15 # 范围是 (10,15] 1: len 4; hex 8000000f; asc ;; Record lock, heap no 9 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000014; asc ;; # 给查询出来的记录的唯一索引加锁，唯一索引为 20 # 范围是 (15,20] 1: len 4; hex 80000014; asc ;; Record lock, heap no 10 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000019; asc ;; # 给查询出来的记录的唯一索引加锁，唯一索引为 25 # 范围是 (20,25] 1: len 4; hex 80000019; asc ;; RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2012 lock_mode X locks rec but not gap # 给查询出来的对应记录的主键加锁，注意这里添加是不是 next-key Lock了，而是普通的记录锁了 Record lock, heap no 8 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 给值15的主键索引加锁 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80137; asc 7;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 9 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000014; asc ;; # 给值20的主键索引加锁 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80144; asc D;; 3: len 4; hex 80000014; asc ;; 4: len 4; hex 80000014; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 10 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000019; asc ;; # 给值25的主键索引加锁 1: len 6; hex 000000000700; asc ;; 2: len 7; hex 82000000d00110; asc ;; 3: len 4; hex 80000019; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; ok，现在结论出来了，select * from user where number \u0026gt; 10 for update的加锁结果如下\n 唯一索引  (10,15] (15,20] (20,25] (25,+∞]  主键索引  [15] [20] [25]   和我们刚刚预测的有些许不同\n 唯一索引确实是按照刚才的逻辑添加的锁。  但又不是完全是，下面我们用另一个sql再测试一下  主键只是对查询出来的那些记录的主键，添加了普通记录锁。  在一次测试，这次我们使用和上面主键查询一样的范围\nmysql\u0026gt; begin; mysql\u0026gt; select * from user where number \u0026lt; 10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 1 | 1 | 1 | 0 | NULL | | 3 | 3 | 3 | 1 | NULL | | 4 | 4 | 4 | 1 | NULL | | 5 | 5 | 5 | 1 | NULL | | 7 | 7 | 4 | 1 | NULL | +----+--------+------+------+------+ 5 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G 锁状态如下：\n3 lock struct(s), heap size 1136, 11 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3386 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 2015 lock mode IX RECORD LOCKS space id 11 page no 5 n bits 80 index uk_number of table `db_test`.`user` trx id 2015 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000001; asc ;; 1: len 4; hex 80000001; asc ;; Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000003; asc ;; 1: len 4; hex 80000003; asc ;; Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000004; asc ;; 1: len 4; hex 80000004; asc ;; Record lock, heap no 5 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 4; hex 80000005; asc ;; Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000007; asc ;; 1: len 4; hex 80000007; asc ;; Record lock, heap no 7 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 4; hex 8000000a; asc ;; RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2015 lock_mode X locks rec but not gap Record lock, heap no 2 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000001; asc ;; 1: len 6; hex 00000000073a; asc :;; 2: len 7; hex 01000000f00c66; asc f;; 3: len 4; hex 80000001; asc ;; 4: len 4; hex 80000001; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; Record lock, heap no 3 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000003; asc ;; 1: len 6; hex 0000000006fc; asc ;; 2: len 7; hex 82000000ce0110; asc ;; 3: len 4; hex 80000003; asc ;; 4: len 4; hex 80000003; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 4 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000004; asc ;; 1: len 6; hex 0000000006f3; asc ;; 2: len 7; hex 81000000cb0110; asc ;; 3: len 4; hex 80000004; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 5 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8011d; asc ;; 3: len 4; hex 80000005; asc ;; 4: len 4; hex 80000005; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 6 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000007; asc ;; 1: len 6; hex 0000000006f4; asc ;; 2: len 7; hex 82000000cb0110; asc ;; 3: len 4; hex 80000007; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; 这里的大部分和主键范围查询是一致的。\n唯一的不同就是针对最后一条唯一索引，并没有使用 gap lock\n主键范围查询针对最后一条记录是一个 间隙锁\nRECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2008 lock_mode X locks gap before rec # 这里又对主键，添加了一个 gap lock Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; # 对主键为10的索引添加 gap lock # 锁住的范围是 (7,10) 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8012a; asc *;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; 唯一索引是这样的，是一个next-key lock\nRECORD LOCKS space id 11 page no 5 n bits 80 index uk_number of table `db_test`.`user` trx id 2015 lock_mode X Record lock, heap no 7 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 4; hex 8000000a; asc ;; 简单来说就是 主键查询和 唯一索引查出来的记录都是 [1,3,4,5,7]。id为7点下一条也同样都是 10。 只不过，针对 10这条记录的索引\n 主键加的是一个 gap lock，不包括 10这条记录 唯一索引，假的是 next-key lock，包括10这条记录。 也就是使用唯一索引和主键索引当查询出的记录一致的情况下，唯一索引会比主键的锁范围大一点。  所以唯一索引范围查询的结论需要更新一下\n 对查询出来的记录的唯一索引，添加next-key lock，也就是锁住记录，和上一条记录值之间的间隙 对查询出记录中唯一索引最大的，下一个索引，添加next-key lock，  比如这次查询出来的记录中最大的是7，那么对7的下一个10（索引顺序，非记录顺序），添加 next-key lock 也就(7,10],这里虽然没有查出来10，但是也把是10锁住。  对查询出来记录的主键，添加普通记录锁  我们先看唯一索引的操作，发现右边的左右被阻塞了。\n我们再看针对主键的操作，发现右边的操作没有被阻塞。\n查询二级索引 二级索引的等值查询 这个可以直接参考show-engine-innodb-status分析。我们这里总结一下结论\n比如使用idx_age 查询的\n 给查询出来记录的idx_age索引添加next-key lock  也就是会锁住该条记录的二级索引 和这个二级索引，和它上一个二级索引之间的间隙(这个上一条的概念，不是记录中的上一条，而是在索引结构中的上一个索引) 这个我觉得是可以理解的，因为记录的顺序是和聚簇索引保持一致的，而一个表中只会有一个聚簇索引，那就是主键。所以二级索引的顺序必然和记录顺序不一致。 而innodb的索引是加在索引上的，所以在对二级索引加锁的时候，必然要按照二级索引的顺序来处理。  对查询出记录中索引值最大的，下一个索引，添加gap lock  比如样例中，查出来记录的索引最大为15，它的下一个索引为20 也就是(15,20)  给查询出来记录的主键索引，添加普通记录锁  二级索引使用范围查询 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where age \u0026gt;10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 15 | 15 | 15 | 1 | NULL | | 25 | 25 | 15 | 0 | NULL | | 20 | 20 | 20 | 1 | NULL | +----+--------+------+------+------+ 3 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G 在查看之前我们还是结合着上面唯一索引范围查询的处理逻辑，预测一下\n 对于查询出来记录的二级索引，添加next-key lock 对于查出来记录中索引值最大的，的下一条索引，同样添加 next-key lock 针对主键索引，只会对查询出来的记录加普通行锁  来验证一下\n3 lock struct(s), heap size 1136, 7 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3377 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 2013 lock mode IX # 表上添加排他意向锁 RECORD LOCKS space id 11 page no 6 n bits 80 index idx_age of table `db_test`.`user` trx id 2013 lock_mode X # 给idx_age 添加 next-key lock Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; # 和上面唯一索引一样的逻辑，锁住记录中age最大值，到正无穷的区间 # (20,+∞) Record lock, heap no 8 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 给idx_age 为15 的索引 添加 next-key lock # 锁住的区间是 (10,15] 1: len 4; hex 8000000f; asc ;; Record lock, heap no 9 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; # 给另一个idx_age 为15 的索引 添加 next-key lock # 虽然索引值都是15，但是毕竟是2个索引，所以都要加锁 # 锁住的区间是 (15,15] 1: len 4; hex 80000019; asc ;; Record lock, heap no 10 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 80000014; asc ;; # 给idx_age 为20 的索引 添加 next-key lock # 锁住的区间是 (15,20] 1: len 4; hex 80000014; asc ;; RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2013 lock_mode X locks rec but not gap # 给主键添加普通行锁，下面就不一一写了，参照上面的即可 Record lock, heap no 8 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80137; asc 7;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 9 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80144; asc D;; 3: len 4; hex 80000014; asc ;; 4: len 4; hex 80000014; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 10 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000019; asc ;; 1: len 6; hex 000000000700; asc ;; 2: len 7; hex 82000000d00110; asc ;; 3: len 4; hex 80000019; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; 首先我们看到，行锁中只有两类，next-key lock 和 普通行锁 下面关注看 next-key lock\n 首先查询出来的3条记录的索引全部被加上了next-key lock 没有问题  下面我们来看猜测规则的第二条，给记录中索引值最大的下一条索引，添加next-key lock。\n记录中二级索引最大的是20，在user表中，已经没有其他记录的idx_age索引比它更大了，InnoDB给数据页中的最大虚拟记录的索引添加了 next-key lock。\nRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; ok，这样说明我们猜测的结论还是正确的\n 对于查询出来记录的二级索引，添加next-key lock 对于查出来记录中索引值最大的，的下一条索引，同样添加 next-key lock  如果没有下一条索引了，则给supremum添加 next-key lock  针对主键索引，只会对查询出来的记录加普通行锁  不使用索引进行查询 begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from user where sex = 1 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 3 | 3 | 3 | 1 | NULL | | 4 | 4 | 4 | 1 | NULL | | 5 | 5 | 5 | 1 | NULL | | 7 | 7 | 4 | 1 | NULL | | 10 | 10 | 10 | 1 | NULL | | 15 | 15 | 15 | 1 | NULL | | 20 | 20 | 20 | 1 | NULL | +----+--------+------+------+------+ 7 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G2 lock struct(s), heap size 1136, 10 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3427 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 2023 lock mode IX # 排他意向锁 RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2023 lock_mode X # 给主键添加 next-key lock Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; # 给最大值添加 next-key lock Record lock, heap no 2 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000001; asc ;; 1: len 6; hex 00000000073a; asc :;; 2: len 7; hex 01000000f00c66; asc f;; 3: len 4; hex 80000001; asc ;; 4: len 4; hex 80000001; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; Record lock, heap no 3 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000003; asc ;; 1: len 6; hex 0000000006fc; asc ;; 2: len 7; hex 82000000ce0110; asc ;; 3: len 4; hex 80000003; asc ;; 4: len 4; hex 80000003; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 4 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000004; asc ;; 1: len 6; hex 0000000006f3; asc ;; 2: len 7; hex 81000000cb0110; asc ;; 3: len 4; hex 80000004; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 5 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8011d; asc ;; 3: len 4; hex 80000005; asc ;; 4: len 4; hex 80000005; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 6 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000007; asc ;; 1: len 6; hex 0000000006f4; asc ;; 2: len 7; hex 82000000cb0110; asc ;; 3: len 4; hex 80000007; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c8012a; asc *;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 8 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80137; asc 7;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 9 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 0000000006e9; asc ;; 2: len 7; hex 81000000c80144; asc D;; 3: len 4; hex 80000014; asc ;; 4: len 4; hex 80000014; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 10 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000019; asc ;; 1: len 6; hex 000000000700; asc ;; 2: len 7; hex 82000000d00110; asc ;; 3: len 4; hex 80000019; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 80; asc ;; 6: SQL NULL; 我们看到，当使用非索引字段查询，并加锁时\n 会给主键添加 next-key lock 然后最重要的一点是，会锁住所有的记录和间隙  所以最终的锁定区间是 (-∞,1] \u0026hellip; n条记录和它们的间隙 (20,+∞)   那还有另一种情况，如果这个表中连主键都没有呢？\nmysql\u0026gt; begin; Query OK, 0 rows affected (0.04 sec) mysql\u0026gt; select * from user_not_index where number = 1 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 1 | 1 | 1 | 0 | NULL | +----+--------+------+------+------+ 1 row in set (0.02 sec) mysql\u0026gt; show engine innodb status\\G2 lock struct(s), heap size 1136, 10 row lock(s) MySQL thread id 43, OS thread handle 123145565257728, query id 3421 localhost root starting show engine innodb status TABLE LOCK table `db_test`.`user_not_index` trx id 2022 lock mode IX # 表上添加意向排他锁 RECORD LOCKS space id 12 page no 4 n bits 80 index GEN_CLUST_INDEX of table `db_test`.`user_not_index` trx id 2022 lock_mode X # 给GEN_CLUST_INDEX 索引添加 next-key lock Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; Record lock, heap no 2 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000200; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b0110; asc ; ;; 3: len 4; hex 80000001; asc ;; 4: len 4; hex 80000001; asc ;; 5: len 4; hex 80000001; asc ;; 6: len 1; hex 80; asc ;; 7: SQL NULL; Record lock, heap no 3 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000201; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b011f; asc ; ;; 3: len 4; hex 80000003; asc ;; 4: len 4; hex 80000003; asc ;; 5: len 4; hex 80000003; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 4 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000202; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b012e; asc ; .;; 3: len 4; hex 80000004; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 4; hex 80000004; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 5 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000203; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b013d; asc ; =;; 3: len 4; hex 80000005; asc ;; 4: len 4; hex 80000005; asc ;; 5: len 4; hex 80000005; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 6 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000204; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b014c; asc ; L;; 3: len 4; hex 80000007; asc ;; 4: len 4; hex 80000007; asc ;; 5: len 4; hex 80000004; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 7 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000205; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b015b; asc ; [;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 4; hex 8000000a; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 8 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000206; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b016a; asc ; j;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 4; hex 8000000f; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 9 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000207; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b0179; asc ; y;; 3: len 4; hex 80000014; asc ;; 4: len 4; hex 80000014; asc ;; 5: len 4; hex 80000014; asc ;; 6: len 1; hex 81; asc ;; 7: SQL NULL; Record lock, heap no 10 PHYSICAL RECORD: n_fields 8; compact format; info bits 0 0: len 6; hex 000000000208; asc ;; 1: len 6; hex 00000000075f; asc _;; 2: len 7; hex 820000013b0188; asc ; ;; 3: len 4; hex 80000019; asc ;; 4: len 4; hex 80000019; asc ;; 5: len 4; hex 8000000f; asc ;; 6: len 1; hex 80; asc ;; 7: SQL NULL; 我们从锁状态中看到，innodb 会生成一个GEN_CLUST_INDEX索引，然后给这个索引添加 next-key lock\n 给所有记录的GEN_CLUST_INDEX索引添加 next-key lock 然后依然会锁住所有的记录和间隙  所以最终的锁定区间是 (-∞,1] \u0026hellip; n条记录和它们的间隙 (20,+∞)   查询不存在的主键索引 mysql\u0026gt; select * from user where id = 200; Empty set (0.00 sec)2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 10, OS thread handle 123145362374656, query id 895 localhost 127.0.0.1 root TABLE LOCK table `db_test`.`user` trx id 6173 lock mode IX RECORD LOCKS space id 11 page no 4 n bits 80 index PRIMARY of table `db_test`.`user` trx id 6173 lock_mode X Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; 我们发现一共添加了2个锁结构\n 表上添加的独占意向锁 给最大值记录添加了邻间锁  锁定了表中最大值210和数据页中的最大索引记录(210,+∞)这个区间   使用多个索引查询 我这里只测试3种情况\nOR操作 begin; select * from user where id = 1 or age = 15 for update; 这里就是取的两种情况的并集。\n主键索引和二级AND操作 begin; select * from user where id = 15 or age = 15 for update; 这个sql应该是被优化了，优化为只根据主键查询，\n所以最终是只对id = 15 记录的主键索引添加了普通行锁\n二级索引和无索引字段AND操作 begin; select * from user where age = 15 or sex = 1 for update; 这里因为sex字段并没有索引，所以在计算锁的时候，会忽略掉sex字段\n 所以这个sql的加锁情况和select * from user where age = 15一致。 虽然这个sql最终的记录只有一条，但是同样都会锁住。  结论 写到一半的时候，我突然想到了一个问题，然后就觉得没有必要再写一下去了。 那就是\n 再一次查询中，通常MySQL只会使用一个索引 所以我们只要判断出这个SQL中会使用哪个索引就好了，加锁的情况只会和使用的索引有关，和查询中其他没有使用索引没有任何关系 所以第二个操作和第三个操作就都能解释了。 关于第一个OR操作，我explain了一下\nmysql\u0026gt; explain select * from user where id = 1 or age = 15 ; +----+-------------+-------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+ | 1 | SIMPLE | user | NULL | index_merge | PRIMARY,idx_age | PRIMARY,idx_age | 4,5 | NULL | 3 | 100.00 | Using union(PRIMARY,idx_age); Using where | +----+-------------+-------+------------+-------------+-----------------+-----------------+---------+------+------+----------+-------------------------------------------+ 1 row in set, 1 warning (0.00 sec)  发现他使用的是index_merge类型，也就是说两个索引都会用到。 所以加锁的情况也就是 2种索引加锁的情况的并集了。\n加锁情况分析总结 分析了上面几条SQL的加锁情况之后，我感觉有一种通用的规则。\n那就是在可重复读级别下，所使用的的加锁方式，都是围绕这个可重复读来添加的，也就是同一个事务中第一次读和第二次读的结果必须是一致的。\n我们还是举例说明一下\nmysql\u0026gt; select * from user where id \u0026lt;= 10; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 3 | 3 | 4 | 1 | test | | 4 | 4 | 34 | 1 | name | | 5 | 5 | 51 | 1 | name | | 7 | 7 | 4 | 1 | test | | 10 | 10 | 10 | 1 | name | +----+--------+------+------+------+ 5 rows in set (0.00 sec) 为了保证这个查询结果不会发生变化，我们需要在什么范围内加锁呢？\n所有id小于等于10的记录和间隙是不是都需要锁住？\n 首先肯定现在表上添加独占意向锁 然后这些查询出来的记录都要加普通记录锁,还有记录之间的间隙也要加间隙锁  所以就是直接加next-key邻间锁  所以现在锁住的区间就有(-∞,3](3,4](4,5](5,7](7,10]  update、delete 和 select for update 的区别 实际测试了一下，这几种当前读的加锁方式，有稍微的不同。\ndelete 和 update 完全相同\ndelete 和 update 在范围查询情况下，往往比 select for update 范围要大一点，就是在临界行的判断上。\n参考一下：\n常见 SQL 语句的加锁分析\nMySQL 范围加锁的一个Bug 在 MySQL 8.0.18之前都有一个Bug。也就是针对上面的那个SQL。\nMySQL同样会给 10后面的一条记录添加邻间锁\nmysql\u0026gt; select version(); +------------+ | version() | +------------+ | 5.7.34-log | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from user where id \u0026lt;=10 for update; +----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 3 | 3 | 4 | 1 | NULL | | 4 | 4 | 34 | 1 | NULL | | 5 | 5 | 51 | 1 | NULL | | 7 | 7 | 4 | 1 | NULL | | 10 | 10 | 10 | 1 | NULL | +----+--------+------+------+------+ 5 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status \\G;TRANSACTIONS ------------ Trx id counter 2323 Purge done for trx\u0026#39;s n:o \u0026lt; 2320 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 2322, ACTIVE 10 sec 2 lock struct(s), heap size 1136, 6 row lock(s) MySQL thread id 19, OS thread handle 22553189902080, query id 50 localhost 127.0.0.1 root starting show engine innodb status TABLE LOCK table `db_test`.`user` trx id 2322 lock mode IX RECORD LOCKS space id 25 page no 3 n bits 80 index PRIMARY of table `db_test`.`user` trx id 2322 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000003; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b0110; asc ;; 3: len 4; hex 80000003; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 3 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000004; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b011c; asc ;; 3: len 4; hex 80000004; asc ;; 4: len 4; hex 80000022; asc \u0026#34;;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 4 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b0128; asc (;; 3: len 4; hex 80000005; asc ;; 4: len 4; hex 80000033; asc 3;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 5 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 80000007; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b0134; asc 4;; 3: len 4; hex 80000007; asc ;; 4: len 4; hex 80000004; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 6 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b0140; asc @;; 3: len 4; hex 8000000a; asc ;; 4: len 4; hex 8000000a; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; Record lock, heap no 7 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 4; hex 8000000f; asc ;; 1: len 6; hex 000000000907; asc ;; 2: len 7; hex a70000011b014c; asc L;; 3: len 4; hex 8000000f; asc ;; 4: len 4; hex 8000000f; asc ;; 5: len 1; hex 81; asc ;; 6: SQL NULL; 我们看到最下一条 id=15的记录也添加了 邻间锁。\n在8.0.18以前的版本中，对加锁规则：在RR可重复读级别下，唯一索引上的范围查询，需要访问到不满足条件的第一个值为止\nMySQL在 8.0.18版本修复了这个Bug\n(MySQL加锁Bug修复)[https://mp.weixin.qq.com/s/xDKKuIvVgFNiKp5kt2NIgA]\nMVCC 首先MVCC只会在RC 和RR隔离级别下生效。\nMVCC是 多版本并发控制(Multi Version Cucurrent Control)的简称.MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读\n这里的多版本指的就是，不同事务操作数据库所产生的不同的历史快照。MVCC可以根据查询语句，来判断是需要加锁读取当前最新数据，还是读取历史版本数据，如果是要读取历史版本数据，则会根据可见性规则判断读取哪一个版本的数据。\n所以这里就会涉及到MVCC的两种读取方式\n 当前读 快照读  当前读 当前读的意思就是要读取这个记录行中最新的数据。因为当前最新的数据可能有多个事务在操作，所以要加锁。触发当前读的操作有\n select * from user in share mode; 共享锁 select * from user for update; 排它锁 update 操作 delete 操作 insert 操作  快照读 我们普通的select 操作，就是快照读。它会根据可见性算法选取可见的版本进行读取。它在很多情况下，避免了加锁操作，降低了开销，提高了数据库的读取并发性能。\nMVCC的实现原理 简单来说MVCC的实现主要依靠\n 隐藏字段 undo log Read View  下面我们来分别分析一下\n隐藏字段 简单来说就是在数据库的每行纪录中都保存着3个隐藏字段(当然可能还有其他的，这里我们不讨论)\n A 6-byte DB_TRX_ID  最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID 其中有一个bit 为用来表示记录是否被删除了，所以删除操作对于InnoDB来就就算是更新操作 InnoDB会有专门的purge线程来    In the InnoDB multi-versioning scheme, a row is not physically removed from the database immediately when you delete it with an SQL statement. InnoDB only physically removes the corresponding row and its index records when it discards the update undo log record written for the deletion. This removal operation is called a purge, and it is quite fast, usually taking the same order of time as the SQL statement that did the deletion.\n当SQL执行删除操作时，InnoDB并不会立即物理删除这条记录，只有当这条删除操作的undo log被抛弃的时候，才会真物理删除这条记录。\n  A 7-byte DB_ROLL_PTR  回滚指针，指定当事务将要回滚的时候，要回滚到哪个版本，指向这条记录的上一个版本  A 6-byte DB_ROW_ID  隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引，如果有主键则不会生成   undo log 我们上面说过，undo log中，记录了和操作相反的记录，用来回滚。\n Insert undo log ：插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了。 Update undo log：修改一条记录时，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了。 Delete undo log：删除一条记录时，至少要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了。  我们上面说过，当我们执行删除的时候，数据库并没有执行物理删除，只是记录了一下删除状态位 -   从另一个角度来看，undo log也可以看成每条记录的不同版本，我们拿update来举例\n比如现在我们有一个person表，有name 和age 两个字段\n 比如一个有个事务插入person表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL  现在来了一个事务1对该记录的name做出了修改，改为Tom  又来了个事务2修改person表的同一个记录，将age修改为30岁   从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，既链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录。\n那么undo log会一直记录下去吗？当然是不会的。后面我们了解完 read view后在来说一下这个问题。\n15.6.6 Undo Logs\nread view 什么是Read View，说白了Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)\n可见性算法 read view的核心其实就是一个可见性算法。计算可见性的关键数据有\n DB_TRX_ID 记录的最后修改事务ID trx_list，当前正在活跃的事务ID列表 up_limit_id，活跃事务列表中，最小的事务ID low_limit_id, 生成readview的时刻，系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1  下面我们来描述一下可见性算法的规则\n首先一个前置的条件就是当前执行查询的这个事务，肯定是存在于trx_list中的。\n 首先比较DB_TRX_ID \u0026lt; up_limit_id  如果是,则当前事务可以看到这条记录。因为这表示修改这条记录的事务不在活跃列表中，并且已经提交了。 如果不是,则进入下面判断  接下来判断DB_TRX_ID \u0026gt;= low_limit_id  如果是，则当前事务看不到这条记录的变更。因为trx_list是在生成read view的这个时刻，活跃的事务列表。判断为true，则表示DB_TRX_ID这个事务，是在read view生成之后修改的这条记录，所以不可见 如果否，则走下面的逻辑  接下来判断DB_TRX_ID事务，是否在当前活跃的事务列表中。  如果在，则对当前事务不可见，因为这表示，在生成read view的时候，DB_TRX_ID事务还没有提交。 如果不在，则对当前事务可见，以为这表示在生成 read view之前，DB_TRX_ID事务就已经提交了。   通过上面的逻辑我们可以知道，这个可见性算法的关键，就是看，在生成 read view的那一刻,修改记录的事务有没有提交。\n 如果提交了，则可见。 如果没提交，则不可见。  生成 read view 根据上面的逻辑，我们可以知道，每次生成read view的关键就是，记录了一份这个时刻的事务信息。\n trx_list，当前正在活跃的事务ID列表 up_limit_id，活跃事务列表中，最小的事务ID low_limit_id, 生成readview的时刻，系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1  然后在查询的时候，系统会使用read view记录的事务信息，进行可见性算法的计算，然后得到合适的记录。\n生成read view的策略 在不同的隔离级别下，对于read view的生成策略也是不一样的。\n比如对于下面这个操作\nbegin; select * from user where age = 10; xxx select * from user where age = 10;  在RC(Read Committed)级别下，每次select 操作都会生成一个read view 在RR(REPEATABLE Read)级别下，只有事务中的第一次select会生成read view  这种区别下，造成的影响就是，在两个select 操作之间，如果有另一个事务T2插入了一条age =10 的记录，并提交了事务。\n 在RC(Read Committed)级别下，会读到这条记录，也就是会发生幻读  原因就是第二次select，会重新生成read view,这时候另一个事务已经提交。判断条件DB_TRX_ID \u0026gt;= low_limit_id，肯定不成立 并且事务T2已经不在活跃事务列表中，所以这条记录会对当前事务可见。  在RR(REPEATABLE Read)级别下，则不会读到这条记录  因为这时还沿用第一次select时的read view，这时候不管 T2是在第一次select之前还是之后生成的，这个时刻T2是没有提交的 所以这个事务T2的所有变更对当前事务都是不可见的。   验证一下 - 首先把两个session的隔离级别都设置为RC\nmysql\u0026gt; set session transaction isolation level read committed; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select @@session.transaction_isolation; +---------------------------------+ | @@session.transaction_isolation | +---------------------------------+ | READ-COMMITTED | +---------------------------------+ 1 row in set (0.00 sec) 我们看按照图片中的序号执行，在另一个事务提交前，无法读取到，但是提交之后，就能读取到了\n 接着测试一下RR级别，首先同样先设置隔离级别为RR\nset session transaction isolation level repeatable read; mysql\u0026gt; select @@session.transaction_isolation; +---------------------------------+ | @@session.transaction_isolation | +---------------------------------+ | REPEATABLE-READ | +---------------------------------+ 1 row in set (0.00 sec)  我们看到，在RR级别下，另一个事务提交后，仍然没有读到插入的数据。\nundo log 什么时候删除 undo log不会一直保存，当undo log能够确保没有事务会用到的时候，会设置delete bit，然后等待purge线程回收。\n insert undo log：事务在插入新记录产生的undo log，当事务提交之后可以直接丢弃，因为这是新插入的数据，肯定没有事务需要查询它； update undo log：事务在进行 update 或者 delete 的时候产生的 undo log，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个log更早的read-view了的时候才能删除。ps：所以长事务会产生很多老的视图导致undo log无法删除 大量占用存储空间。  RR级别下如何解决幻读 通过生成read-view的策略这一部分我们了解，在RR级别下，通过生成Read-View的策略解决了快照读的幻读问题。\n那么当前读会不会有幻读问题呢？\n答案是肯定的。继续沿用上面的RR隔离级别下的SQL，我们在左边的事务中执行一个当前读的操作\nmysql\u0026gt; update user set sex = 0 where age = 10; Query OK, 3 rows affected(0.00 sec) 我们发现，虽然上面查询只查出来了2条，但是我们执行更新的时候却更新了3条，这在某种意义上来说也算是一种幻读 一种针对当前读的幻读。\n因为update 是当前读，会读到所有已经提交的记录，所以能够读取到有右边事务插入的数据\n本篇文章使用的表结构 数据库版本 因为8.0.18版本之前的MySQL加锁有Bug，所以如果你使用的是5.x版本，和我查看的加锁结构可能会有锁区别\nmysql\u0026gt; select version(); +-----------+ | version() | +-----------+ | 8.0.25 | +-----------+ 1 row in set (0.00 sec) 表结构 CREATE TABLE `user` ( `id` int NOT NULL, `number` int DEFAULT NULL, `age` int DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uk_number` (`number`) USING BTREE, KEY `idx_age` (`age`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;CREATE TABLE `user_not_index` ( `id` int NOT NULL, `number` int DEFAULT NULL, `age` int DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci; 表数据\n+----+--------+------+------+------+ | id | number | age | sex | name | +----+--------+------+------+------+ | 1 | 1 | 1 | 0 | NULL | | 3 | 3 | 3 | 1 | NULL | | 4 | 4 | 4 | 1 | NULL | | 5 | 5 | 5 | 1 | NULL | | 7 | 7 | 4 | 1 | NULL | | 10 | 10 | 10 | 1 | NULL | | 15 | 15 | 15 | 1 | NULL | | 20 | 20 | 20 | 1 | NULL | | 25 | 25 | 15 | 0 | NULL | +----+--------+------+------+------+ 参考 15.7.1 InnoDB Locking\n15.3 InnoDB Multi-Versioning\n15.6.6 Undo Logs\n自增锁模式\n你真的懂MVCC吗？来手动实践一下\nMySQL原子性与持久性的保证\n解决死锁之路（终结篇）- 再见死锁\n读 MySQL 源码再看 INSERT 加锁流程\nMySQL锁系列（一）之锁的种类和概念\nInnoDB这个将近20年的\u0026rdquo;bug\u0026rdquo;修复了-范围查询加锁Bug\n15.7.3 Locks Set by Different SQL Statements in InnoDB\n","permalink":"https://balvboy.github.io/blog/mysql_lock/","summary":"MySQL的存储引擎 MySQL有多种可选的存储引擎，常见的有 InnoDB MyISAM Memory 其中InnoDB是最常用的存储引擎，并且也是目前MySQL的默认存储引擎。","title":"MySQL的事务、日志、锁和MVCC"},{"content":" 终于来到了重头戏-AQS,AQS可以说是整个J.U.C的核心，整个工具包中的大部分同步工具都是借助于AQS来实现的。接下来我们将通过ReentranLock的实现来了解AQS的原理\nAQS结构 同步状态 首先在AQS中维护了一个名叫state的字段，是由volatile修饰的，它就是所谓的同步状态：\nprivate volatile int state; 并且提供了几个访问这个字段的方法：\n   方法名称 描述     protected final int getState() 获取state的值   protected final void setState(int newState) 设置state的值   protected final boolean compareAndSetState(int expect, int update) 使用CAS方式更新state的值    可以看到这几个方法都是final修饰的，说明子类中无法重写它们。另外它们都是protected修饰的，说明只能在子类中使用这些方法。\n同步队列 AQS使用一个Volatile的int类型的成员变量state来表示同步状态，通过内置的FIFO同步队列来完成资源获取的排队工作。\n有一点值得注意，就是这里的头结点是一个虚节点，它的thread为空，头结点的存在更多意义上是为了编程方便。当然为了方便理解，我们可以认为头结点就是获取了锁的线程的节点，但是thread被清空了\n当线程获取到锁的时候，会把线程所在的节点设置为头结点，设置为头结点后，会把不需要的属性设置为null。\n/** * Sets head of queue to be node, thus dequeuing. Called only by * acquire methods. Also nulls out unused fields for sake of GC * and to suppress unnecessary signals and traversals. * * @param node the node */ private void setHead(Node node) { head = node; node.thread = null; node.prev = null; } AQS中定义一个头节点引用，一个尾节点引用：\nprivate transient volatile Node head; //执行队列的头结点 private transient volatile Node tail; //执行队列的尾节点  上面图中的每个线程，都对应着一个Node节点，Node是AQS中的一个内部类，下面解释一下几个方法和属性值的含义：\n   方法和属性 含义     waitStatus 当前节点在队列中的状态   thread 表示处于该节点的线程   prev 指向前一个节点的指针   next 指向后一个节点的指针   predecessor 返回前一个节点，没有的话抛出npe   nextWaiter 指向下一个处于CONDITION状态的节点(暂不多做介绍)       枚举 含义     0 Node初始化的默认值   CANCELLED 为1，表示节点已经取消获取锁   CONDITION 为-2，表示节点在等待队列中，节点线程等待唤醒   PROPAGATE 为-3，当前线程处在SHARED情况下，该字段才会使用   SIGNAL 为-1，表示该节点的继任者(下一个节点)，已经或者将要被block    这里把java源码中的注释也贴出来，方便大家理解\n/** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn\u0026#39;t need to * signal. So, most code doesn\u0026#39;t need to check for particular * values, just for sign. * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; todo 后面我们在补充一下\n独占和共享模式 在一些线程协调的场景中，一个线程在进行某些操作的时候其他的线程都不能执行该操作，比如持有锁时的操作，在同一时刻只能有一个线程持有锁，我们把这种情景称为独占模式； 在另一些线程协调的场景中，可以同时允许多个线程同时进行某种操作，我们把这种情景称为共享模式。 我们可以通过修改AQS中state字段代表的同步状态来实现多线程的独占模式或者共享模式。\n 独占模式 在独占模式下，我们设置state为0，线程要进行独占操作的时候，需要使用CAS操作，把0修改为1，我们把这个过程称为尝试获取同步状态。然后在执行完成后，同样再通过CAS操作修改回来,把这个操作成为释放同步状态。这洋就能保证任何时候，都只能有一个线程独占。\n 共享模式 在共享模式下，我们设置state为能支持共享的最大线程数，比如10。线程在执行共享操作时，每次都判断state是否大于0，如果大于0，通过CAS把state的值减1,我们把这个过程成为尝试获取共享同步状态。然后每个线程再执行完之后，再通过CAS把state的值+1,我们把这个操作成为释放共享同步状态。\n  在后面的代码分析中会详细讲解独占模式和共享模式。\n对于上面提到的获取共享状态和释放共享状态以及尝试获取共享同步状态和释放共享同步状态，AQS中定义了几个方法\n   方法名称 描述     protected boolean tryAcquire(int arg) 独占式的获取同步状态，获取成功返回true，否则false   protected boolean tryRelease(int arg) 独占式的释放同步状态，释放成功返回true，否则false   protected int tryAcquireShared(int arg) 共享式的获取同步状态，获取成功返回true，否则false   protected boolean tryReleaseShared(int arg) 共享式的释放同步状态，释放成功返回true，否则false   protected boolean isHeldExclusively() 在独占模式下，如果当前线程已经获取到同步状态，则返回 true；其他情况则返回 false    这几个方法，AQS都没有实现，而是要求子类去实现。如果我们自定义的同步工具需要在独占模式下工作，那么我们就重写tryAcquire、tryRelease和isHeldExclusively方法。\n在了解了上面这些内容之后，我们通过ReentranLock来详细了解一下AQS的独占模式是如何工作的。\nReentranLock 先来看一下ReentranLock的代码结构：\npublic class ReentrantLock implements Lock, java.io.Serializable { /** Synchronizer providing all implementation mechanics */ private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer{ ... } static final class NonfairSync extends Sync { ... } static final class FairSync extends Sync { ... } public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } public void lock() { sync.lock();} public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } public boolean tryLock() { return sync.nonfairTryAcquire(1); } public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); } public void unlock() { sync.release(1); } public Condition newCondition() { return sync.newCondition(); } } 上面我们把ReentranLock的主要结构，罗列出来。、\n 首先定义了一个Sync属性sync 接下来是Sync的内部类，Sync继承自AbstractQueuedSynchronizer 然后是两个Sync的子类，分别是非公平锁和公平锁的实现 接下来是两个构造方法，可以看到，默认是使用的非公平锁 然后就是实现自Lock接口的方法，可以看到方法都是最终调用了sync，也就是我们前面说的，ReentranLock借助于AQS实现了Lock。  我们看到ReentranLock的几个方法中，都是调用的Sync的相关方法，下面我们就来看一下Sync和它的两个子类NonfairSync与FairSync:\nSync内部类 Sync继承自AbstractQueuedSynchronizer,并重写了tryRelease和isHeldExclusively方法。独占模式要求的另一个方法tryAcquire，由他的子类NonfairSync和FairSync分别实现。\n看到这里，我们可以知道什么，那就是非公平锁和公平锁只在获取锁上有区别，在释放锁的上没有任何区别\nabstract static class Sync extends AbstractQueuedSynchronizer { abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ //注释说到， tryAcquire在子类中实现，但是tryLock是使用nofair的，所以放到了父类中  final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { //如果当前没有线程持有，则直接尝试获取一次，不管后面后又没其他线程再等待  if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //判断是否为锁重入  else if (current == getExclusiveOwnerThread()) { //记录重入  int nextc = c + acquires; //判断int overflow的情况，所以最大的重入次数为int的最大值  if (nextc \u0026lt; 0) // overflow  throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } //尝试释放锁  protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //如通c == 0，表示所有的锁都释放完了  //则设置持有锁线程为null  //返回释放锁成功  if (c == 0) { free = true; setExclusiveOwnerThread(null); } //如果c != 0 则表示发生了锁重入，只是里层释放了锁  //返回没有完全释放锁  setState(c); return free; } protected final boolean isHeldExclusively() { // While we must in general read state before owner,  // we don\u0026#39;t need to do so to check if current thread is owner  return getExclusiveOwnerThread() == Thread.currentThread(); } // 省略掉一些不太重要的方法。。。。 } 下面在看NonfairSync这个子类\n/** * Sync object for non-fair locks */ static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; /** * performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() { //非公平锁上来就先尝试获取一次,就是这里体现了不公平，  if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else //如果没有获取成功,通过acquire方法，加入队列中等待  acquire(1); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } } 在看一下FairSync这个子类\n/** * Sync object for fair locks */ static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } /** * Fair version of tryAcquire. Don\u0026#39;t grant access unless * recursive call or no waiters or is first. */ //公平锁的tryAcquire和非公平锁的差别就是，非公平锁会直接尝试一次CAS获取锁  //而公平锁则会先判断一下等待队列是不是为空。  //如果都尝试获取失败，之后的处理逻辑都是一样的  protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { //如果队列为空，或者当前线程已经处于队列的最前，则尝试一次通过CAS获取锁  //否则不获取  if (!hasQueuedPredecessors() \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //判断重入的逻辑  else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } //获取锁失败，并且不是重入，则tryAcquire失败  return false; } } 公平锁和非公平锁在获取锁时的区别 我们看到NonfairSync和FairSync都是只有两个方法，tryAcquire和lock方法。其中tryAcquire方法是实现自AQS。 那么公平锁和非公平锁的区别就体现在，这两个类，对着两个方法的实现上。\n我们先看tryAcquire方法的区别。\n NonfairSync是直接调用的父类的nonfairTryAcquire方法，它呢不会管当前有没有其他线程再等待，只要当前没有线程持有，就尝试获取一次 FairSync是会先判断是否有其他线程再等待，只有没有线程等待或者它本身就是最前面的节点的时候，才会尝试获取。  我们再看lock方法 - NonfairSync,上来直接使用CAS，尝试获取一次，获取不到则调用AQS的acquire方法，在acquire方法中会调用NonfairSync的tryAcquire，如果仍然失败，加入到等待队列中。 - FairSync,直接调用父类AQS的acquire方法，在acquire方法中会调用FairSync的tryAcquire)，如果失败，加入到等待队列中。\n我们看到公平锁和非公平锁的区别就在，非公平锁不会管现在又没有线程在等待，而是直接尝试获取。\nnonfairTryAcquire方法为何定义在父类 看这个方法名称nonfairTryAcquire,感觉应该写在子类NonfairSync中会比较合适,这里会写到父类中呢？方法的注释中写到\n/** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ 执行非公平的tryLock。 tryAcquire在子类中实现。但两者都需要非公平的trylock方法。 意思是在调用Lock.tryLock()方法的时候，都会用到nonfairTryAcquire,所以需要写到父类中。\n那么为什么tryLock都要用非公平的nonfairTryAcquire呢？\n我们再来看一下tryLock方法的注释\n注释中写到， - 在当前没有线程持有这个锁的时候，那么tryLock方法就可以立即抢占这个锁，即使使用的公平锁的策略。这种行为在有些情况下能够带来更好的性能，尽管它会破坏公平性。 - 如果不想破坏公平性，那么可以使用tryLock(0, TimeUnit.SECONDS)方法。\n公平锁和非公平锁的性能对比 上面我们说到tryLock方法一直使用非公平的方式尝试获取锁，是因为非公平锁的性能要更好。那下面我们来分析一下原因和验证一下\n 因为公平锁在获取锁时，永远是等待时间最长的线程获取到锁，这样当线程T1释放锁以后，如果还想继续再获取锁，它也得去同步队列尾部排队，这样就会频繁的发生线程的上下文切换，当线程越多，对CPU的损耗就会越严重。 而且在唤醒队首的线程后，线程不会立即执行，而是需要等待CPU分配时间片，才能获取到锁。 而非公平锁，是有机会跳过等待队列，和等待CPU分配时间片的这个情况的，所以性能会好一些。 非公平锁性能虽然优于公平锁，但是会存在导致线程饥饿的情况。在最坏的情况下，可能存在某个线程一直获取不到锁。不过相比性能而言，饥饿问题可以暂时忽略。  下面我们通过代码来验证一下：\npublic class FairVsNonFairLock { // 公平锁  private static Lock fairLock = new ReentrantLock(true); // 非公平锁  private static Lock nonFairLock = new ReentrantLock(false); // 计数器  private static int fairCount = 0; // 计数器  private static int nonFairCount = 0; private static int threadCount = 1; public static void main(String[] args) throws InterruptedException { System.out.println(\u0026#34;公平锁耗时: \u0026#34; + testFairLock(threadCount) + \u0026#34; ms\u0026#34;); System.out.println(\u0026#34;非公平锁耗时: \u0026#34; + testNonFairLock(threadCount) + \u0026#34; ms\u0026#34;); } public static long testFairLock(int threadNum) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(threadNum); // 创建threadNum个线程，让其以公平锁的方式，对fairCount进行自增操作  List\u0026lt;Thread\u0026gt; fairList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; threadNum; i++) { fairList.add(new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 10000; j++) { fairLock.lock(); fairCount++; fairLock.unlock(); } countDownLatch.countDown(); })); } long startTime = System.currentTimeMillis(); for (Thread thread : fairList) { thread.start(); } // 让所有线程执行完  countDownLatch.await(); return System.currentTimeMillis() - startTime; } public static long testNonFairLock(int threadNum) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(threadNum); // 创建threadNum个线程，让其以非公平锁的方式，对nonFairCountCount进行自增操作  List\u0026lt;Thread\u0026gt; nonFairList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; threadNum; i++) { nonFairList.add(new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 10000; j++) { nonFairLock.lock(); nonFairCount++; nonFairLock.unlock(); } countDownLatch.countDown(); })); } long startTime = System.currentTimeMillis(); for (Thread thread : nonFairList) { thread.start(); } // 让所有线程执行完  countDownLatch.await(); return System.currentTimeMillis() - startTime; } }  线程数为1,跑3次\n公平锁耗时: 4 ms 非公平锁耗时: 2 ms ----- 公平锁耗时: 5 ms 非公平锁耗时: 3 ms ----- 公平锁耗时: 6 ms 非公平锁耗时: 3 ms 线程数为5，跑3次\n公平锁耗时: 337 ms 非公平锁耗时: 11 ms ------ 公平锁耗时: 497 ms 非公平锁耗时: 11 ms ------ 公平锁耗时: 421 ms 非公平锁耗时: 13 ms 线程数为10，跑3次\n公平锁耗时: 991 ms 非公平锁耗时: 22 ms ------ 公平锁耗时: 903 ms 非公平锁耗时: 31 ms ------ 公平锁耗时: 768 ms 非公平锁耗时: 18 ms  我们看到随着线程数的增加，非公平锁的性能要明显高于非公平锁了。所以这应该就是ReentranLock默认使用非公平锁的原因了。 其实我们看synchronized的源码，它也是非公平锁。\n独占式同步状态获取和释放 我们先来看一下获取同步状态的方法调用流程\n调用ReentranLock的lock方法，调用的是FairSync或者NonfairSync的lock()方法。\n NonfairSync会先尝试CAS获取一次，如果获取失败则调用AQS的acquire()方法 FairSync则是直接调用AQS的acquire方法。 acquire方法中，首先会调用FairSync或者NonfairSync的tryAcquire()方法 如果tryAcquire()失败，则会进入等待队列中。  下面我们一个方法一个方法的分析，先来看acquire()。\n加锁逻辑 acquire方法 /** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once {@link #tryAcquire}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquire} until success. This method can be used * to implement method {@link Lock#lock}. * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg) { if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //自我中断，用来传递线程在获取锁的过程中被中断的状态  selfInterrupt(); }  注释中提到，这个方法是忽略中断的。也就是说线程在获取锁的过程中，无法通过调用线程的interrupt()方法中断获取锁的行为。 会至少调用一次tryAcquire()方法，如果获取成功则返回。 所以说，如果一个线程是第一获取锁的线程，那么它会直接获取成功，并不会创建节点，只有第二个线程来获取，才会创建节点，然后加入等待队列。 如果失败线程会进入等待队列。 在队列中获取到锁之后会返回，  如果返回true则表示线程在获取锁过程中被调用过中断，则需要调用selfInterrupt()重新中断一下自己，把中断状态传传出来 如果返回false则表示没有被调用过中断。   addWaiter封装线程为Node节点 /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) { //构建新的node节点  Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure  //这里进行一次快速入队，而不是直接走完整的入队方法的考虑是  //完整入队操作，是通过死循环，然后调用CAS来实现的。JVM或者操作系统，在处理循环的时候，需要很多额外的资源和开销，  //所以先进行一次单独的CAS操作，如果成功的话，就能节省掉死循环的开销,如果不成功再使用enq，也不会有太大的开销  Node pred = tail; //如果尾节点不为空，把当前节点的前置节点设置为尾节点  //这里入队的时候，先尝试快速入队  if (pred != null) { //先和前面的节点建立联系，保证从后面遍历的时候，能够遍历到所有的节点  node.prev = pred; //使用CAS设置当前节点为尾节点  if (compareAndSetTail(pred, node)) { //如果设置成功，把前置节点的next指向当前节点  pred.next = node; return node; } } //如果CAS失败，或者尾结点为空，则需要进入完整的入队逻辑。  //CAS失败，则说明，有另一个线程进入了队列，并成为了尾结点。  enq(node); return node; }  首先通过当前线程构建一个Node节点 然后判断如果尾节点不为空，则尝试一次快速入队(通过单次CAS操作)  这里有一点需要注意，就是快速入队的时候，是先设置的node.prev = pred,然后在设置的pred.next = node，包括enq里面的操作也是，这里是有原因的，下面我们会详细的分析一下  如果快速入队失败，则调用enq(node),执行完整的入队操作  enq完整入队 我们说他是一个完整入队逻辑的原因是，它在for循环里，执行CAS操作，直到成功加入队列才会跳出循环\n这种操作也叫做 slow path\n/** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node\u0026#39;s predecessor */ private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize  //走到这里的话说明，说明Node还没有初始化，需要创建一个节点，当做头结点  //初始化的时候，只有一个节点，所以这个节点既是头结点又是尾结点  if (compareAndSetHead(new Node())) tail = head; } else { //当初始化完成之后，会继续循环，直到把当前节点设置为尾结点。  node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } }  如果当前队列为空，或者快速入队失败，则会执行完整的入队逻辑 完整入队的其实就是循环调用快速入队的逻辑，直到成功。 如果当前队列为空，这时候需要先把头结点创建出来，然后下次循环的时候，在把真正的节点加入到头结点的后面。 所以，头结点是被第二个获取锁的线程，获取锁失败的时候，创建的。  acquireQueued方法 这个方法就是线程等待队列中获取锁，在这个方法中，线程会不断的进行尝试获取-\u0026gt;挂起-\u0026gt;唤醒-\u0026gt;尝试获取知道获得锁\n/** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting 如果在等待过程，被中断过，获取锁之后返回true */ final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); //如果这个节点的前置节点是头结点，那么则表示这个节点有获取锁的资格。  //顺便说一下，在AQS的队列中个，头结点是一个虚节点，是为了在编程的时候更为方便，或者可以理解为已经获取到锁的节点  //调用tryAcquire()尝试获取锁  if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { setHead(node); //把之前的头结点踢出等待队列  p.next = null; // help GC  failed = false; //获取锁成功之后，返回中断状态  return interrupted; } //如果没有资格获取锁，或者获取锁失败  //则需要通过shouldParkAfterFailedAcquire()，判断这个线程是否需要挂起  //如果当前节点，是头结点的下一个节点，那么shouldParkAfterFailedAcquire()方法会返回false，直接跳过挂起，再执行上面的逻辑获取一次  //如果需要park，则调用parkAndCheckInterrupt()方法，进行挂起。  //线程在挂起的时候，有两种唤醒的方式，  // 1.使用unpark  // 2.使用线程中断方法  //如果这个线程是被线程中断方法唤醒，那么会把这个interrupted变量置为true  //然后在等到这个线程获取到锁的时候，会把这个中断状态传出去  //这里使用到的一个特性就是，被park挂起的线程，当线程中断的时候不会抛出线程中断异常  if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; //如果返回true，表示是被中断唤醒的  parkAndCheckInterrupt()) //记录中断状态  interrupted = true; } } finally { if (failed) cancelAcquire(node); } }  线程被封装成Node节点加入等待队列之后，进入这个方法。 首先判断这个节点的前置节点是不是头结点，也就是说，这个节点是等待队列的第二个节点。 在AQS中，头结点是虚节点(或者理解为持有锁的节点)，只有第二个节点是有资格去获取锁。 然后调用tryAcquire尝试获取锁，获取成功后  会调用setHeader() 把当前线程的Node节点设置为头结点 并踢掉之前的头结点 并返回线程的中断状态，记录线程在获取锁的过程中，有没有被中断过。  如果不是第二个节点，或者tryAcquire失败，会调用shouldParkAfterFailedAcquire,判断线程是否应该挂起。  shouldParkAfterFailedAcquire方法 在这个方法中，会根据节点的状态判断线程是否要被挂起,并在某些情况下修改前置节点状态\n/** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node\u0026#39;s predecessor holding status * @param node the node * @return {@code true} if thread should block */ //在这个方法判断node节点的线程，是否需要挂起 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { //获取前置节点的waitStatus  int ws = pred.waitStatus; if (ws == Node.SIGNAL) //如果pred节点的waitStatus是SIGNAL，则表示pred节点正在等待别的通知来唤醒  //所以肯定还轮不到node节点来获取锁，直接挂起  //这个节点已经设置了请求释放资源的时候来通知它的状态，所以可以安全的挂起  /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws \u0026gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ //waitStatus \u0026gt; 0 只有可能是canceled，那么则踢出pred节点  //让node的prev指向 pred节点的prev，就相当于跳过了pred节点。  //这里是一个循环操作，表示会把前面所有的连续的cancel状态的节点都踢出队列  do { node.prev = pred = pred.prev; } while (pred.waitStatus \u0026gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don\u0026#39;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ //执行到这里的话，waitStatus只能是0 或者 PROPAGATE。  //这时候会把前置节点的waitStatus 状态修改为signal，这样在下次循环的时候，当前节点就会执行挂起操作了  //每个节点的waitStatus都是由他的下一个节点来修改的  compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; }  首先拿到当前节点的前置节点的waitStatus,然后开始判断 如果waitStatus是SIGNAL状态,则返回true，表示新加入的节点已经告诉了他的前置节点，当前置节点释放的时候唤醒他，他可以放心的挂起了;下面的逻辑都会返回false，表示不会挂起。 如果waitStatus大于0，也就是CANCELLED状态，表示当前节点的前置节点已经被取消了，那么将这个前置节点踢出等待队列 并会把前面所有的连续的CANCELLED状态的节点都踢出队列 如果waitStatus不大于0，那么则waitStatus是0,或者PROPAGATE，那么就把它设置为SIGNAL状态，这样会再次尝试获取一次,如果仍然没有获取到，则会在下次判断shouldParkAfterFailedAcquire的时候，因为前置节点是SIGNAL而挂起。  这里的重点是对于SIGNAL状态的理解，我们再来看一下Java的解释，Java的解释有三个地方\n最后一张图片的注释中提到，AQS中使用和CLH相同的策略，在节点中保存一个后置节点的控制信息。当一个节点的前置节点被释放的时候，通知它的后置节点。 只有SIGNAL状态表示的是对后置节点的操作，其他状态都是表示的本身节点的状态\n上面提到，一个节点的waitStatus设置为SIGNAL，表示的是这个节点的后置节点正在或者将要被阻塞，也可以理解为这个节点的后置节点等待它前面节点唤醒(这个更符合SIGNAL的定义)。\n 所以说，一个节点的处于SIGNAL状态，表示的是，当这个节点被释放的时候，需要唤醒它的后续节点。 那么既然这个状态会指导对后置节点的操作，所以这个状态的变更也应该有后置节点来触发。 所以每个节点的初始状态都是0，当有后置节点加入队列的时候，会在后置节点执行shouldParkAfterFailedAcquire的时候，把这个节点的状态修改为SIGNAL  parkAndCheckInterrupt挂起并检查中断状态 当经过上面的方法判断，线程需要被挂起，就会执行这个方法，使用LockSupport.park()挂起当前线程。\n//当线程被unpark()唤醒，或者被终端的时候返回当前线程的中断状态 //使用park()挂起的一个特点就是，当调用线程的中断方法时，不会抛出中断异常，同时也会保留线程的中断状态 private final boolean parkAndCheckInterrupt() { LockSupport.park(this); //这里注意一下，如果是通过调用线程interrupt方法唤醒了挂起的线程。  //这里调用的是 interrupted(),这个方法的作用是，返回当前线程的中断状态，然后清除掉中断状态，  //这里为什么必须要清除中断状态呢？  //因为线程被唤醒之后，需要再次去尝试获取锁，但是并不能保证肯定成功，如果失败了，还需要继续挂起。  //如果这里不清除中断状态，那么下次获取失败，需要再次挂起的时候，因为线程有中断状态，所以LockSuport.park()会失效，则导致线程无法挂起。  return Thread.interrupted(); }  线程被挂起后就会停在这行代码，等待被唤醒后继续向下执行。 线程被唤醒后，继续执行return Thread.interrupted();,返回当前线程的中断状态，然后清除掉中断状态。 所以如果线程是被中断方法唤醒的，parkAndCheckInterrupt()方法就会返回true，然后在acquireQueued()方法中就会执行interrupted = true;记录下来中断状态。 然后在线程成功获得锁之后，将记录的中断状态返回出去。  释放锁逻辑 release方法释放锁 当调用lock.unlock()方法释放锁时，会调用AQS的release()方法。\n/** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} * */ public final boolean release(int arg) { //tryRelease，尝试释放  //这里如果返回false，则表示发生了锁重入，这里只是释放了里层的，外层仍然还在持有锁  //如果返回true，则表示所有的重入都已经被释放了，可以唤醒下面的等待线程了  if (tryRelease(arg)) { Node h = head; //如果有head不为null，则表示至少有一个线程进入过等待队列，因为head节点是在后面线程进入等待队列的时候初始化的  //h.waitStatus != 0,为什么要加这个判断呢?  //因为waitStatus=0，是一个节点的初始状态，如果头结点处于这个状态，说明要么后面加入的线程还在执行中，没有执行到 shouldParkAfterFailedAcquire方法中的compareAndSetWaitStatus  //要么就是后面的线程在执行到 shouldParkAfterFailedAcquire()方法之前，已经超时了  //这两种情况都不需要唤醒  //第一种线程正在执行的情况，后面的线程会在第二次循环的时候tryAcquire(),能够拿到锁  if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 1.首先调用Sync.tryRelease()方法，尝试释放锁\n//尝试释放锁 protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //如通c == 0，表示所有的锁都释放完了  //则设置持有锁线程为null  //返回释放锁成功  if (c == 0) { free = true; setExclusiveOwnerThread(null); } //如果c != 0 则表示发生了锁重入，只是里层释放了锁  //返回没有完全释放锁  setState(c); return free; } 这里主要处理了一个重入的逻辑，只有所有重入的锁都释放完毕了，才返回true。 值得注意的是，这个tryRelease()方法是写在Sync这个类中的，而不是FairSycn和NonFairSync，也就可以说明公平锁和非公平锁的释放逻辑是完全相同的。\n2.tryRelease()返回true，则需要判断是否需要唤醒后面的节点。\n我们来看这里的判断条件\nNode h = head; if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true;  head!=null,因为head节点是，后续线程获取锁失败后，加入队列时创建的，所以head!=null就表示有后续节点。 h.waitStatus != 0一个节点的初始状态是0，在后置节点第一次判断是否应该挂起的时候，会把他的前置节点状态修改为SIGNAL也就是1。所以h.waitStatus=0就可以理解为  后置节点正在执行中，还没有挂起，所以不需要唤醒 后置节点调用的是带有超时的acquire()方法，已经等待所超时了 这几种情况都不需要唤醒。   unparkSuccessor唤醒后置节点 当一个线程释放了锁，并且确定有线程需要唤醒的时候，会调用unparkSuccessor()唤醒后面的节点。\n/** * Wakes up node\u0026#39;s successor, if one exists. * * @param node the node */ private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 这里传入的是头结点，头结点已经完成了唤醒后面节点的操作，那么则可以把这个状态改回默认值了  int ws = node.waitStatus; if (ws \u0026lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ /** 这里从后向前遍历的原因是，在新节点node入队的时候，都是先设置 node.prev = p（之前的tail节点）(也就是说从后向前可以遍历整个队里了) 然后通过cas，把node节点设置为tail 如果cas成功，才设置 p.next = node (这时候从head节点向后才能遍历整个队列) 以为cas成功，和 设置 p.next = node 这两个步骤并不是原子的 所以如果cas成功之后，在执行 p.next = node之前，unparkSuccessor()被调用。 线程开始从前往后遍历，这时候 p.next 还是为null的，所以就不能遍历队列所有的节点了。 **/ /** * 因为Node是一个双向队列 * 在插入新节点的时候，总是会先把新节点和前面的节点(也就是之前的尾结点)建立联系。node.prev = p; * 然后当新节点成功的成为尾结点之后，才会把 前面的节点和新节点建立联系 p.next = node; * * 这是可以理解，也是必须的。 * 因为 p(之前的尾结点)，已经是队列中确定的一个节点，如果在node节点确定加入队列之前就修改了p节点的next属性，如果node能在紧接着的 * cas操作成功还好，如果cas失败，那就是让p.next指向了一个队列外的节点。这肯定是不行的。 * * 所以说要么把入队和与p.next = node 这两个操作搞成一个原子操作(但是这样肯定会影响性能)，要么想出一个方案，在节点已经入队(已经成为了尾结点)，但是前面节点p还没和node节点建立联系的情况下，也能顺利的遍历所有的节点。 * * 先执行node.prev = p，就是解决这个问题的办法。 * * 所以导致了这里必须采用从队尾开始遍历的方案 * */ //拿到头结点的下一个节点  Node s = node.next; //如果为空，或者状态是已取消，则从尾结点开始找到一个非canceled状态的节点，然后唤醒它  if (s == null || s.waitStatus \u0026gt; 0) { s = null; for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev) if (t.waitStatus \u0026lt;= 0) s = t; } //如果找到了合适的节点，则使用unpark()方法唤醒  if (s != null) LockSupport.unpark(s.thread); }  首先拿到头结点的后置节点，如果为空或者状态是CANCELLED则从队列中寻找一个可用的节点 这里有一个关键就是从队尾开始寻找  如果找到了，则使用LockSupport.unpark(s.thread)唤醒指定的线程。 我们上面说过了，线程挂起之后就会停在 parkAndCheckInterrupt()方法的LockSupport.park()这里，被唤醒后会继续向下执行，就会继续在acquireQueued()方法中尝试获取锁 不断的循环尝试获取-\u0026gt;失败-\u0026gt;挂起-\u0026gt;唤醒-\u0026gt;尝试获取这个过程，直到成功获取。  Condition 在详细分析Condition代码之前，先说一下我对Condition的理解\n如果说Lock和synchronized相对应，那么Conditon就是和wait(),notify相对应\nCondition为Lock提供了条件等待的功能，即一个线程达到某个条件时暂停执行，直到另一个线程通知它再次执行。因为这个条件需要在不同的线程中被访问，所以对Conditon对象的操作必须受到Lock的保护，也就是必要获得Lock，才能执行。\nCondition原理  当一个线程A获取了lock锁，调用了condition.await(),会释放锁，并构建一个Node对象(和AQS中的一样)节点状态为CONDITION,-2，加入到Condition的条件队列中。 然后让当前线程挂起，等待唤醒，或者挂起一段时间自己唤醒 当另一个线程B获取了lock锁，调用了condition.signal(),会找到condition条件队列中的第一个节点，把它加入到AQS的同步队列中，然后唤醒Node中的线程。 线程A被唤醒后，会调用acquireQueued再次尝试获取锁  Condition的原理其实和JVM对于wait和notify的实现很类似。我们对比着来说明一下。\nwait和notify执行大致流程\n 线程A在同步代码块中，调用wait()方法，释放锁，并把A线程加入到waitSet中 线程挂起，等待唤醒，或者挂起一段时间自己唤醒 线程B，在同步代码块中，调用notify方法，会唤醒waitSet队列中的第一个节点，然后把这个节点加入到cxq队列中 线程A就在cxq队列中等待再次获取锁。  我们看到Condition和wait于notify的流程基本完全相同\n Condition队列对应着waitSet 同步队列对应着cxq 另外他们对于中断的处理也是很相似的。因为线程的挂起可以被中断方法唤醒，所以他们在被唤醒之后，都需要检查自己是不是被中断唤醒的 如果是被中断唤醒，需要有对应的处理，  wait是直接抛出中断异常 condition可以根据一定的策略，可以选择抛出中断异常和自我中断   有了这些概念，下面我们来进入代码分析\n代码分析 await() // Condition中的操作实际上是，先把自己加入到一个 Condition队列中。 // 然后释放掉获取的AQS锁，然后通过LockSupport挂起，等待其他线程唤醒，唤醒后在继续获取锁 public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); //加入一个新节点到，condition队列中  Node node = addConditionWaiter(); //释放锁，想一下wait和notify，别人在唤醒你的时候，也需要获得锁，如果你不释放别人怎么唤醒你呢，所以这里要释放锁  int savedState = fullyRelease(node); int interruptMode = 0; //在调用signal的时候会把节点加入到同步队列中，  //如果已经在队列中了，那说明已经有人唤醒了它，把它加入到了队列中，那么直接获取锁就可以了。  //如果还没有加入队列，则需要挂起，等待唤醒的时候被加入到队列中。  while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } //然后在进入等待队列中获取锁  if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled  unlinkCancelledWaiters(); if (interruptMode != 0) //根据interruptMode执行抛出异常或者自我中断  reportInterruptAfterWait(interruptMode); } addConditionWaiter /** * Adds a new waiter to wait queue. * @return its new wait node */ //这里之所以在向队列中添加节点的时候，没有采用AQS中的那种 形式 //是因为在调用 condition.await()的时候，需要先通过 lock.lock()获取到锁，所以在这一步不会存在竞争 //Condition队列是一个全新的队列 //这里因为没有并发问题，所以写起来就明朗多了，不用各种的CAS操作来保证并发安全了 private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out.  if (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) { //删除所有cancelled状态的节点  unlinkCancelledWaiters(); t = lastWaiter; } //构建节点，初始即为Condition状态。  //如果当前队列为空，就设置为头结点  //如果不为空，就设置为当前tail的next  //最后设置当前节点为尾节点  Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } fullyRelease //这里的fully的意思是，不管发生了几次重入，全部一次性释放 //所以这里是直接拿到当前的state，然后一次性release //并唤醒同步队列中的一个节点 final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } checkInterruptWhileWaiting /** * Checks for interrupt, returning THROW_IE if interrupted * before signalled, REINTERRUPT if after signalled, or * 0 if not interrupted. */ /** * 在唤醒钱被中断，则返回 throw_ie,唤醒后中断则返回 REINTERRUPT * 没有中断，返回0 */ private int checkInterruptWhileWaiting(Node node) { return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; } signal public final void signal() { //首先判断是不是持有锁，如果没有持有锁，则抛出监视器状态异常  if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //唤醒Condition队列的第一个节点  Node first = firstWaiter; if (first != null) doSignal(first); }//唤醒wait队列上的第一个节点 private void doSignal(Node first) { do { //判断是否队列上只有一个节点，如果是，就将lastWaiter 设置为null  if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; //既然要唤醒第一个节点，唤醒后，直接将第一个节点从队列上移除。  first.nextWaiter = null; //通过transferForSignal将节点加入到同步队列中。如果加入失败了，则重新取出wait队列的第一个节点并唤醒。  } while (!transferForSignal(first) \u0026amp;\u0026amp; (first = firstWaiter) != null); }//将wait节点放入到同步队列中 final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ //这里如果CAS失败，说明当前节点的状态已经不是CONDITION，说明已经被其他线程唤醒了。  //返回false之后，外层是一个循环，会继续取出wait队列的第一个节点，继续执行唤醒操作  if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ //将当前节点加入到同步队列，注意，这里enq返回值返回的是假如队列节点的前一个节点，也就是原队尾节点。  Node p = enq(node); int ws = p.waitStatus; //这里的判断非常巧妙，我们知道，我们把Node节点从wait移动到同步队列，如果我们把节点线程唤醒，是没有问题的。  //因为唤醒后执行到await中的acquireQueued的时候，会被重新挂起，但是这样比较耗费性能，是没有必要的。  //所以这里进行了判断，如果移入到同步队列后，发现原尾节点的状态大于0，或者将尾节点的状态改为SIGNAL的时候失败了，才会唤醒。并在acquireQueued中重新整理同步队列并重新挂起。  //这里不挂起是没有问题的，因为在acquireQueued挂起前判断，如果当前节点是第一个节点，会直接获取锁。如果中断唤醒了，或继续从await挂起的地方继续执行，会继续在acquireQueued的地方重新挂起。  if (ws \u0026gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } signalAll public final void signalAll() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //拿到wait队列，执行doSignalAll  Node first = firstWaiter; if (first != null) doSignalAll(first);//理解了signal，理解这里的doSignalAll就很简单了。 //就是遍历wait队列上的节点逐个顺序取出放入到同步队列中。 private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null); } 重点问题总结 下面的一些重点问题，其实在上面方法的部分中已经提到了，这里专门整理出来，也是为了更方便的查看，AQS中的细节很多，如果全部都去了解需要耗费太多的精力。\n为什么线程被唤醒之后要调用Thread.interrupted()清除中断状态 parkAndCheckInterrupt挂起并检查中断状态 我们在上面的这个标题中个，讨论了这个问题。 主要原因就是线程在被中断唤醒之后，去获取锁不一定会成功，如果失败了，还需要继续挂起，如果不清除中断状态，就会无法挂起了，所以这里必须要清除\n为什么需要调用selfInterrupt进行自我中断 上面我们说到，线程在等待锁的状态下，被调用了中断。\n 在执行parkAndCheckInterrupt()方法后，会被清除掉线程的中断状态。 但是会在acquireQueued方法中记录下来被调用了中断的这个事情interrupted = true; 线程在获取到锁之后，会返回中断状态 如果这时候返回的是true，表示线程在这段时间内被中断过，但是线程的中断状态已经被清除了 所以需要调用selfInterrupt自我中断一下，设置中断状态，一遍后面的代码可能会有用到中断状态的地方。 AQS在这里秉持的一个原则就是，我可以不响应中断，但是我不能报中断状态吞掉  唤醒后置节点的时候为什么从Tail开始遍历 这个问题我们在unparksuccessor的代码注释中有详细的说明。\nfast path和slow path 在查看synchronized原码的时候就很多次看到fast path和slow path这两个词。这次又在AQS的代码中看到相关的概念，稍微有一点想法，尝试着解释一下。\nfast path\n 我忍为可以理解为一种，使用一种相对比较轻量级的方式来达成目标，但是不能保证一定成功。比如在AQS中这里的fast path指的就是一次CAS操作。  slow path\n-相对的slow path，就是指的一种重量级的方式，可以确保一定会成功。在AQS中，slow path指的就是循环调用CAS操作。操作系统在执行循环操作的时候，会需要一些额外的资源。\n一般在编写过程中，可以先尝试使用一次fast path - 如果成功了则节省了很多资源 - 如果失败了那么在调用slow path，比直接调用slow path只多出了一次fast path操作，消耗也可以接受。\nCANCELED节点 这里我们讨论一下CANCELED状态节点的问题。\nCANCELED节点何时产生 在代码里我们看到CANCELED被直接用到的地方只有两处代码 第二处调用的方法fullyRelease是Condition相关的，我们先不看，主要看第一个方法cancelAcquire。\n我们看这个方法的名字就很清晰，表示取消获取锁，它在什么时候被调用呢?\n我们看到它被调用的地方都很统一，就是在各种各样的获取锁方法中被调用。代码的逻辑也都很一致。\n 在方法中定义一个局部变量 fail = true； 在获取锁成功的时候设置 fail = false; 在finally代码块中判断fail，如果为true，则执行cancelAcquire方法。 这就表示，在获取锁的过程中，只要发生了任何意外情况导致获取锁失败了，像执行出现异常、获取锁超时、获取锁被中断(不响应中断的获取锁除外)都会执行到这个方法。  下面就来看一下这个方法\nprivate void cancelAcquire(Node node) { // Ignore if node doesn\u0026#39;t exist  if (node == null) return; //将节点中的线程设置为null  //设置该节点不关联任何线程，也就是虚节点  node.thread = null; // Skip cancelled predecessors  //跳过前面节点中状态为cancel的节点，把这个节点的前置节点引用指向一个不是cancel状态的节点(0,或者SIGNAL)  Node pred = node.prev; while (pred.waitStatus \u0026gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will  // fail if not, in which case, we lost race vs another cancel  // or signal, so no further action is necessary.  Node predNext = pred.next; // Can use unconditional write instead of CAS here.  // After this atomic step, other Nodes can skip past us.  // Before, we are free of interference from other threads.  //把当前节点的状态设置为取消  node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves.  // 如果当前节点是尾结点，则修改当前节点的前置节点为新的尾结点  if (node == tail \u0026amp;\u0026amp; compareAndSetTail(node, pred)) { //如果修改成功，然后把前置节点的next 设置为null,这时候前置节点已经是尾结点了，所以它没有next节点了  //这一步成功失败，并不重要，如果失败，表示节点已经为null了，或者有新的节点加入，成为了它的next  compareAndSetNext(pred, predNext, null); } else { // If successor needs signal, try to set pred\u0026#39;s next-link  // so it will get one. Otherwise wake it up to propagate.  //如果走到这里，说明要么当前节点不是tail节点  //或者，在cas的时候node不是尾结点了，有新的线程加入成为了新的尾结点。  int ws; //首先判断node节点的前置节点是不是head,如果是则直接走else逻辑  if (pred != head \u0026amp;\u0026amp; //如果node的前置节点不是head  //则判断waitStatus是不是signal  //如果不是signal，则判断是不是非cancelled状态，如果是则cas把状态设置为signal  //判断pred的线程不能为null  ((ws = pred.waitStatus) == Node.SIGNAL || (ws \u0026lt;= 0 \u0026amp;\u0026amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) \u0026amp;\u0026amp; pred.thread != null) { //接下来的操作，我理解就是把node的前置节点和node的next节点，连接起来  Node next = node.next; if (next != null \u0026amp;\u0026amp; next.waitStatus \u0026lt;= 0) compareAndSetNext(pred, predNext, next); } else { //如果是head的话那么现在队列的情况是 head -\u0026gt; node -\u0026gt; node1 -\u0026gt; tail  //这时候 node节点是cancel状态，那么就需要唤醒 node1节点  //唤醒node1 需要传入的是node1的前置节点也就是node，所以 unparkSuccessor(node);  unparkSuccessor(node); } //为什么不是=null呢？  node.next = node; // help GC  } }  设置Node的thread为null 把当前节点的挂到一个非CANCELLED状态的节点上，并没有清除,因为这这里并没有设置pred.next = node 设置当前Node状态为CANCELLED 拿到前置节点的后置节点，一般来说正常情况下，就是Node节点 判断当前节点是不是尾节点 如果是尾节点，就把当前节点的前置节点设为尾节点  如果设置成功，把前置节点(也就是当前的尾节点)的next设置为null(这一步失败了也没有关系)  如果不是尾节点，或者设置尾节点失败(表示有新节点加入成为了新的尾节点)。执行else逻辑  else中的逻辑判断比较复杂，我们单独来看一下\n 首先如果Node节点的前置节点是Head节点,也就是下面这种情况，其中Node表示当前节点，Node节点为CANCELLED状态。本来正常情况下Node节点是下次被唤醒的节点，但是它取消了，那么就应该唤醒它的后置节点node1了。 唤醒它的后置节点后，后置节点会尝试获取锁，这时候如果之前持有锁的线程还没有释放，他会获取失败，然后在shouldParkAfterFailedAcquire方法中，把处于CANCELLED状态的节点移除队列 如果获取成功了，那么前面的节点肯定也会被排除队列了\nHead -\u0026gt; cancelledNode -\u0026gt; node1 如果前置节点不是头结点，并且前置节点的状态不是CANCELLED,后面这些判断条件看看前置节点是不是SIGNAL状态，或者能不能设置为SIGNAL状态\n 如果可以，就把CANCELLED状态节点的后置节点和他的前置节点连接上。相当于把自己踢出队列\nHead -\u0026gt; node1-\u0026gt; cancelledNode -\u0026gt; node2 Head -\u0026gt; node1-\u0026gt; node2  CANCELLED节点何时被踢出 大部分的踢出CANCELLED节点的操作都在shouldParkAfterFailedAcquire方法中完成。也就是这部分代码\nif (ws \u0026gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus \u0026gt; 0); pred.next = node; } 在JDK原码中有很多这种写法，看的有点蒙蒙的，我们把它拆解一下\npred = pred.prev; node.prev = pred; 就是pred，往前挪一个节点，然后node.prev指向新的pred节点。 下面用图来表示一下，tail表示 node节点\n 初始状态，pred指向node3，node.prev指向node3， 因为node3状态为 cancelled,所以pred向前挪一个,指向node2，同时node.prev指向node2 因为node2状态为 cancelled,所以pred向前挪一个,指向node1，同时node.prev指向node1 node1状态为SIGNAL,跳出循环，设置node1.next = node,把node2和node3排除队列  参考 java并发编程系列：牛逼的AQS（上）\n从ReentrantLock的实现看AQS的原理及应用\n公平锁与非公平锁的对比\nReentrantLock Condition源码分析\n","permalink":"https://balvboy.github.io/blog/aqs/","summary":"终于来到了重头戏-AQS,AQS可以说是整个J.U.C的核心，整个工具包中的大部分同步工具都是借助于AQS来实现的。接下来我们将通过Reen","title":"Java同步机制(六)- AQS"},{"content":"Lock接口 Lock接口是J.U.C中的一个接口，为我们提供和Synchronized相似的并发控制功能，但是使用起来比Synchronized更加灵活。 下面我们通过接口中定义的方法来分析一下\npublic interface Lock { //能够保证获得锁  //如果锁再当前不是空闲状态，则会挂起当前线程  void lock(); //解锁  void unlock(); //保证获得锁  //但是在获取锁的过程中，能够响应线程中断，并且抛出中断异常  void lockInterruptibly() throws InterruptedException; //尝试获取锁，不能保证获取成功  //如果获取失败则返回false  //如果获取成功则返回true  boolean tryLock(); //在一段时间内尝试获取锁  //在这段时间内如果锁不是空闲状态则会挂起当前线程  //在获取锁的过程中可以相应中断，抛出终端异常  boolean tryLock(long time, TimeUnit unit) throws InterruptedException; Condition newCondition(); 我们看到，接口中定义了lock和unlock方法，我们可以理解为分别对应了Synchronized的monitorenter和monitorexit。 这两个方法可以说是体现了Lock接口和Synchronized相似的部分。\n那么下面的几个方法就体现了Lock接口和Synchronized的区别，和更加灵活的地方。\nlockInterruptibly方法 这个方法就体现了Lock接口和Synchronized的一个主要区别，就是可以响应中断。\n 在使用Synchronized获取锁，在等待的过程中，如果我们想停止获取锁，是没有办法实现的。\n 而在使用Lock接口的lockInterruptibly方法获取锁的时候，我们可以通过调用线程的interrupt方法，停止线程获取锁。\n  tryLock方法 tryLock就是Lock接口和Synchronized的另一个主要区别了，可以尝试获取锁，从而避免获取锁失败的时候陷入阻塞状态。\n 在使用Synchronized,是没有尝试获取锁这个说法的，你要么获取到锁，要么获取失败，陷入阻塞状态等待获取锁。 使用Lock接口的tryLock()方法,如果获取成功则返回try,如果获取失败则返回false，并不会阻塞线程。  下面另一个版本的tryLock方法，区别不大，只不过是给定了一个尝试获取的时间，并且在这段时间内会响应中断。\nnewCondition方法 newCondition方法，会返回一个Condition对象。对象中的await方法，和signal方法，在功能上大致和wait,notify相同。\nLock接口和Synchronized的区别 Lock更加灵活 我们都说Lock比Synchronized更灵活。但是具体怎么灵活呢，通过上面Lock接口定义的几个方法，我理解主要在下面几个方面。\n Lock提供了尝试获取方法tryLock()\n Lock提供了尝试获取方法，既拿不到锁立即返回 相对应的Synchronized则没有，一旦使用，则必须获取成功才能继续往下执行  Lock提供了可响应中断的获取锁方法\n Lock提供了可中断的获取锁方法，lockInterruptibly()和tryLock(long time,TimeUnit unit)。既线程在获取Lock的挂起过程中是可以响应中断的，开发者可以通过这种方法来终止获取锁。 Synchronized则不可以，线程在Synchronized的挂起过程中，不可响应中断操作，一旦开始，就无法停止。  Condition机制\n Condition还需要在好好理解一下，还是不太懂 todo   性能与便利性  性能\n 我自己理解，性能方面已经不是Lock和Synchronized的主要区别了，我们知道Lock主要是依赖AQS来实现的，但是熟悉Synchronized应该也知道，Synchronized优化后，性能强了不少。并且Synchronized的重量级锁实现和AQS有很多类似的地方。  方便性\n 在使用便利性上Synchronized还有有一些优势的，因为Synchronized可以省掉一步手动释放锁的操作。JVM帮我们完成了释放的操作。 另一点，除了开发上的便利性，在调试上Synchronized也是有一定优势的，因为毕竟是JVM原生提供的，所以在使用JVM的命令,比如jstack调试的时候，能够方便的看到Synchronized相关的信息。而Lock就不可以了。   Lock合AQS的关系 Lock接口是定义了一种锁的行为，并没有规定具体的实现方式。 我们常见的Lock接口的实现类ReentranLock，就是使用的AQS，实现的Lock接口中定义的各种行为。\n所以说Lock接口是，定义了锁的行为，AQS是其中的一种实现方式。\n","permalink":"https://balvboy.github.io/blog/lock/","summary":"\u003ch1 id=\"lock接口\"\u003eLock接口\u003c/h1\u003e\n\n\u003cp\u003e\u003ccode\u003eLock\u003c/code\u003e接口是\u003ccode\u003eJ.U.C\u003c/code\u003e中的一个接口，为我们提供和\u003ccode\u003eSynchronized\u003c/code\u003e相似的并发控制功能，但是使用起来比\u003ccode\u003eSynchronized\u003c/code\u003e更加灵活。\n下面我们通过接口中定义的方法来分析一下\u003c/p\u003e","title":"Java同步机制(五)-Lock接口"},{"content":" LockSupport LockSupport是Java中实现同步的一个重要方式，LockSupport提供了阻塞线程和唤醒线程的功能。\nLockSupport中的方法 LockSupport中提供了一系列的park，unpark方法供我们进行挂起和唤醒。\npark和unpark 我们看到6个park方法，可以分为了3类分别是\n park() 一直阻塞 parkNanos() 阻塞指定的纳秒数 parkUntil() 阻塞到指定的时间，是时间的毫秒值  还有1个unpark方法\n unpark(Thread) 唤醒指定线程  Blocker 然后每一类方法，都有一个带有Object参数的版本。比如park(Object)方法。\n 获得了当前线程， 然后把传入的对象，通过Unsafe把对象设置到Thread中的parkObject属性。   然后会调用Unsafe的park方法挂起当前线程。 然后待线程被唤醒后，设置blocker为null  那设置和不设置的区别是什么呢? 这个Blocker对象是用来记录线程被阻塞时被谁阻塞的，主要用于线程监控和分析工具来定位原因的。\nLockSupport的使用 先用代码来展示一下LockSupport最简单的使用方式。\n@Test public void testPark() throws InterruptedException { Object parkObject = \u0026#34;I am parkObject\u0026#34;; Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;t1调用park\u0026#34;); LockSupport.park(parkObject); System.out.println(\u0026#34;t1被唤醒了\u0026#34;); }); t1.start(); Thread.sleep(1000); Thread t2 = new Thread(() -\u0026gt; { System.out.println( LockSupport.getBlocker(t1)); System.out.println(\u0026#34;t2调用unpark\u0026#34;); LockSupport.unpark(t1); }); t2.start(); } 执行结果是\nt1调用park t2调用unpark t1被唤醒了,阻塞了1003ms OK,其实上面的代码就能够展示出LockSupport的绝大部分场景的用法了。一个线程因为某些原因调用park方法阻塞，然后另一个线程在达到某些条件的时候，通过unpark唤醒这个线程。\n在LockSupport的注释中有这么一句话\n/** Additionally, {@code park} will return if the caller\u0026#39;s thread was interrupted, and timeout versions are supported. The {@code park} method may also return at any other time, for \u0026#34;no reason\u0026#34;, so in general must be invoked within a loop that rechecks conditions upon return. **/ 意思是，park()方法会在调用线程被终端的时候返回。 park()方法还可以在其他任何时间“毫无理由”地返回，因此通常必须在重新检查返回条件的循环里调用此方法。\n这就意味着，当我们使用了LockSupport.park(),进行阻塞。当这个方法突然返回的时候，有可能并不是我们调用了unpark()方法导致的。 所以我们需要在循环代码中是否符合业务逻辑，只有确认了是我们自己调用了unpark()触发的才可以。\n所以我们看到AQS中对于LockSupport.park()的使用，都是在循环中使用的。\n简单理解LockSupport阻塞的原理 下面来简单的理解一下LockSupport的原理。\n每一个线程内部都有一个permit,许可证的概念 线程在初始化的时候，permit为0。 当在线程中调用LockSupport.park()方法的时候，会消耗掉一个permit。\n 如果此时线程中permit为0，线程就会挂起 如果此时permit为1，则park()方法会立刻返回，并消耗一个permit，线程内的permit变为0  调用LockSupport.unpark()方法的时候，会生产一个permit。如果该线程因为调用了park()方法而挂起，同时也会唤醒该线程。\n 不管调用多少次unpark,线程中permit的数量最多就是1。  通过上面描述，我们发现LockSupport的工作原理，很像一个信号量为1的Semaphore。 park为加锁，unpark为解锁。\nLockSupport和线程中断 除了unpark能唤醒park挂起的线程外，调用线程的interrupt()方法也能唤醒线程。 对于interrupt()方法，我们了解，\n 当一个线程处于sleep，或者wait的阻塞状态的时候。如果这个时候调用线程的interrupt方法，线程会抛出InterruptedException，并清除掉线程的中断状态。 如果线程处于运行状态，那么调用线程的interrupt()方法，则不会发生任何异常，只会把线程的中断状态设置为true。 如果使用interrupt()打断一个，通过park挂起的线程，线程会被唤醒，但是不会抛出异常，并且保留线程的中断状态。  而且如果一个线程的中断状态为true，就算没有permit，park()方法也会失效。 我们通过下面的代码来说明一下。\n@Test public void testInterruptAndPark() throws InterruptedException { Thread thread = new Thread(() -\u0026gt; { System.out.println(\u0026#34;自己中断\u0026#34;); Thread.currentThread().interrupt(); System.out.println(\u0026#34;打印线程中断状态：\u0026#34; + Thread.currentThread().isInterrupted()); System.out.println(\u0026#34;开始park\u0026#34;); long st = System.currentTimeMillis(); LockSupport.park(); System.out.println(\u0026#34;park结束,持续时间:\u0026#34; + (System.currentTimeMillis() - st)); st = System.currentTimeMillis(); LockSupport.park(); System.out.println(\u0026#34;park结束,持续时间:\u0026#34; + (System.currentTimeMillis() - st)); }); thread.start(); Thread.sleep(100000); } 执行结果\n自己中断 打印线程中断状态：true 开始park park结束,持续时间:1 park结束,持续时间:0 我们在一个线程中，让它自己调用了interrupt方法，然后调用了两次park()方法，然后两次park()方法都失效了。 所以说线程的中断状态，会影响park()的挂起，下面我我们会从源码上来找一下原因。\n源码分析 park和unpark源码 LockSupport.park()方法调用的是本地方法。在JVM中最终调用的是Parker类的park方法，这个方法针对不同平台有不同的实现，这里我们主要看一下Linux平台下的实现。\n// thread.hpp class Thread { // OS data associated with the thread  OSThread* _osthread; // Platform-specific thread information  ParkEvent * _ParkEvent; // for synchronized(), wait  ParkEvent * _SleepEvent; // for Thread.sleep  // JSR166 per-thread parker  Parker* _parker; // for LockSupport::park  //... }; class JavaThread: public Thread { // 指向Java Thread实例, oop是HotSpot里指向一个Java level的实例, 一个gc对象.  oop _threadObj; // The Java level thread ,  JavaFrameAnchor _anchor; // Encapsulation of current java frame and it state  CompiledMethod* _deopt_nmethod; // CompiledMethod that is currently being deoptimized  //  volatile JavaThreadState _thread_state; //... }; 我们先来看一下JVM中Thread的定义,Thread 类里有两个 ParkEvent 和一个 Parker, 其实 ParkEvent 和 Parker 实现和功能十分类似。\n _ParkEvent 是实现 synchronized 关键字，wait，notify 用的， _SleepEvent 是给 Thread.sleep 用的。 _parker 是用来实现 J.U.C 的 LockSupport的park/unpark (阻塞 / 唤醒)。\npublic: Parker() : PlatformParker() { _counter = 0 ; FreeNext = NULL ; AssociatedWith = NULL ; }  我们再来看一下Parker的结构。 我们主要看_counter这个字段，这个其实就是我们上面说到的permit。\n// src/hotspot/os/posix/os_posix.cpp //isAbsolute 表示后面的时间是绝对时间还是相对时间 void Parker::park(bool isAbsolute, jlong time) { // 设置_counter为0，并且判断原值  // 如果别的线程已经unpark了我.  // 这里没有使用锁机制，需要Atomic::xchg和barrier保证lock-free代码的正确.  // We depend on Atomic::xchg() having full barrier semantics  // since we are doing a lock-free update to _counter.  if (Atomic::xchg(0, \u0026amp;_counter) \u0026gt; 0) return; Thread* thread = Thread::current(); assert(thread-\u0026gt;is_Java_thread(), \u0026#34;Must be JavaThread\u0026#34;); JavaThread *jt = (JavaThread *)thread; // 如果线程被中断，直接返回  if (Thread::is_interrupted(thread, false)) { return; } // safepoint region相关, 我对细节不详.  // safepoint region大致的了解, 见RednaxelaFX的回答https://www.zhihu.com/question/29268019  ThreadBlockInVM tbivm(jt); // 再次判断线程是否被中断，如果没有被中断，尝试获得互斥锁，如果获取失败，直接返回  // 如果别的线程正在unpark我, 而持有了mutex, 我先返回了,没有必要在_mutex上等  if (Thread::is_interrupted(thread, false) || pthread_mutex_trylock(_mutex) != 0) { return; } // 如果别的线程已经unblock了我, no wait needed  // 已经拿到了mutex, 所以不需要和前面一样Atomic::xchg了.因为已经拿到了锁  int status; if (_counter \u0026gt; 0) { _counter = 0; status = pthread_mutex_unlock(_mutex); OrderAccess::fence(); return; } // 记录线程的状态  OSThreadWaitState osts(thread-\u0026gt;osthread(), false /* not Object.wait() */); jt-\u0026gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() or java_suspend_self()  // 这一坨, 就是block自己这个线程了.(Java层当前执行的线程)  if (time == 0) { _cur_index = REL_INDEX; // arbitrary choice when not timed  status = pthread_cond_wait(\u0026amp;_cond[_cur_index], _mutex); } else { _cur_index = isAbsolute ? ABS_INDEX : REL_INDEX; status = pthread_cond_timedwait(\u0026amp;_cond[_cur_index], _mutex, \u0026amp;absTime); } _cur_index = -1; // 已经从block住状态中恢复返回了, 把_counter设0.  _counter = 0; status = pthread_mutex_unlock(_mutex); // 要保证多线程的正确性要十二分小心  // 这里的memory fence 是一个lock addl 指令, 加上compiler_barrier  // 保证_counter = 0 是对调用unlock线程是可见的.  // Paranoia to ensure our locked and lock-free paths interact  // correctly with each other and Java-level accesses.  OrderAccess::fence(); // 已经醒过来, 但如果有别人在suspend我,那么继续suspend自己.  // If externally suspended while waiting, re-suspend  if (jt-\u0026gt;handle_special_suspend_equivalent_condition()) { jt-\u0026gt;java_suspend_self(); } }// src/hotspot/os/posix/os_linux.cpp void Parker::unpark() { int status = pthread_mutex_lock(_mutex); assert_status(status == 0, status, \u0026#34;invariant\u0026#34;); const int s = _counter; _counter = 1; // must capture correct index before unlocking  int index = _cur_index; status = pthread_mutex_unlock(_mutex); assert_status(status == 0, status, \u0026#34;invariant\u0026#34;); // s记录的是unpark之前的_counter数，如果s \u0026lt; 1，说明有可能该线程在等待状态，需要唤醒。  if (s \u0026lt; 1 \u0026amp;\u0026amp; index != -1) { // 发信号唤醒线程  status = pthread_cond_signal(\u0026amp;_cond[index]); assert_status(status == 0, status, \u0026#34;invariant\u0026#34;); } } 简单总结一下这两个流程，(不会分析每一行代码的作用)\npark\n 首先把_counter设置为0，并判断如果之前为1的话直接返回 检查线程的中断状态，如果处于中断状态，则直接返回 设置线程状态 调用pthread相关函数阻塞线程（线程进入阻塞状态，等待阻塞超时或者被唤醒） 阻塞超时结束，或者被唤醒之后，设置_counter为0  unpark\n 把_counter设置为1 判断_counter原值，如果小于1，则表示有可能有线程在阻塞（这里并不是一定，因为初始的时候_counter为0）  interrupt源码 我们上面说到，interrupt()方法，也能唤醒通过park阻塞的线程，那我们就来看一下interrupt的源码.\n//hotspot\\src\\os\\linux\\vm\\os_linux.cpp void os::interrupt(Thread* thread) { assert(Thread::current() == thread || Threads_lock-\u0026gt;owned_by_self(), \u0026#34;possibility of dangling Thread pointer\u0026#34;); // 获取  OSThread* osthread = thread-\u0026gt;osthread(); if (!osthread-\u0026gt;interrupted()) { osthread-\u0026gt;set_interrupted(true); // More than one thread can get here with the same value of osthread,  // resulting in multiple notifications. We do, however, want the store  // to interrupted() to be visible to other threads before we execute unpark().  OrderAccess::fence(); ParkEvent * const slp = thread-\u0026gt;_SleepEvent ; if (slp != NULL) slp-\u0026gt;unpark() ; } // For JSR166. Unpark even if interrupt status already was set  if (thread-\u0026gt;is_Java_thread()) ((JavaThread*)thread)-\u0026gt;parker()-\u0026gt;unpark(); ParkEvent * ev = thread-\u0026gt;_ParkEvent ; if (ev != NULL) ev-\u0026gt;unpark() ; }  每一个Java线程都与一个osthread一一对应，如果相应的os线程没有被中断，则会设置osthread的interrupt标志位为true。 并唤醒线程的_SleepEvent 随后唤醒线程的parker和ParkEvent。  总结 通过查看源码，我们对LockSupport的实现原理有了进一步的了解。\n 当调用LockSupport.park()的时候，最终调用的是JVM中Thread对象Parker变量的park()方法 在park()方法中，会判断_counter属性（也就是permit）,然后检查线程的中断状态 然后会调用pthread_cond_wait,pthread_cond_timedwait阻塞线程 当调用LockSupport.park(Thread)的时候，最终调用的是JVM中Thread对象Parker变量的unpark()方法 在unpark()方法中，也会判断_counter属性，然后通过pthread_cond_signal来环境阻塞的线程。 当调用了线程的interrupt方法，最终执行的是os::interrupt()(Linux平台) 在os::interrupt()方法中，会设置线程的中断状态，并对JVM线程持有的SleepEvent,Parker,_ParkEvent三个属性，执行unpark()方法  LockSupport和wait、sleep的对比  park、unpark方法和wait、notify()方法有一些相似的地方。都是休眠，然后唤醒。但是wait、notify方法有一个不好的地方，就是我们在编程的时候必须能保证wait方法比notify方法先执行。 如果notify方法比wait方法晚执行的话，就会导致因wait方法进入休眠的线程接收不到唤醒通知的问题。\n 而park、unpark则不会有这个问题，我们可以先调用unpark方法释放一个许可证，这样后面线程调用park方法时，发现已经许可证了，就可以直接获取许可证而不用进入休眠状态了。\n 另外，和wait方法不同，执行park进入休眠后并不会释放持有的锁。\n 对中断的处理，park()方法阻塞的时候，调用终端，会取消阻塞，但是不会抛出中断异常。\n  参考 [并发系列-4] 从AQS到futex(二): HotSpot的JavaThread和Parker\nLockSupport源码分析\nJava Thread 和 Park\nThread.interrupt()相关源码分析\nThread.sleep、Object.wait、LockSupport.park 区别\n","permalink":"https://balvboy.github.io/blog/locksupport/","summary":"LockSupport LockSupport是Java中实现同步的一个重要方式，LockSupport提供了阻塞线程和唤醒线程的功能。 LockSupport中的","title":"Java同步机制(四)-LockSupport"},{"content":" #JMM\n什么是Memory Model 想要了解JMM，我们先来了解一下什么是内存模型，下面是JMM规范中对内存模型的描述。\n A high level, informal overview of the memory model shows it to be a set of rules for when writes by one thread are visible to another thread.\n 内存模型是规定了一个线程的修改什么时候可能对其他线程可见的一组规则。\n既然是规则，那么就会有强弱之分，所以就会多种不同的内存模型。\n各种内存模型在设计的时候，需要考虑程序员在编程的时候的难易程度，还有程序的执行性能。\n 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。  这些内存模型我们可以简单的分为\n 语言级内存模型，比如(JMM、C++11MM等等) 处理器内存模型，比如(TSO,PSO,RMO,PowerPC)  下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图：\n顺序一致性模型 顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。各种内存模型在设计的时候通常会把顺序一致性模型作为参考。然后在实现的时候会对顺序一致性模型做一些放松 因为如果完全按照顺序一致性模型来实现处理器和语言内存模型，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。\n处理器内存模型 根据对不同类型读 / 写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型：\n 放松程序中写 - 读操作的顺序，由此产生了 total store ordering 内存模型（简称为 TSO）。 在前面 1 的基础上，继续放松程序中写 - 写操作的顺序，由此产生了 partial store order 内存模型（简称为 PSO）。 在前面 1 和 2 的基础上，继续放松程序中读 - 写和读 - 读操作的顺序，由此产生了 relaxed memory order 内存模型（简称为 RMO）和 PowerPC 内存模型。  注意，这里处理器对读 / 写操作的放松(重排序)，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守 as-if-serial 语义，处理器不会对存在数据依赖性的两个内存操作做重排序）\n下面的表格展示了常见处理器内存模型的细节特征：\n 在这个表格中，我们可以看到所有处理器内存模型都允许写 - 读重排序，原因在第一章以说明过：它们都使用了写缓存区，写缓存区可能导致写 - 读操作重排序。同时，我们可以看到这些处理器内存模型都允许更早读到当前处理 器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。 上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。  Java Memory Model 了解完内存模型，我们来说回JMM。\nJMM是Java的设计者们权衡出来的一套规则。JMM的实现最终还是要借助于JVM编译器和各种处理器的内存模型。\n如果一个处理器的内存模型强于JMM，那么对于JMM来说就不需要做任何额外的操作了，反之如果处理器的内存模型弱于JMM，那么JVM要想在这个处理器上依然能够实现JMM的规则，就需要一些 额外的操作，让处理器能够达到JMM的要求。这里的额外操作，就是指内存屏障。\nJMM在不同处理器上的实现 由于常见的处理器内存模型比 JMM 要弱，java 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。 同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型， JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了 JMM 在不同处理器内存模型中需要插入的内存屏障的示意图：\n如上图所示，JMM 屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为 java 程序员呈现了一个一致的内存模型。\nHappens-Before 上面我们说到，内存模型，就是规定了一个线程中的修改什么时候可以对其他线程可见的规则。在JMM中使用happens-before这个概念来描述两个操作之间的可见性。 这两个操作既可以是在同一个线程，也可以是在不同的线程中。JMM中定义了8种关于happens-before的规则\n 单一线程原则：在一个线程内，在程序前面的操作先行发生(happens-before)于后面的操作。 监视器锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 volatile 变量规则：对一个 volatile 变量的写操作先行发生于(happens-before)后面对这个变量的读操作。 线程启动规则：Thread 对象的 start() 方法调用先行发生(happens-before)于此线程的每一个动作。 线程加入规则：Thread 对象的结束先行发生于 join() 方法返回。 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生 对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。  这种先行发生的需求，在我们的代码中也十分常见。在我们的逻辑中，经常会有这样的要求，先执行操作A，然后在执行操作B。也就是要求 操作A happens before 操作B\n 在单线程中，我们需要把操作A的代码写在操作B之前，就能实现。\n 多线程中，我们则需要对操作A和操作B，进行正确的同步操作。\n  Happens-Before和执行顺序 比如说现在有 操作1 happens before 操作2两个操作之间没有数据依赖。那么请问操作1一定在操作2之前被执行吗？\n答案是不一定，这里唯一的例外就是在单线程情况下。\n单线程\n在单线程下，编译器和处理器遵循as-if-serial语义，保证不管怎么重排序也不会改变程序的执行结果。所以这里会对没有数据依赖的执行重排序。 所以这种情况下，虽然操作2可能会在操作1之前被执行，但是因为不影响程序结果，就像是按顺序执行一样，所以我们也认为这种是符合 操作1 happens before 操作2的。\n多线程\n在多线程中，如果两个线程中的操作1和操作2，满足操作1 happens before 操作2,那么我们就可以说，操作1一定在操作2之前被执行。\nJMM中对long和double类型的读取 JVM规定 - 实现对普通long与double的读写不要求是原子的（但如果实现为原子操作也OK） - 实现对volatile long与volatile double的读写必须是原子的（没有选择余地）\n所以是否是原子操作，需要看虚拟机的自己的实现。\n目前情况是，是否为原子操作，和JVM所处的硬件平台，处理器位数都有关系。但是JVM提供了-XX:+AlwaysAtomicAccesses参数，来保证原子操作。\n具体的测试可以查看这个文章 All Accesses Are Atomic\n目前我们关注的，在目前intel平台的x64 hotspot jvm中，long 、double的访问是原子的.\n总结 因为在不同的硬件生产商和不同的操作系统下，内存的访问逻辑有一定的差异，结果就是当你的代码在某个系统环境下运行良好，并且线程安全，但是换了个系统就出现各种问题。为了解决这个问题，Java 内存模型(JMM)的概念就被提出来了，来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n总的来说，就是JMM就是Java为开发者提供的，屏蔽了硬件差异，在多线程环境下保证线程间可见性的一套规则。\n开发者按照这套规则开发代码逻辑，就能够在不同的硬件平台，获得一致的内存访问效果。\n参考 JVM 基础 - Java 内存模型详解 Java 内存模型（Java Memory Model） 全面理解Java内存模型(JMM)及volatile关键字\n","permalink":"https://balvboy.github.io/blog/jmm/","summary":"#JMM 什么是Memory Model 想要了解JMM，我们先来了解一下什么是内存模型，下面是JMM规范中对内存模型的描述。 A high level, informal overview of the memory model shows it to be a set of rules","title":"Java同步机制(三)-JMM"},{"content":" volatile在Java中的语义 对于volatile我们都比较熟悉，volatile在Java中有两种作用\n 保障字段在多线程之间的可见性 防止指令进行重排序(编译器层面和CPU层面，后面会说明)  下面我就来看一下jvm是如何实现这两种作用的\nJVM对volatile的实现 volatile关键字只能用来修饰属性。对于属性有获取和设置两种操作，所以我们就从这两种操作入手分析一下JVM对volitile的处理。\n上面的两种操作在字节码中对应着 getfield，getstatic和putfield，putfield这四种字节码。\n我们去bytecodeinterpreter.cpp看一下对应的实现逻辑。(说明一下，JVM现在使用的是模板编译器的，但是字节码编译器可读性比较好，用来学习还是比较合适的)\n我们找到上面几个字节码的执行位置\n... CASE(_getfield): CASE(_getstatic): { ... if (cache-\u0026gt;is_volatile()) { if (support_IRIW_for_not_multiple_copy_atomic_cpu) { OrderAccess::fence(); } ... } ... }... CASE(_putfield): CASE(_putstatic): { ... if (cache-\u0026gt;is_volatile()) { ... OrderAccess::storeload(); } ... } 可以看到，在访问对象字段的时候，会先判断它是不是volatile的，如果是的话，并且当前CPU平台支持多核核atomic操作的话（现代的绝大多数的CPU都支持），然后就调用OrderAccess::fence()。 在设置字段的时候，会使用OrderAccess::storeload(); 这两个就是JVM提供的内存屏障。\nJVM提供的内存屏障 JVM中，所有内存屏障的使用都由OrderAccess来提供。在OrderAccess.hpp中说明了JVM提供的几种内存屏障。\n// Memory Access Ordering Model // // This interface is based on the JSR-133 Cookbook for Compiler Writers. // // In the following, the terms \u0026#39;previous\u0026#39;, \u0026#39;subsequent\u0026#39;, \u0026#39;before\u0026#39;, // \u0026#39;after\u0026#39;, \u0026#39;preceding\u0026#39; and \u0026#39;succeeding\u0026#39; refer to program order. The // terms \u0026#39;down\u0026#39; and \u0026#39;below\u0026#39; refer to forward load or store motion // relative to program order, while \u0026#39;up\u0026#39; and \u0026#39;above\u0026#39; refer to backward // motion. // // We define four primitive memory barrier operations. // // LoadLoad: Load1(s); LoadLoad; Load2 // // Ensures that Load1 completes (obtains the value it loads from memory) // before Load2 and any subsequent load operations. Loads before Load1 // may *not* float below Load2 and any subsequent load operations. // // StoreStore: Store1(s); StoreStore; Store2 // // Ensures that Store1 completes (the effect on memory of Store1 is made // visible to other processors) before Store2 and any subsequent store // operations. Stores before Store1 may *not* float below Store2 and any // subsequent store operations. // // LoadStore: Load1(s); LoadStore; Store2 // // Ensures that Load1 completes before Store2 and any subsequent store // operations. Loads before Load1 may *not* float below Store2 and any // subsequent store operations. // // StoreLoad: Store1(s); StoreLoad; Load2 // // Ensures that Store1 completes before Load2 and any subsequent load // operations. Stores before Store1 may *not* float below Load2 and any // subsequent load operations.  // 省略 acquire and release 部分内容  // Finally, we define a \u0026#34;fence\u0026#34; operation, as a bidirectional barrier. // It guarantees that any memory access preceding the fence is not // reordered w.r.t. any memory accesses subsequent to the fence in program // order. This may be used to prevent sequences of loads from floating up // above sequences of stores.  通过上面的注释我们知道，JVM根据JSR-133 Cook Book定义了4种基本的内存屏障操作，并由下面的几种作用。\n   内存屏障 使用方法 作用     LoadLoad Load1 LoadLoad Load2 确保Load1一定是在\nLoad2以及其后的指令之前完成   StoreStore Store1 StoreStore Store2 确保 Store1 一定是在\nStore2 以及其后的指令之前完成\n（同时，Store1的写入数据会立即被其他 CPU看到   LoadStore Load1 LoadStore Store2 确保 Load1 一定是在\nStore2 以及其后的指令之前完成   StoreLoad Store1 StoreLoad Load2 确保 Store1 一定在 Load2 以及其后的指令之前完成    我们看到，在常见的4中基本内存屏障之后，还单独定义了fence操作，fence操作的功能可以说涵盖了上面的4中基本屏障。它可以保证fence前的任何操作op1都在op2之前完成。\nJVM为每种屏障类型都定义了一个单独的方法，带代码中如果需要某种屏障可能直接调用。\nstatic void loadload(); static void storestore(); static void loadstore(); static void storeload(); static void acquire(); static void release(); static void fence(); volatile和硬件的关系 volatile在上面提到的两个功能，都是通过JVM定义的内存屏障来实现的。 而JVM定义的内存屏障可以理解是一个规范，它要求不管在什么平台上都要有同样的效 果。但是最终还是要依靠硬件来实现。所以们可以看到，在JVM中对于各种硬件平台都有对应的内存屏障实现。\n因为我们在服务器领域还是使用Linux比较多，而且大部分使用的是Intel的CPU，所以下面我们先关注一下linux_x86的实现\nlinux_x86内存屏障实现 static inline void compiler_barrier() { __asm__ volatile (\u0026#34;\u0026#34; : : : \u0026#34;memory\u0026#34;); } inline void OrderAccess::loadload() { compiler_barrier(); } inline void OrderAccess::storestore() { compiler_barrier(); } inline void OrderAccess::loadstore() { compiler_barrier(); } inline void OrderAccess::storeload() { fence(); } inline void OrderAccess::acquire() { compiler_barrier(); } inline void OrderAccess::release() { compiler_barrier(); } inline void OrderAccess::fence() { if (os::is_MP()) { // always use locked addl since mfence is sometimes expensive #ifdef AMD64  __asm__ volatile (\u0026#34;lock; addl $0,0(%%rsp)\u0026#34; : : : \u0026#34;cc\u0026#34;, \u0026#34;memory\u0026#34;); #else  __asm__ volatile (\u0026#34;lock; addl $0,0(%%esp)\u0026#34; : : : \u0026#34;cc\u0026#34;, \u0026#34;memory\u0026#34;); #endif  } compiler_barrier(); } 我们看上面用到的fence()和storeload()方法，都其实最终调用的都是fence()方法。其他的都是调用的compiler_barrier()方法。 然后这里两个方法里面都是使用的内嵌汇编指令的方式，所以我们下来分析一下这个内嵌汇编指令的格式。\n内嵌汇编指令 内嵌汇编指令的格式是\n__asm__　__volatile__(\u0026quot;Instruction List\u0026quot; : Output : Input : Clobber/Modify);\n __asm__或asm 用来声明一个内联汇编表达式，所以任何一个内联汇编表达式都是以它开头的，是必不可少的。 __volatile__或volatile 是可选的。如果用了它，表示防止编译器对代码块进行优化。  而这里的优化是针对代码块而言的，使用嵌入式汇编的代码分成三块： 嵌入式汇编之前的代码块 嵌入式汇编代码块 嵌入式汇编之后的c代码块 所以使用了volatile修饰的内嵌汇编的意思是，防止编译器对汇编代码块及前后的代码进行重排序等优化。  Instruction List 是要执行的汇编指令序列。它可以是空的。 Output和Input是汇编指令中的输入和输出，都可以为空，这里我们不做过多分析 Clobber/Modify是寄存器/内存修改标示。通知GCC当前内联汇编语句可能会对某些寄存器或内存进行修改,希望GCC在编译时能够将这一点考虑进去,这会对GCC在编译的时候有一些影响，但具体是什么影响我们就不深究了。  了解了内嵌汇编代码的格式，我们再来看上面的两个方法。\ncompiler_barrier()：__asm__ volatile (\u0026quot;\u0026quot; : : : \u0026quot;memory\u0026quot;);\n禁止编译器对汇编代码前后的代码块，进行重排序等优化，并且告诉编译器我修改了memory中的内容\nfence():__asm__ volatile (\u0026quot;lock; addl $0,0(%%esp)\u0026quot; : : : \u0026quot;cc\u0026quot;, \u0026quot;memory\u0026quot;);\n禁止编译器对汇编代码前后的代码块，进行重排序等优化,并且执行 lock; addl $0,0(%%esp)这条汇编指令，并且告诉编译器我修改了memory中的内容\nLock前缀指令 通过上面我们已经知道，JVM通过使用带有volatile关键字的内嵌汇编的方便，解决了编译器重排序的问题。那么CPU级别的重排序，和内存间的可见性是怎么实现的呢，下面我们就要用到Lock指令了。\n我们看到在fence()方法内嵌的汇编代码中，使用了lock前缀指令，那lock前缀指令在这里起到的是什么作用呢。\nLock前缀指令的作用 在Intel 用户开发手册中关于lock前缀有这样的描述。\nIntel开发手册下载地址\n8.1- LOCKED ATOMIC OPERATIONS\n The processor uses three interdependent mechanisms for carrying out locked atomic operations:\n• Guaranteed atomic operations\n• Bus locking, using the LOCK# signal and the LOCK instruction prefix\n• Cache coherency protocols that ensure that atomic operations can be carried out on cached data structures (cache lock); this mechanism is present in the Pentium 4, Intel Xeon, and P6 family processors\n 意思是，我们有3种方式可以实现CPU的原子操作\n 使用被保证的原子操作，比如读写1byte等 使用lock指令作为指令前缀 使用缓存一致性协议  所以使用lock指令作为前缀，能够把它后面的一个或者几个操作\u0026rsquo;包装\u0026rsquo;为一个原子操作。不过你可能会想，那这么说来lock的作用和我们使用它的目前好像不大一样啊，可见性呢？重排序呢？别急我们继续看。\nLock前缀保证可见性 lock前缀指令的实现方法，在早期CPU和现代CPU中有很大不同,我们还是引用开发手册中的描述\n8.1.2-Bus Locking\n In the case of the Intel386, Intel486, and Pentium processors, explicitly locked instructions will result in the asser- tion of the LOCK# signal. It is the responsibility of the hardware designer to make the LOCK# signal available in system hardware to control memory accesses among processors.\nFor the P6 and more recent processor families, if the memory area being accessed is cached internally in the processor, the LOCK# signal is generally not asserted; instead, locking is only applied to the processor’s caches\n 意思是，在早期的CPU中，当使用lock前缀指令时候，会导致产生一个LOCK#信号，通过总线锁定对应的内存，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放。 在后来的处理器的处理逻辑中，如果要操作的内存，已经cache到了处理器的缓存中，那么将不会产生LOCK#信号，则通过缓存一致性协议来完成原子性的保证。\n8.1.4-Effects of a LOCK Operation on Internal Processor Caches\n For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is cached in the processor that is performing the LOCK operation as write-back memory and is completely contained in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow it’s cache coherency mechanism to ensure that the operation is carried out atomically. This operation is called “cache locking.” The cache coherency mechanism automatically prevents two or more processors that have cached the same area of memory from simultaneously modifying data in that area.\n 意思是：在LOCK操作中被锁定的内存区域是缓存在执行LOCK操作的处理器中，作为回写存储器，并且完全包含在缓存行中。在一个缓存行中，处理器可能不会在总线上发出LOCK#信号。相反，它将在内部修改内存位置，并允许它的缓存一致性机制确保该操作是原子式进行的。这种操作被称为\u0026rdquo;高速缓存锁定\u0026rdquo;。缓存一致性机制会自动防止两个或更多的处理器在缓存同一区域的内存上同时修改该区域的数据。\n显而易见，使用总线锁定的方式代价要大得多。不过目前在大多数情况下，我们在使用lock指令的时候，都是通过缓存一致性协议来保证的后面操作的原子性操作。但是有一些情况同样也会导致不能使用高速缓存锁定，而只能使用总线锁定，比如涉及到的数据跨越多个CacheLine，CPU不支持缓存锁定等。\n 在 Pentium 和早期的 IA-32 处理器中，lock 前缀会使处理器执行当前指令时产生一个 LOCK# 信号，会对总线进行锁定，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放 后来的处理器，加锁操作是由高速缓存锁代替总线锁来处理。 因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存。 这种场景多缓存的数据一致通过缓存一致性协议(MESI)来保证。  所以总结一下，当我们使用lock前缀指令的时候会发生这两件事\n 要操作的数据在缓存中，会导致其他CPU的缓存行失效 如果数据不再内存中，则会使用总线锁定，把内存中的数据读入或者写出到内存。同时也会导致其他CPU的缓存行失效。  所以使用lock前缀指令，会通过触发缓存一致性协议导致关联的缓存行失效，从而保证可见性。\n可见性我们知道了，那么防止指令重排序的作用呢？我们继续在用户手册中寻找一下答案。\nLock前缀防止指令重排 8.2.5 Strengthening or Weakening the Memory-Ordering Model\n The Intel 64 and IA-32 architectures provide several mechanisms for strengthening or weakening the memory- ordering model to handle special programming situations. These mechanisms include:\n• The I/O instructions, locking instructions, the LOCK prefix, and serializing instructions force stronger ordering on the processor.\n• The SFENCE instruction (introduced to the IA-32 architecture in the Pentium III processor) and the LFENCE and MFENCE instructions (introduced in the Pentium 4 processor) provide memory-ordering and serialization capabilities for specific types of memory operations.\n\u0026hellip; 省略部分\nSynchronization mechanisms in multiple-processor systems may depend upon a strong memory-ordering model. Here, a program can use a locking instruction such as the XCHG instruction or the LOCK prefix to ensure that a read-modify-write operation on memory is carried out atomically. Locking operations typically operate like I/O operations in that they wait for all previous instructions to complete and for all buffered writes to drain to memory\n 意思是，Intel处理器提供了几种机制用来加强或者削弱内存排序。其中使用IO相关指令、锁定指令、LOCK前缀指令、序列化相关指令都能够强化 排序。(这里强化的意思是，更加按照指令流的顺序来执行,也就是减少处理器的重排序)\n在程序中可以使用锁定指令，或者lock前缀指令来强化排序，它们会等待所有先前的指令完成，并等待所有缓冲的写操作耗尽到内存中。\n所以我们看到，JVM通过内嵌lock前缀的汇编指令，保证了可见性和防止了内存重排序。\nLock前缀指令的其他应用 我们经常使用的CAS的底层，也是使用lock前缀实现的，使用lock指令保证了后面的操作的原子性。\n为何x86只实现了storeload内存屏障 还有一点我们在上面的x86的实现中看到，只有fence()方法，和storeload()方法使用lock前缀指令，其他的几种都是只是实现了编译器级别的内存屏障，也就是只能防止编译器的指令重排序。这是为什么呢？\n同样我们在操作手册中寻找一下答案，在操作手册的 8.2.3-Examples Illustrating the Memory-Ordering章节，说明x86处理器对store和load指令的重排序情况\n 8.2.3.2 Neither Loads Nor Stores Are Reordered with Like Operations 8.2.3.3 Stores Are Not Reordered With Earlier Loads 8.2.3.4 Loads May Be Reordered with Earlier Stores to Different Locations  意思是\n load指令和store指令，都不能喝同类型的指令之间发生重排序，也就是 load1,load2 和 store1，store2 是不会发生重排序的 store指令和前面出现的load指令，不会重排序，也就是 load1,store2 不会发生重排序。 load指令，和它前面出现的store指令之间可能会发生重排序。  看到这，我们能知道，x86的CPU，在不添加任何内存屏障的情况下，已经支持了loadload,storestore,loadstore屏障了。只有storeload这种需要单独添加内存屏障来保证不会重排序。\n所以对于x86处理器原生支持的3种屏障，只需要保证编译器不会发生重排序即可。\n所以说，volatile的实现和硬件平台关系非常密切。下面这个是在不同硬件下，发生重排序的情况。\n   处理器 Load-Load Load-Store Store-Store Store-Load 数据依赖     x86 N N N Y N   PowerPC Y Y Y Y N   ia64 Y Y Y Y N    我们看到，x86在loadload,loadStore,storestore 和有数据依赖的时候不会发生重排序。 另外两种平台，只有在有数据依赖的时候不会发生重排序。\n所以JVM需要根据不同平台来进行不同的处理。\n为何x86下JVM使用LOCK前缀实现内存屏障 在Intel的处理器平台下内存屏障分为两类：\n 本身是内存屏障，比如“lfence”，“sfence”和“mfence”汇编指令 本身不是内存屏障，但是被LOCK指令前缀修饰，其组合成为一个内存屏障。在X86指令体系中，其中一类内存屏障常使用“LOCK指令前缀加上一个空操作”方式实现，比如lock addl $0x0,(%esp)  所以有一个疑问，为什么JVM选择使用lock前缀指令来实现内存屏障而不使用专门的内存屏障指令呢？\n我在JVM的源码中搜索了一下mfence,搜索到了下面几段注释\nmacroAssembler_x86.cpp\n// We have a classic Dekker-style idiom: // ST m-\u0026gt;_owner = 0 ; MEMBAR; LD m-\u0026gt;_succ // There are a number of ways to implement the barrier: // (1) lock:andl \u0026amp;m-\u0026gt;_owner, 0 // is fast, but mask doesn\u0026#39;t currently support the \u0026#34;ANDL M,IMM32\u0026#34; form. // LOCK: ANDL [ebx+Offset(_Owner)-2], 0 // Encodes as 81 31 OFF32 IMM32 or 83 63 OFF8 IMM8 // (2) If supported, an explicit MFENCE is appealing. // In older IA32 processors MFENCE is slower than lock:add or xchg // particularly if the write-buffer is full as might be the case if // if stores closely precede the fence or fence-equivalent instruction. // See https://blogs.oracle.com/dave/entry/instruction_selection_for_volatile_fences // as the situation has changed with Nehalem and Shanghai. // (3) In lieu of an explicit fence, use lock:addl to the top-of-stack // The $lines underlying the top-of-stack should be in M-state. // The locked add instruction is serializing, of course. // (4) Use xchg, which is serializing // mov boxReg, 0; xchgl boxReg, [tmpReg + Offset(_owner)-2] also works // (5) ST m-\u0026gt;_owner = 0 and then execute lock:orl \u0026amp;m-\u0026gt;_succ, 0. // The integer condition codes will tell us if succ was 0. // Since _succ and _owner should reside in the same $line and // we just stored into _owner, it\u0026#39;s likely that the $line // remains in M-state for the lock:orl. // // We currently use (3), although it\u0026#39;s likely that switching to (2) // is correct for the future.  orderAccess_linux_x86.inline.hpp\n// always use locked addl since mfence is sometimes expensive  大概意思就是说，mfence目前有几个缺点\n1.并不是所有cpu都支持这个指令。 2. 在最早前的CPU中性能比lock前缀差一些。 3. 有时mfence的性能损耗比较严重\n所以基于以上考虑，目前还是使用lock前缀(我查看的jvm源码是jdk11的)，但是未来很有可能改为使用mfence指令。\nInstruction selection for volatile fences : MFENCE vs LOCK:ADD\n缓存一致性协议 在上面我们不止一次的提到了缓存一致性协议，那么缓存一致性协议具体是什么样的呢？下面我们来简单的了解一下。\n现在处理器处理能力上要远胜于主内存（DRAM），主内存执行一次内存读写操作，所需的时间可能足够处理器执行上百条的指令，为了弥补处理器与主内存处理能力之间的鸿沟，引入了高速缓（Cache),来保存一些CPU从内存读取的数据，下次用到该数据直接从缓存中获取即可，以加快读取速度，随着多核时代的到来,每块CPU都有多个内核，每个内核都有自己的缓存，这样就会出现同一个数据的副本就会存在于多个缓存中，在读写的时候就会出现数据 不一致的情况。\n缓存行 数据在缓存中不是以独立的项来存储的，它不是一个单独的变量，也不是一个单独的指针,它在数据缓存中以缓存行存在的，也称缓存行为缓存条目。目前主流的CPU Cache的Cache Line大小通常是64字节，并且它有效地引用主内存中的一块地址。\n局部性原理 局部性原理：在CPU访问存储设备时，无论是存取数据或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。\n 时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如程序中的循环、递归对数据的循环访问， 主要体现在指令读取的局部性 空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如程序中的数据组的读取或者对象的连续创建， 对内存都是顺序的读写，主要体现在对程序数据引用的局部性  MESI协议 MESI是众多缓存一致性协议中的一种，也在Intel系列中广泛使用的缓存一致性协议 缓存行（Cache line）的状态有Modified、Exclusive、 Share 、Invalid，而MESI 命名正是以这4中状态的首字母来命名的。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一。\n   状态 描述 监听任务     M 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。   E 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。 缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。   S 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）   I 该Cache line无效。 无    监听任务  一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回主内存 一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。 一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S  嗅探协议 上面提到的监听任务大多数都是通过嗅探(snooping)协议来完成的\n “窥探”背后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源， 所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道， 而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知， 它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。\n MESI读取缓存流程 CPU1需要读取数据X，会根据数据的地址在自己的缓存L1A中找到对应的缓存行,然后判断缓存行的状态\n 如果缓存行的状态是M、E、S，说明该缓存行的数据对于当前读请求是可用的，则可以直接使用 如果缓存行的状态是I，则说明该缓存行的数据是无效的，则CPU1会向总线发送Read消息，说’我现在需要地址A的数据，谁可以提供？‘，其它处理器会CPU2监听总线上的消息，收到消息后，会从消息中解析出需要读取的地址， 然后在自己缓存中查找缓存行，这时候根据找到缓存行的状态会有以下几种情况  状态为S/E , CPU2会构造Read Response消息，将相应缓存行中的数据放到消息中，发送到总线同时更新自己缓存行的状态为S，CPU1收到响应消息后，会将消息中的数据存入相应的缓存行中，同时更新缓存行的状态为S 状态为M，会先将自己缓存行中的数据写入主内存，并响应Read Response消息同时将L1B中的相应的缓存行状态更新为S 状态为I或者在自己的缓存中不存在X的数据，那么主内存会构造Read Response消息，从主内存读取包含指定地址的块号数据放入消息（缓存行大小和内存块大小一致所以可以存放的下），并将消息发送到总线  CPU1获接收到总线消息之后，解析出数据保存在自己的缓存中  MESI写缓存流程 CPU1 需要写入数据X\n 为E/M时，说明当前CPU1已经拥有了相应数据的所有权，此时CPU1会直接将数据写入缓存行中，并更新缓存行状态为M，此时不需要向总线发送任何消息。 S时，说明数据被共享，其它CPU中有可能存有该数据的副本，则CPUA向总线发送Invalidate 消息以获取数据的所有权，其它处理器（CPU2)收到Invalidate消息后,会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据， 并回复Invalidate Acknowledge消息，CPU1收到所有处理器的响应消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M I时，说明当前处理器中不包含该数据的有效副本，则CPU1向总线发送Read Invalidate消息，表明我要读数据X，希望主存告诉我X的值，同时请示其它处理器将自己缓存中包含该数据的缓存行并且状态不是I的缓存行置为无效` 其它处理器（CPUB)收到Invalidate消息后，如果缓存行不为I的话，会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据，并回复Invalidate Acknowledge消息 主内存收到Read消息后，会响应Read Response消息将需要读取的数据告诉CPU1 CPU1收到所有处理器的Invalidate Acknowledge消息和主内存的Read Response消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M  MESI的状态变化  Local Read：表示本内核读本Cache中的值 Local Write：表示本内核写本Cache中的值 Remote Read：表示其它内核读其Cache中的值 Remote Write：表示其它内核写其Cache中的值 箭头表示本Cache line状态的迁移，环形箭头表示状态不变  StoreBuffer和Invalidate Queue 说了缓存一致性协议，好像就能够解决问题了，但是，在这里你会发现，又有新的问题出现了。MESI协议中：当cpu0写数据到本地cache的时候，如果不是M或者E状态，需要发送一个invalidate消息给cpu1，只有收到cpu1的ack之后cpu0才能继续执行， 在这个过程中cpu0需要等待，这大大影响了性能。于是CPU设计者引入了Store Buffer，这个buffer处于CPU与cache之间。\nStore Buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给缓存一致性协议。但是Store Buffer仍然引入了一些复杂性,那就是缓存数据和Store Buffer数据不一致的问题。\nStore Forwarding 为了解决上面的问题，修改为了下面的架构，这种设计叫做Store forwarding，当CPU执行load操作的时候，不但要看cache，还有看Store Buffer是否有内容，如果Store Buffer有该数据，那么就采用Store Buffer中的值。\nInvalid Queue 同样的问题也会出现在其他线程发送Invalidate Acknowledge消息的时候，通常Invalidate Cacheline操作没有那么快完成,尤其是在Cache繁忙的时候，这时CPU往往进行密集的load和store的操作，而来自其他CPU的， 对本CPU Cache的操作需要和本CPU的操作进行竞争，只有完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。 为了解决这个问题，引入了Invalid Queue,系统架构如下。\n有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候， 那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。\n另外说一下，x86的CPU不含有 invalidate queue,这也是上面提到的，x86平台下只有storeload会发生重排序的原因。\n乱序执行/重排序 了解完上面的这些知识，我们再来整体的总结一下乱序执行或者说重排序的问题。\n从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：\n上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。\nas-if-serial语义 无论是处理器还是编译器,不管怎么重排都要保证(单线程)程序的执行结果不能被改变,这就是as-if-serial语义。\n编译器重排序 编译器重排序：编译器会对高级语言的代码进行分析，当编译器认为你的代码可以优化的话，编译器会选择对代码进行优化，重新排序，然后生成汇编代码。当然这个优化是有原则的，原则就是在保证单线程下的执行结果不变。\n编译器在编译时候，能够获得最底层的信息，比如要读写哪个寄存器，读写哪块内存。所以编译就根据这些信息对代码进行优化，包括不限于减少无用变量、修改代码执行顺序等等。 优秀的编译器优化能够提升程序在CPU上的运行性能，更好的使用寄存器以及现代处理器的流水线技术，减少汇编指令的数量，降低程序执行需要的CPU周期，减少CPU读写主存的时间。\n当然，编译器在优化的时候，只能保证在单线程下的结果，在多线程情况下，不加限制就可能会导致错误的结果。所以在多线程情况就需要开发者对编译器进行适当的指引，防止编译器进行错误的优化。\n处理器乱序 CPU接受到编译器编译的指令，通常为了为了提高CPU流水线的工作效率，也会对指令进行分析，然后进行乱序执行。当然不同的硬件进行乱序的规则也不大相同，我们还把上面的表格哪来参考一下。\n   处理器 Load-Load Load-Store Store-Store Store-Load 数据依赖     x86 N N N Y N   PowerPC Y Y Y Y N   ia64 Y Y Y Y N    我们对CPU发生乱序执行情况进行一下分类\n 在没有数据依赖的情况下，发生的乱序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果) ，处理器可以改变语句对应的机器指令的执行顺序,从而减少流水线停顿，提高处理器运行效率。 CPU顺序执行，但是因为StoreBuffer和 Invalidate Queue的存在产生了乱序的效果。  关于StoreBuffer和 Invalidate Queue引起的乱序稍微复杂一点，就不在这里展开了，有兴趣的同学可以查看 Why Memory Barriers   同样上面的这些乱序，都是能够保证在单线程的情况下执行结果的正确行。在多线程环境下，如果需要保证有序，那就需要开发者使用CPU提供的内存屏障指令，或者带有内存屏障作用的其他指令，来告诉CPU不要进行乱序执行了。\nvolatile作用总结 上面我们对volatile涉及到相关之后都了解了一下，下面对再对volatile的作用做一下总结。\n 可以防止编译器的重排序优化，会禁止编译器对操作volatile变量的上下两部分代码段进行重排序。 可以防止CPU的重排序优化  使用volatile之后，在某些硬件平台下，会使用内存屏障，防止CPU进行指令重排序，使用内存屏障后，就算是没有相关性的指令，CPU也不会进行排序  可以保证变量在线程之间的可见性  我们上面了解到，在MESI协议之外，有些处理器还有Store Buffer，这就会导致虽然有缓存一致性协议，但是并不能实时生效，所以还是没有办法保证可见性。当使用了volatile之后，使用了内存屏障指令之后，会强制处理器清空Store Buffer，这样就能保证每次操作volatile之后，缓存一致性协议立即生效，这样就能够保证了可见性。   伪共享问题 伪共享的意思是，我们在开发中定义了共享变量，然后在多个线程中访问。看起来像是这个变量在内存中，多个CPU共享，但是实际情况是每个CPU都访问自己的缓存，并不是直接访问的整个变量。\n伪共享导致的问题就是，如果几个字段因为局部性原理，被加载到了同一个缓存行中，然后被几个线程分别访问。这时就会因为MESI协议，导 致缓存频繁失效，从而CPU每次只能从内存中加载数据，从而降低程序的执行效率。\n下面我们通过代码验证一下， 在下面代码中我们我们定义了两个长度为2的long数组，其中一个使用volatile关键字修饰，另一个没有。\npublic class FalseShareTest { private final long CYCLE_TIMES = 10_0000_0000L; private volatile long[] array = new long[2]; private long[] array1 = new long[2]; /** * 启动2个线程修改volatile数组的第1，2位 1000w次 */ @Test public void test() throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array[0] = i; } }); Thread t2 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\u0026#34;Duration: \u0026#34; + (end - start) / 100_0000); } /** * 启动2个线程修改非volatile数组的第1，2位 1000w次 */ @Test public void test1() throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array1[0] = i; } }); Thread t2 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array1[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\u0026#34;Duration: \u0026#34; + (end - start) / 100_0000); } } 每个方法我们都执行5次看一下耗时\nvolatile数组 Duration: 3281 Duration: 3052 Duration: 3071 Duration: 3079 Duration: 3111 非volatile数组 Duration: 358 Duration: 347 Duration: 552 Duration: 545 Duration: 548 我们发现修改volatile修饰的数组，消耗的时间是没有volatile数组的10倍。 这个时间花在什么地方呢。 我们来分析一下。\n 缓存行的大小一般为64字节 定义的数据长度为2，类型是long，所以数据大小就是16字节。根据局部性原理，所以他们很有可能放到了同一个缓存行中 两个线程并发的读取修改第一个数据和第二个数据，这里我们可以理解为CPU1修改第一个数据X，CPU2修改第二个数据Y CPU1修改了X，因为数据定义为volatile，所以必须保证多线程之间的可见性，所以会强制使用lock前缀指令，让CPU2中对应的缓存行失效 CPU2想要修改Y，这时候发现这个缓存行已经失效了，所以需要重新从内存中读取，然后修改，同时又会导致CPU1的缓存行失效。 所以耗时发生在，volatile的可见性要求导致缓存行一直失效，需要不断的从内存中读取所导致。 而非volatile数据，并没有可见性要求，并且因为store buffer的存在，缓存并不会立即失效，所以效率要高的多。  volatile的优化 知道了上面伪共享和volatile带来的性能问题，那么有没有办法进行优化呢？ 答案肯定是有的，我们思考一下，上面的主要问题是，两个数据都存在于同一个缓存行中，对任何一个字段的读写，都会导致缓存行失效，那么我们把这两个数据分开，放到不同的缓存行呢？\n我们把上面的代码改一下，把数组长度改为16，两个线程分别修改第1个，和第9个，因为缓存行是64字节，long是8个字节，所以第1个和第9个肯定不会再同一个缓存行中。\npublic class FalseShareTest { private final long CYCLE_TIMES = 10_0000_0000L; private volatile long[] array = new long[2]; private volatile long[] array1 = new long[16]; public void test() throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array[0] = i; } }); Thread t2 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\u0026#34;Duration: \u0026#34; + (end - start) / 100_0000); } public void test1() throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array1[0] = i; } }); Thread t2 = new Thread(() -\u0026gt; { for (long i = 0; i \u0026lt; CYCLE_TIMES; i++) { array1[8] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\u0026#34;Duration: \u0026#34; + (end - start) / 100_0000); } public static void main(String[] args) throws InterruptedException { FalseShareTest falseShareTest = new FalseShareTest(); System.out.println(\u0026#34;未优化\u0026#34;); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); System.out.println(\u0026#34;优化后\u0026#34;); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); } } 执行结果\n未优化 Duration: 6589 Duration: 7006 Duration: 7527 Duration: 7278 Duration: 7813 优化后 Duration: 1961 Duration: 2011 Duration: 1974 Duration: 2056 Duration: 1953 我们发现把数据移动到不同的缓存行之后，运行时间缩短了三分之二左右。\n所以对volatile的优化的主要逻辑就是，让volatile的字段，自己处于一个缓存行中，不要让其他字段的变化，影响volatile变量所处缓存行的状态。\nfalse share的优化案例 这种优化，在很多高性能的框架中还是挺常见的。比如在caffeine中就有这样的应用\n依据JVM对象继承关系中父类属性与子类属性，内存地址连续排列布局,PadReadCounter中的字段会作为前置填充，PadWriteCounter中的字段会作为后置填充。 保证readCounter字段能够独占一个缓存行。\n我们看到这里前后各使用的15个long字段作为填充，这应该是为了防止不同的系统下缓存行大小不一致的情况。\n参考 [关键字: volatile详解]\n[汇编指令的LOCK指令前缀]\n[一文了解内存屏障]\n[volatile与内存屏障]\n[内存屏障及其在JVM内的应用]\n[CPU缓存一致性协议MESI]\n[x86架构]\n[聊聊缓存一致性协议]\n[浅论Lock与X86 Cache一致性]\n[Why Memory Barriers？中文翻译（上）]\n[Volatile全面解析，实现原理及作用分析]\n[编译器重排序]\n[一篇对伪共享、缓存行填充和CPU缓存讲的很透彻的文章]\n[为什么volatile注释变量，对其下面的变量也会有影响？]\n[一次深入的volatile研究]\n[既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？]\n","permalink":"https://balvboy.github.io/blog/volatile/","summary":"volatile在Java中的语义 对于volatile我们都比较熟悉，volatile在Java中有两种作用 保障字段在多线程之间的可见性 防止","title":"Java同步机制(二)-Volatile"},{"content":" Java对象头 锁升级和对象头关系很密切，所以我先了解一下对象头。\n我们先来看一下64位系统下对象头的结构，对象头结构分为两部分Mark Word和Klass Word。我们主要关注Mark Word，klass word是指向这个对象的类对象的指针。\n|--------------------------------------------------------------------------------------------------------------| | Object Header (128 bits) | |--------------------------------------------------------------------------------------------------------------| | Mark Word (64 bits) | Klass Word (64 bits) | |--------------------------------------------------------------------------------------------------------------| | unused:25 | identity_hashcode:31 | unused:1 | age:4 | biased_lock:1 | lock:2 | OOP to metadata object | 无锁 |----------------------------------------------------------------------|--------|------------------------------| | thread:54 | epoch:2 | unused:1 | age:4 | biased_lock:1 | lock:2 | OOP to metadata object | 偏向锁 |----------------------------------------------------------------------|--------|------------------------------| | ptr_to_lock_record:62 | lock:2 | OOP to metadata object | 轻量锁 |----------------------------------------------------------------------|--------|------------------------------| | ptr_to_heavyweight_monitor:62 | lock:2 | OOP to metadata object | 重量锁 |----------------------------------------------------------------------|--------|------------------------------| | | lock:2 | OOP to metadata object | GC |--------------------------------------------------------------------------------------------------------------| 对象头的格式在处于不同锁级别的时候，格式有所不同。\n 无锁状态下，可以保存的数据有对象的hashCode，垃圾回收年龄，偏向标识，锁状态 偏向状态下，hashCode会被替换成，线程Id,和epoch，同时还有垃圾回收年龄，偏向标识，锁状态 轻量级状态下，保留了锁状态，其他部分都被替换成了指向Lock Record的指针。 重量级状态下，指向Lock Record的指针被替换成了指向一个Monitor对象的指针。  这里大家可能会有疑问，在各种锁状态下，都会有部分对象头中的数据被替换成了锁相关的数据，那么被替换的数据都去哪里了呢。\n 偏向锁，hashcode和偏向锁不能共存，在任何情况下调用hashcode，都会导致该锁对象的偏向锁失效。  如果在获得偏向锁之前调用了hashcode，会把对象头中的biased_lock设置为0 如果在获取锁之后的同步代码块中，调用hashcode，则会导致偏向撤销。  轻量级锁，会把被替换的对象头整体放到Lock Record中的 displaced_mark_word中 重量级锁，会放到monitor对象的_header中。 下面我们主要主要关注一下和锁状态关系比较密切的几个  biased_lock和lock  biased_lock这个标志位表示当前这个锁对象是否可以偏向。0表示不可偏向 1表示可偏向。 lock表示当前锁对象所处的锁级别   下面在开启偏向锁，并且过了4秒钟的默认偏向锁生效时间的前提下我们来分析。\n 创建出来的实例的对象头的后三位为1 01，并且偏向的线程ID也为空,表示当前的实例状态是可偏向、没有偏向线程、没有锁定（也叫做匿名偏向状态） 当有线程对这个实例加锁，这时候线程会偏向这个线程，既对象头中的线程ID修改为这个线程的ID，后三位为1 01,这时候实例状态是，可偏向，偏向某一线程，没有锁定(这里为什么认为是没有锁定，我理解，就是把偏向锁也认为是无锁状态) 这时候有另一个线程，尝试锁定这个实例，这时候会触发偏向锁的撤销，也就是把对象头中的biased_lock标志位从1改为0，并且升级到轻量级锁。这时候如果之前偏向的线程已经执行完毕，这个线程就能顺利的使用轻量级获得锁。这时候后三位是0 00。这时候意思是不可偏向，已轻量级锁定 这时候如果另一个线程来尝试锁定，并且没有获取成功，会导致锁继续升级为重量级锁。这时候后三位是0 10。这时候意思是不可偏向，已重量级锁定  epoch epoch主要和批量重偏向次数有关，每当这个类型实例，发生了一次批量重偏向，就会把实例所属类型的epoch加1，同时把当前所有正在被线程使用的该类型的锁对象，对象头中的epoch加1，这个操作发生在安全点。 所以如果某些锁对象，如果发生批量重偏向的时候，没有被线程使用，那它的epoch就会小于类型中的epoch，当有线程尝试锁定这个锁对象的时候，则会直接进行一次重偏向。让这个锁对象，偏向当前的线程。\n注意这里是把所有正在被线程使用的锁对象的epoch加1，因为上面重偏向逻辑的存在，所以需要保证正在被某个线程持有的锁对象，不会重新偏向给其他线程。\n下面我就按照偏向锁、轻量级锁、重量级锁的顺序来详细了解一下加锁过程，和其中的关键部分。\n锁升级整体流程 为什么要有锁升级 在jdk1.6之前，当一个线程获得synchronized，会阻塞后面的所有其他线程，而java的线程和操作系统的线程是一一映射的，所以阻塞和唤醒线程，都需要操作系统提供支持，都需要从用户态转入内核态，需要耗费大量的CPU的时间，这种状态转换用时可能比执行用户代码的时间还要长。所以在jdk1.6之前，synchronized都是一个重量级的操作，而在jdk1.6之后，对synchronized进行的优化，引入了偏向锁和轻量级锁的概念，使得synchronized的性能得到了很大的提升。jdk1.6之后的synchronized，从偏向锁到轻量级锁，再到重量级锁，让锁随着线程竞争的升级来逐渐升级。\n在有一个线程访问的时候，使用偏向锁，只需要一次比较就能获得锁，性能最好。 在多个线程交替访问的时候，使用轻量级锁，只需要一次CAS操作就可以获得锁（这里说的交替，是指的线程不会同时去争抢锁。一个线程用完了，下一个线程再去获取）。 在存在线程竞争的时候，使用重量级锁。让没有获取到锁的线程进入阻塞状态，避免一些无效的自旋操作，节省CPU资源。\n首先看一下这张图，这是Hotspot官方给出的锁升级过程图，我们先简单分析一下这张图。\n 开启了偏向锁  锁对象刚分配的时候默认锁状态是匿名偏向状态。 有一个线程抢占锁，则在对象头中存储当前线程ID，锁进入偏向状态。 如果发生了重偏向，则会重新回到匿名偏向状态。 如果发生了偏向撤销。  如果发生的时候是无锁状态，则会进入不可偏向的无锁状态。 如果发生的时候是有线程正持有，则会进入轻量级加锁状态。 如果还有另一个线程尝试获取，并且获取失败，就会再升级到重量级。 轻量级和重量级在执行完同步代码之后，锁对象头会回到不可偏向的无锁状态。  偏向锁执行完同步代码之后，不会修改对象头，仍然保持上次的偏向状态。  没有开启偏向锁，则默认分配的就是不可偏向的无锁状态。  有线程尝试获取，则直接轻量级锁定 如果又有另一个线程获取锁，并且轻量级获取失败(也就是上一个线程还没有执行完同步代码)，就会导致锁升级到重量级。 执行完同步代码，对象头回到初始的不可偏向无锁状态。   偏向锁 偏向锁被设计于优化单线程访问下的synchronized，在偏向锁下，只需要一个比较就能够获取锁。 下面我们从C++的源码来分析一下偏向锁的过程\n偏向锁加锁 CASE(_monitorenter): { oop lockee = STACK_OBJECT(-1); // derefing\u0026#39;s lockee ought to provoke implicit null check  CHECK_NULL(lockee); // find a free monitor or one already allocated for this object  // if we find a matching object then we need a new monitor  // since this is recursive enter  BasicObjectLock* limit = istate-\u0026gt;monitor_base(); BasicObjectLock* most_recent = (BasicObjectLock*) istate-\u0026gt;stack_base(); BasicObjectLock* entry = NULL; //从当前线程栈中获取一个空闲的BasicObjectLock  while (most_recent != limit ) { if (most_recent-\u0026gt;obj() == NULL) entry = most_recent; else if (most_recent-\u0026gt;obj() == lockee) break; most_recent++; } //获取BasicObjectLock成功  if (entry != NULL) { //将线程栈中的BasicObjectLock的obj指针指向锁对象  entry-\u0026gt;set_obj(lockee); int success = false; uintptr_t epoch_mask_in_place = (uintptr_t)markOopDesc::epoch_mask_in_place; //获取当前锁对象的对象头，用来进行下面的判断  markOop mark = lockee-\u0026gt;mark(); intptr_t hash = (intptr_t) markOopDesc::no_hash; // implies UseBiasedLocking  //判断锁对象是否是是偏向模式  if (mark-\u0026gt;has_bias_pattern()) { uintptr_t thread_ident; uintptr_t anticipated_bias_locking_value; thread_ident = (uintptr_t)istate-\u0026gt;thread(); //下面这个操作，可以理解为为了方便进行后面的运算，可以说是比较骚的一种玩法，我们可以不用过分关注  anticipated_bias_locking_value = (((uintptr_t)lockee-\u0026gt;klass()-\u0026gt;prototype_header() | thread_ident) ^ (uintptr_t)mark) \u0026amp; ~((uintptr_t) markOopDesc::age_mask_in_place); //value = 0 表示已经偏向，并且偏向的就是自己，而且epoch和klass的epoch也相同，什么都不用做，直接获得偏向锁  if (anticipated_bias_locking_value == 0) { // already biased towards this thread, nothing to do  if (PrintBiasedLockingStatistics) { //如果需要统计偏向锁重入次数，可以使用biased_lock_entry_count_addr统计  (* BiasedLocking::biased_lock_entry_count_addr())++; } //标记状态为获取锁成功  success = true; } //对象的Klass的对象头不是偏向模式，则撤销偏向  else if ((anticipated_bias_locking_value \u0026amp; markOopDesc::biased_lock_mask_in_place) != 0) { // try revoke bias  markOop header = lockee-\u0026gt;klass()-\u0026gt;prototype_header(); if (hash != markOopDesc::no_hash) { header = header-\u0026gt;copy_set_hash(hash); } if (Atomic::cmpxchg_ptr(header, lockee-\u0026gt;mark_addr(), mark) == mark) { if (PrintBiasedLockingStatistics) (*BiasedLocking::revoked_lock_entry_count_addr())++; } } //当前对象的对象头epoch不等于Klass中的epoch，则尝试重新偏向  else if ((anticipated_bias_locking_value \u0026amp; epoch_mask_in_place) !=0) { // try rebias  markOop new_header = (markOop) ( (intptr_t) lockee-\u0026gt;klass()-\u0026gt;prototype_header() | thread_ident); if (hash != markOopDesc::no_hash) { new_header = new_header-\u0026gt;copy_set_hash(hash); } //进行CAS将对象头中线程Id替换为自己，如果替换成功，则偏向成功  if (Atomic::cmpxchg_ptr((void*)new_header, lockee-\u0026gt;mark_addr(), mark) == mark) { if (PrintBiasedLockingStatistics) (* BiasedLocking::rebiased_lock_entry_count_addr())++; } //替换失败，表示有多个线程并发争抢，则开始锁的升级  else { CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception); } success = true; } else { //重新偏向， 如果markOop是匿名偏向的时候会偏向当前线程成功  //走到这里说明当前要么偏向别的线程，要么是匿名偏向（即没有偏向任何线程）  // try to bias towards thread in case object is anonymously biased  //构建一个匿名偏向的对象头  markOop header = (markOop) ((uintptr_t) mark \u0026amp; ((uintptr_t)markOopDesc::biased_lock_mask_in_place | (uintptr_t)markOopDesc::age_mask_in_place | epoch_mask_in_place)); if (hash != markOopDesc::no_hash) { header = header-\u0026gt;copy_set_hash(hash); } markOop new_header = (markOop) ((uintptr_t) header | thread_ident); // debugging hint  DEBUG_ONLY(entry-\u0026gt;lock()-\u0026gt;set_displaced_header((markOop) (uintptr_t) 0xdeaddead);) //进行CAS替换，如果替换成功，则偏向成功(只有markOop是匿名偏向的时候，才会替换成功)  if (Atomic::cmpxchg_ptr((void*)new_header, lockee-\u0026gt;mark_addr(), header) == header) { if (PrintBiasedLockingStatistics) (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++; } //失败，则升级  else { CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception); } success = true; } } // traditional lightweight locking  //轻量级锁  if (!success) { //设置当前的对象头为无锁状态，并且复制到Lock Record中的markoop中  markOop displaced = lockee-\u0026gt;mark()-\u0026gt;set_unlocked(); entry-\u0026gt;lock()-\u0026gt;set_displaced_header(displaced); bool call_vm = UseHeavyMonitors; //将对象头中的地址替换为指向Lock Record的指针，替换成功，则说明获取轻量级锁成功,则什么都不做。  //这里判断，如果是替换失败，则继续判断是否是锁重入。  if (call_vm || Atomic::cmpxchg_ptr(entry, lockee-\u0026gt;mark_addr(), displaced) != displaced) { // Is it simple recursive case?  //这里判断是不是锁重入，判断指向Lock Record的指针指向的地址是否属于当前线程栈  if (!call_vm \u0026amp;\u0026amp; THREAD-\u0026gt;is_lock_owned((address) displaced-\u0026gt;clear_lock_bits())) { //如果是轻量级锁的锁重入,说明前面set_displaced_header设置的是第一个Lock Record的地址，  //所以要重新将申请的Lock Record的displaced_header置为空,同样也会通过申请的displaced_header的个数来统计轻量级锁的重入次数  //栈的最高位的Lock Record的displaced_header不是空，重入锁退出锁的时候，会由低到高遍历退出，只在最后一个锁的时候使用CAS替换  entry-\u0026gt;lock()-\u0026gt;set_displaced_header(NULL); } else { //替换失败，则进行锁升级  CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception); } } } UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1); } else { istate-\u0026gt;set_msg(more_monitors); UPDATE_PC_AND_RETURN(0); // Re-execute  } } 通过代码我们可以知道在偏向锁的获取过程主要进行了几个判断\n 锁本省的偏向模式是否关闭 锁的epoch和proto header是否一致并且当前得前程ID和已经偏向的线程ID是否一致 锁类型的偏向模式(proto header)是否关闭  具体流程如下\n 获得一个可用的Lock Record，并把锁对象设置到lock record的obj中。 判断锁对象是否处于偏向模式  如果不是偏向模式，则直接走轻量级流程 是偏向模式  判断是不是已经偏向了当前线程，并且epoch和proto header中相同。并且proto header中也是偏向模式  如果是，则设置success = true，表示直接获取成功。  如果不是，则判断proto header中是否关闭了偏向模式  如果proto header关闭了偏向模式，则构建一个通过proto header构建一个新的对象头，并CAS设置到锁对象头中，完成偏向撤销，然后走轻量级逻辑。（对象头状态: 偏向模式-\u0026gt;撤销偏向）  如果没有关闭，则继续判断，是不是epoch不同  如果是epoch不同，则表示发生了批量重偏向，然后构建一个偏向当前线程的对象头，然后CAS设置到锁对象头。  如果CAS成功，则设置success = true，表示获取偏向锁成功。（对象头状态: 偏向其他线程-\u0026gt;重新偏向当前线程） 如果CAS失败，则表示在这一步发生了线程并发获取锁的操作，则直接调用monitorenter锁升级。   如果都不满足上面的情况，那就是标明，当前锁对象头处于匿名偏向状态，或者偏向了其他线程，那构建一个偏向当前线程的对象头，和匿名偏向的对象头，然后CAS替换到锁对象头中，这里只有锁是匿名偏向状态的时候才会替换成功  如果设置成功，则设置success= true，表示获取偏向锁成功。（对象头状态: 匿名偏向-\u0026gt;偏向当前线程） 如果设置失败，说明锁已经偏向了其他线程，则直接调用monitorenter锁升级。     偏向锁撤销 如果一直只有一个线程持有这个锁，那么这个锁会一直保持偏向状态，并且获取所得操作只需要一次判断，效率最高。 如果一旦出现了另一个线程，尝试获取这个锁对象，就会触发偏向锁的撤销。 偏向撤销，是指把锁对象头中的bias_lock修改为0，这样可以让后续的获取锁的步骤中，跳过偏向流程，直接进入轻量级逻辑。 撤销会有三种情况 1. 锁对象处于匿名偏向状态时发起的偏向撤销。比如这个锁对象在没有被任何线程获取之前，调用了hashcode()方法。 2. 持有偏向锁的线程自己发起的偏向撤销，比如在同步方法里调用了hashcode()方法。 3. 一个线程持有偏向锁，另一个线程也尝试获取，导致的偏向撤销。\n前两种情况的撤销，不会对任何线程产生影响，所以可以不用等待安全点，直接操作就行。而且第一种，因为没有任何线程获取过它，所以直接使用CAS操作替换就行。 第三种情况，因为直接撤销的话，有可能会对正持有偏向锁的线程产生影响，为了避免这种影响，所以需要在安全点来进行。\n下面我们通过代码来分析一下这个过程。\nfast_enter //obj 是锁对象 //lock 是线程栈中的 lock record，存储了displaced header //attempt_rebias 是是否允许重偏向，我们这里是true void ObjectSynchronizer::fast_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) { //判断是否开启偏向锁,如果没开启这走slow_enter升级  if (UseBiasedLocking) { //判断是否是业务线程触发的撤销  if (!SafepointSynchronize::is_at_safepoint()) { BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) { return; } } else { //这里表示是由vm线程触发的  assert(!attempt_rebias, \u0026#34;can not rebias toward VM thread\u0026#34;); BiasedLocking::revoke_at_safepoint(obj); } assert(!obj-\u0026gt;mark()-\u0026gt;has_bias_pattern(), \u0026#34;biases should be revoked by now\u0026#34;); } //执行锁升级  slow_enter(obj, lock, THREAD); } revoke_and_rebias 我们先列举一下这个方法的返回值\n BIAS_REVOKED_AND_REBIASED 偏向撤销并已重偏向 BIAS_REVOKED 偏向已撤销 NOT_BIASED 没有偏向  我们看到fast_enter的逻辑中，只要revoke_and_rebias()方法返回的不是BIAS_REVOKED_AND_REBIASED,那么最终都会执行到slow_enter中进行锁升级。\n下面我们来看revoke_and_rebias()方法的实现。\nBiasedLocking::Condition BiasedLocking::revoke_and_rebias(Handle obj, bool attempt_rebias, TRAPS) { assert(!SafepointSynchronize::is_at_safepoint(), \u0026#34;must not be called while at safepoint\u0026#34;); // We can revoke the biases of anonymously-biased objects  // efficiently enough that we should not cause these revocations to  // update the heuristics because doing so may cause unwanted bulk  // revocations (which are expensive) to occur.  //获取锁的对象头  markOop mark = obj-\u0026gt;mark(); //1. 如果不允许重新偏向，并且锁处于匿名偏向  if (mark-\u0026gt;is_biased_anonymously() \u0026amp;\u0026amp; !attempt_rebias) { // We are probably trying to revoke the bias of this object due to  // an identity hash code computation. Try to revoke the bias  // without a safepoint. This is possible if we can successfully  // compare-and-exchange an unbiased header into the mark word of  // the object, meaning that no other thread has raced to acquire  // the bias of the object.  markOop biased_value = mark; //构建撤销了偏向模式的对象头  markOop unbiased_prototype = markOopDesc::prototype()-\u0026gt;set_age(mark-\u0026gt;age()); //CAS替换锁对象的对象头  markOop res_mark = (markOop)Atomic::cmpxchg_ptr(unbiased_prototype, obj-\u0026gt;mark_addr(), mark); //如果替换成功，则撤销完成，然后通过slow_enter进行锁升级即可  //如果替换失败，说明此时锁已经被其他线程获取，则会通过下面的逻辑走由JVM线程发起的单个撤销  if (res_mark == biased_value) { return BIAS_REVOKED; } //2. 如果不是匿名偏向，或者是允许重偏向，并且锁对象是偏向模式  //这里大多数情况是，锁偏向了某个线程。  } else if (mark-\u0026gt;has_bias_pattern()) { Klass* k = obj-\u0026gt;klass(); //获取Klass的markOop  markOop prototype_header = k-\u0026gt;prototype_header(); //2.1. 如果Klass的Oop不是偏向模式则执行  //表示锁对象所属的类型，已经关闭了偏向模式，发生了批量撤销  if (!prototype_header-\u0026gt;has_bias_pattern()) { // This object has a stale bias from before the bulk revocation  // for this data type occurred. It\u0026#39;s pointless to update the  // heuristics at this point so simply update the header with a  // CAS. If we fail this race, the object\u0026#39;s bias has been revoked  // by another thread so we simply return and let the caller deal  // with it.  markOop biased_value = mark; markOop res_mark = (markOop) Atomic::cmpxchg_ptr(prototype_header, obj-\u0026gt;mark_addr(), mark); assert(!(*(obj-\u0026gt;mark_addr()))-\u0026gt;has_bias_pattern(), \u0026#34;even if we raced, should still be revoked\u0026#34;); return BIAS_REVOKED; //2.2 . 如果Klass markOop和锁对象的markOop的epoch不同，则执行  //这里是说明锁对象仍然处于偏向模式，但是发生了一次批量重偏向，导致epoch不同了  } else if (prototype_header-\u0026gt;bias_epoch() != mark-\u0026gt;bias_epoch()) { // The epoch of this biasing has expired indicating that the  // object is effectively unbiased. Depending on whether we need  // to rebias or revoke the bias of this object we can do it  // efficiently enough with a CAS that we shouldn\u0026#39;t update the  // heuristics. This is normally done in the assembly code but we  // can reach this point due to various points in the runtime  // needing to revoke biases.  // 如果允许重偏向  if (attempt_rebias) { assert(THREAD-\u0026gt;is_Java_thread(), \u0026#34;\u0026#34;); markOop biased_value = mark; //构建一个偏向当前线程的对象头  markOop rebiased_prototype = markOopDesc::encode((JavaThread*) THREAD, mark-\u0026gt;age(), prototype_header-\u0026gt;bias_epoch()); //cas替换  markOop res_mark = (markOop) Atomic::cmpxchg_ptr(rebiased_prototype, obj-\u0026gt;mark_addr(), mark); // 如果替换成功，返回BIAS_REVOKED_AND_REBIASED，表示获取锁成功  //替换失败，则走下面的偏向撤销流程  if (res_mark == biased_value) { return BIAS_REVOKED_AND_REBIASED; } } else { // 如果不允许重偏向，则进行偏向撤销  markOop biased_value = mark; markOop unbiased_prototype = markOopDesc::prototype()-\u0026gt;set_age(mark-\u0026gt;age()); markOop res_mark = (markOop) Atomic::cmpxchg_ptr(unbiased_prototype, obj-\u0026gt;mark_addr(), mark); if (res_mark == biased_value) { return BIAS_REVOKED; } } } } //3. 如果锁对象已经偏向了某个线程，而且proto header中偏向模式没有关闭，  //epoch 也相同的话(也就是偏向了某个线程，但是没有发生批量重偏向和批量撤销)  //则后走下面的逻辑  //update_heuristics 这个方法就是决定接下来改进行什么样的操作  HeuristicsResult heuristics = update_heuristics(obj(), attempt_rebias); if (heuristics == HR_NOT_BIASED) { return NOT_BIASED; } else if (heuristics == HR_SINGLE_REVOKE) { //3.1 开始单个撤销  Klass *k = obj-\u0026gt;klass(); markOop prototype_header = k-\u0026gt;prototype_header(); //当前对象偏向当前线程，并且对象的epoch和Klass的Epoch相同，则直接开始执行撤销，  //也就是说是线程自己发起的偏向撤销，就是我们上面提到的在同步代码中，调用了hashcode方法  if (mark-\u0026gt;biased_locker() == THREAD \u0026amp;\u0026amp; prototype_header-\u0026gt;bias_epoch() == mark-\u0026gt;bias_epoch()) { // A thread is trying to revoke the bias of an object biased  // toward it, again likely due to an identity hash code  // computation. We can again avoid a safepoint in this case  // since we are only going to walk our own stack. There are no  // races with revocations occurring in other threads because we  // reach no safepoints in the revocation path.  // Also check the epoch because even if threads match, another thread  // can come in with a CAS to steal the bias of an object that has a  // stale epoch.  ResourceMark rm; if (TraceBiasedLocking) { tty-\u0026gt;print_cr(\u0026#34;Revoking bias by walking my own stack:\u0026#34;); } //因为是自己线程发起的，所以直接进行撤销操作，不需要等待安全点，这里allow_rebias 也是false  BiasedLocking::Condition cond = revoke_bias(obj(), false, false, (JavaThread*) THREAD); ((JavaThread*) THREAD)-\u0026gt;set_cached_monitor_info(NULL); assert(cond == BIAS_REVOKED, \u0026#34;why not?\u0026#34;); return cond; } else { //3.2 如果需要撤销的不是当前线程，则需要等待线程安全点，之后Jvm在线程安全点会触发撤销程序  VM_RevokeBias revoke(\u0026amp;obj, (JavaThread*) THREAD); VMThread::execute(\u0026amp;revoke); return revoke.status_code(); } } //批量撤销和批量重偏向，注意这里，会把attempt_rebias传过去  assert((heuristics == HR_BULK_REVOKE) || (heuristics == HR_BULK_REBIAS), \u0026#34;?\u0026#34;); VM_BulkRevokeBias bulk_revoke(\u0026amp;obj, (JavaThread*) THREAD, (heuristics == HR_BULK_REBIAS), attempt_rebias); VMThread::execute(\u0026amp;bulk_revoke); return bulk_revoke.status_code(); } 首先\n 判断: 是否处于匿名偏向状态，并且不允许重新偏向  这是我们上面说到的撤销的第一种情况，在同步代码块执行前，调用了锁对象的hashcode()方法。  判断：是否锁对象处于偏向模式，包括匿名偏向和偏向了某一个线程  判断: 是否Class已经关闭了偏向模式  说明发生了偏向撤销 直接使用Class的proto header替换锁对象的对象头，完成撤销操作  判断: 锁对象和Class的epoch是否不同  epoch不同说明，发生了批量重偏向 根据attempt_rebias来处理，如果为true则尝试重偏向，如果为false，则执行偏向撤销\n   无法简单的判断如何操作，需要根据Class中记录的偏向撤销信息来进行决策  走到这里条件是:已经偏向了某个线程、Class的偏向模式没有关闭、epoch相同 如果是返回HR_SINGLE_REVOKE  判断: 当前线程是否为持有锁线程，并且epoch相同。  这里是我们上面提到的撤销3种情况中的，在同步代码快中调用了hashcode()方法 如果是则直接由当前线程调用revoke_bias完成撤销，因为自己发起的，不会导致持有锁线程的异常。 如果不是，则需要交给JVM线程，在安全点调用revoke_bias完成撤销。   如果返回的HR_BULK_REVOKE和HR_BULK_REBIAS，则由JVM线程，在安全点完成批量撤销和批量重偏向。   update_heuristics JVM通过这个方法来进行偏向撤销的决策。 先说一下这个决策的数据依据。\n 每个锁对象，发生一次偏向撤销，都会在这个锁对象所属的Class中记录下来，称谓偏向撤销次数 每当发生了批量撤销，也会记录下来最近一次发生的时间。 用户设置的批量重偏向阈值和批量撤销阈值，新一次批量重偏向延迟时间\n-XX:BiasedLockingBulkRebiasThreshold=20 偏向锁批量重偏向阈值 -XX:BiasedLockingBulkRevokeThreshold=40 偏向锁批量撤销阈值  JVM就是根据上面这些数据来进行计算决策的。\nstatic HeuristicsResult update_heuristics(oop o, bool allow_rebias) { markOop mark = o-\u0026gt;mark(); //如果不是偏向模式直接返回  if (!mark-\u0026gt;has_bias_pattern()) { return HR_NOT_BIASED; } // 锁对象的类  Klass* k = o-\u0026gt;klass(); // 当前时间  jlong cur_time = os::javaTimeMillis(); // 上一次批量撤销或者批量重偏向的时间  // 因为批量撤销和批量重偏向都是同一个方法，所以都会更新这个时间  jlong last_bulk_revocation_time = k-\u0026gt;last_biased_lock_bulk_revocation_time(); // 该类偏向锁撤销的次数  int revocation_count = k-\u0026gt;biased_lock_revocation_count(); // BiasedLockingBulkRebiasThreshold是重偏向阈值（默认20），  //BiasedLockingBulkRevokeThreshold是批量撤销阈值（默认40），  //BiasedLockingDecayTime是开启一次新的批量重偏向距离上次批量重偏向或者批量撤销后的延迟时间，默认25000。也就是开启批量重偏向后，  //经过了一段较长的时间（\u0026gt;=BiasedLockingDecayTime），撤销计数器才超过阈值，那我们会重置计数器。  if ((revocation_count \u0026gt;= BiasedLockingBulkRebiasThreshold) \u0026amp;\u0026amp; (revocation_count \u0026lt; BiasedLockingBulkRevokeThreshold) \u0026amp;\u0026amp; (last_bulk_revocation_time != 0) \u0026amp;\u0026amp; (cur_time - last_bulk_revocation_time \u0026gt;= BiasedLockingDecayTime)) { // This is the first revocation we\u0026#39;ve seen in a while of an  // object of this type since the last time we performed a bulk  // rebiasing operation. The application is allocating objects in  // bulk which are biased toward a thread and then handing them  // off to another thread. We can cope with this allocation  // pattern via the bulk rebiasing mechanism so we reset the  // klass\u0026#39;s revocation count rather than allow it to increase  // monotonically. If we see the need to perform another bulk  // rebias operation later, we will, and if subsequently we see  // many more revocation operations in a short period of time we  // will completely disable biasing for this type.  k-\u0026gt;set_biased_lock_revocation_count(0); revocation_count = 0; } // 自增撤销计数器  if (revocation_count \u0026lt;= BiasedLockingBulkRevokeThreshold) { revocation_count = k-\u0026gt;atomic_incr_biased_lock_revocation_count(); } // 如果达到批量撤销阈值则返回HR_BULK_REVOKE  if (revocation_count == BiasedLockingBulkRevokeThreshold) { return HR_BULK_REVOKE; } // 如果达到批量重偏向阈值则返回HR_BULK_REBIAS  if (revocation_count == BiasedLockingBulkRebiasThreshold) { return HR_BULK_REBIAS; } // 没有达到阈值则撤销单个对象的锁  return HR_SINGLE_REVOKE; }  获取偏向撤销次数、上次批量撤销的时间 然后就是一个比较长的判断  撤销次数大于等于重偏向阈值20，小于批量撤销阈值40，并且发生过重偏向或者批量撤销，并且距离上次发生的时间超过了25000ms，那么我们就把撤销次数清零。 这个判断的意思是，如果一个类型发生过批量操作，但是在接下来的很长时间内，都没有达到下一次批量操作的触发条件，那么JVM就会认为，这个类型的锁对象线程争抢不严重，为了避免它达到批量撤销阈值，从而再也不能使用偏向模式，而把撤销计数归0\n  然后就是根据撤销计数返回对应的撤销类型了。  revoke_bias update_heuristics 返回对应的撤销决策之后，后面就要根据决策进行具体的处理了。 我们先看单个撤销revoke_bias\nstatic BiasedLocking::Condition revoke_bias(oop obj, bool allow_rebias, bool is_bulk, JavaThread* requesting_thread) { markOop mark = obj-\u0026gt;mark(); // 如果没有开启偏向模式，则直接返回NOT_BIASED  if (!mark-\u0026gt;has_bias_pattern()) { ... return BiasedLocking::NOT_BIASED; } uint age = mark-\u0026gt;age(); // 构建两个mark word，一个是匿名偏向模式（101），一个是无锁模式（001）  markOop biased_prototype = markOopDesc::biased_locking_prototype()-\u0026gt;set_age(age); markOop unbiased_prototype = markOopDesc::prototype()-\u0026gt;set_age(age); ... JavaThread* biased_thread = mark-\u0026gt;biased_locker(); if (biased_thread == NULL) { // 匿名偏向。当调用锁对象的hashcode()方法可能会导致走到这个逻辑  // 这里我也有点疑问，如果是匿名偏向状态，这表示没有被线程获取过，那么在revoke_and_bias的逻辑中应该可以CAS成功，如果那里失败，这里也不会是匿名偏向模式了  // 如果不允许重偏向，则将对象的mark word设置为无锁模式  if (!allow_rebias) { obj-\u0026gt;set_mark(unbiased_prototype); } ... return BiasedLocking::BIAS_REVOKED; } // code 1：判断偏向线程是否还存活  bool thread_is_alive = false; // 如果当前线程就是偏向线程  if (requesting_thread == biased_thread) { thread_is_alive = true; } else { // 遍历当前jvm的所有线程，如果能找到，则说明偏向的线程还存活  for (JavaThread* cur_thread = Threads::first(); cur_thread != NULL; cur_thread = cur_thread-\u0026gt;next()) { if (cur_thread == biased_thread) { thread_is_alive = true; break; } } } // 如果偏向的线程已经不存活了  if (!thread_is_alive) { // 允许重偏向则将对象mark word设置为匿名偏向状态，否则设置为无锁状态  if (allow_rebias) { obj-\u0026gt;set_mark(biased_prototype); } else { //如果不允许，就设置为偏向撤销状态  obj-\u0026gt;set_mark(unbiased_prototype); } ... return BiasedLocking::BIAS_REVOKED; } // 线程还存活则遍历线程栈中所有的Lock Record  GrowableArray\u0026lt;MonitorInfo*\u0026gt;* cached_monitor_info = get_or_compute_monitor_info(biased_thread); BasicLock* highest_lock = NULL; for (int i = 0; i \u0026lt; cached_monitor_info-\u0026gt;length(); i++) { MonitorInfo* mon_info = cached_monitor_info-\u0026gt;at(i); // 如果能找到对应的Lock Record说明偏向的线程还在执行同步代码块中的代码  if (mon_info-\u0026gt;owner() == obj) { ... // 需要升级为轻量级锁，直接修改偏向线程栈中的Lock Record。  //为了处理锁重入的case，在这里将Lock Record的Displaced Mark Word  //设置为null，第一个Lock Record会在下面的代码中再处理  markOop mark = markOopDesc::encode((BasicLock*) NULL); highest_lock = mon_info-\u0026gt;lock(); highest_lock-\u0026gt;set_displaced_header(mark); } else { ... } } if (highest_lock != NULL) { // 修改第一个Lock Record为无锁状态，然后将obj的mark word设置为指向该Lock Record的指针  highest_lock-\u0026gt;set_displaced_header(unbiased_prototype); obj-\u0026gt;release_set_mark(markOopDesc::encode(highest_lock)); ... } else { // 走到这里说明偏向线程已经不在同步块中了  ... if (allow_rebias) { //设置为匿名偏向状态  // 目前从代码中，只发现了会在批量重偏向的时候，allow_rebias会是true，从fast_enter带过来，然后传到VM_BulkRevokeBias  obj-\u0026gt;set_mark(biased_prototype); } else { // 将mark word设置为无锁状态  obj-\u0026gt;set_mark(unbiased_prototype); } } return BiasedLocking::BIAS_REVOKED; } 上面的撤销逻辑看似比较长，其实核心逻辑并不复杂：\n 如果当前对象锁已经不是偏向模式了，就不用执行撤销。 如果当前锁对象偏向的线程Id为NULL，也就是没有偏向任何线程，就根据参数allow_rebias判断是否允许重新偏向，不允许就设置锁状态为无锁，相当于撤销偏向。 判断当前锁对象中偏向的线程是否存活，如果持有偏向锁的线程已经死掉了，那如果允许重新偏向就设置对象头锁状态为偏向锁的初始状态，不允许就设置为无锁状态。 如果线程还存活，就开始执行真正的撤销了：  这里回忆一下前面偏向锁的获取和退出流程：偏向锁的获取，就是在当前线程的线程栈中申请一块Lock Record，然后将Lock Record的obj指向锁对象，并且在对象头中存储当前线程的线程Id。而偏向锁的退出，仅仅将Lock Record中的obj值置为空，其他的什么都没有做。\n 如果持有偏向锁的线程依旧存活，这里就有两种情况  持有偏向锁的线程还没有退出同步代码块 第二是持有偏向锁的线程退出了同步代码块。  而判断是否已经退出，判断依据就是线程栈中是否还有指向锁对象的Lock Record，这以上面的代码中，首先就是遍历线程栈，判断持有锁的线程是否退出了。 遍历结束后，如果highest_lock不等于空，说还没有退出，如果等于NULL说明已经退出了。 如果还在代码块中没有退出，就需要升级锁为轻量级锁，升级为轻量级锁业很简单，先将Lock Record的displaced_header设置为无锁的markoop，在把锁对象头替换成指向LockRecord的指针。 后面看完轻量级锁，再回过头看这里的升级过程，就会明白了。 如果持有偏向锁的线程已经退出了，则判断是否允许重新偏向，如果允许重新偏向，就设置锁对象的对象头为匿名偏向状态。否则设置为轻量级无锁状态，即撤销偏向锁。  批量重偏向，批量撤销  当只有一个线程A反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当线程B尝试获得锁时，就需要等到safe point时交给JVM将偏向锁撤销为无锁状态或升级为轻量级/重量级锁。（因为锁已经被线程A持有，线程B不能修改锁的状态，因为会影响线程A。所以叫给JVM来修改锁的状态）safe point这个词我们在GC中经常会提到，其代表了一个状态，在该状态下所有线程都是暂停的(STW)。总之，偏向锁的撤销是有一定成本的，如果说运行时的场景本身存在多线程竞争的，那偏向锁的存在不仅不能提高性能，而且会导致性能下降。因此，JVM中增加了一种批量重偏向/撤销的机制。\n  一个线程创建了大量对象并执行了初始的同步操作，之后在另一个线程中将这些对象作为锁进行之后的操作。这种case下，会导致大量的偏向锁撤销操作。 存在明显多线程竞争的场景下使用偏向锁是不合适的，例如生产者/消费者队列。  批量重偏向（bulk rebias）机制是为了解决第一种场景。批量撤销（bulk revoke）则是为了解决第二种场景。 JVM以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1。然后根据撤销计数器来决定是否触发批量操作，具体逻辑可以查看上面的 update_heuristics方法逻辑。\n下面我们看代码。 最终批量重偏向和批量撤销都会调用到bulk_revoke_or_rebias_at_safepoint方法。\nstatic BiasedLocking::Condition bulk_revoke_or_rebias_at_safepoint(oop o, bool bulk_rebias, bool attempt_rebias_of_object, JavaThread* requesting_thread) { ... jlong cur_time = os::javaTimeMillis(); //记录本次批量操作的时间  o-\u0026gt;klass()-\u0026gt;set_last_biased_lock_bulk_revocation_time(cur_time); Klass* k_o = o-\u0026gt;klass(); Klass* klass = k_o; if (bulk_rebias) { // 批量重偏向的逻辑  if (klass-\u0026gt;prototype_header()-\u0026gt;has_bias_pattern()) { // 拿到类中的epoch  int prev_epoch = klass-\u0026gt;prototype_header()-\u0026gt;bias_epoch(); // code 1：把类中的epoch自增加1  klass-\u0026gt;set_prototype_header(klass-\u0026gt;prototype_header()-\u0026gt;incr_bias_epoch()); // 获取到自增后的类epoch  int cur_epoch = klass-\u0026gt;prototype_header()-\u0026gt;bias_epoch(); // code 2：遍历所有线程的栈，更新所有该类型锁实例的epoch  // 这里很重要，这里是遍历的线程栈，也就是表示是当前正在使用的偏向锁  //也就是说，这里是找到所有当前正在被线程持有的，或者说正在同步代码块中执行的偏向锁对象  //然后把它们的epoch和类的epoch保持一致。  //这么做的目的是，因为线程在获取偏向锁的时候，会比较锁的epoch和类型epoch是否相同  //如果不同的话，会进行重偏向操作。所以为了避免，当前正在使用的锁，别其他线程获取，  //所以这里会把当前正在使用的锁，和类的epoch保持一致  for (JavaThread* thr = Threads::first(); thr != NULL; thr = thr-\u0026gt;next()) { GrowableArray\u0026lt;MonitorInfo*\u0026gt;* cached_monitor_info = get_or_compute_monitor_info(thr); for (int i = 0; i \u0026lt; cached_monitor_info-\u0026gt;length(); i++) { MonitorInfo* mon_info = cached_monitor_info-\u0026gt;at(i); oop owner = mon_info-\u0026gt;owner(); markOop mark = owner-\u0026gt;mark(); if ((owner-\u0026gt;klass() == k_o) \u0026amp;\u0026amp; mark-\u0026gt;has_bias_pattern()) { // We might have encountered this object already in the case of recursive locking  assert(mark-\u0026gt;bias_epoch() == prev_epoch || mark-\u0026gt;bias_epoch() == cur_epoch, \u0026#34;error in bias epoch adjustment\u0026#34;); owner-\u0026gt;set_mark(mark-\u0026gt;set_bias_epoch(cur_epoch)); } } } } // 接下来对当前锁对象进行重偏向  //没错这里也是调用的 revoke_bias,不过第三个参数 is_bulk 为true  revoke_bias(o, attempt_rebias_of_object \u0026amp;\u0026amp; klass-\u0026gt;prototype_header()-\u0026gt;has_bias_pattern(), true, requesting_thread); } else { ... // code 3：批量撤销的逻辑，将类中的偏向标记关闭，markOopDesc::prototype()返回的是一个关闭偏向模式的prototype  klass-\u0026gt;set_prototype_header(markOopDesc::prototype()); // code 4：遍历所有线程的栈，撤销该类所有锁的偏向  //这里和上面批量重偏向一样，撤销的也是当前被使用的锁对象  for (JavaThread* thr = Threads::first(); thr != NULL; thr = thr-\u0026gt;next()) { GrowableArray\u0026lt;MonitorInfo*\u0026gt;* cached_monitor_info = get_or_compute_monitor_info(thr); for (int i = 0; i \u0026lt; cached_monitor_info-\u0026gt;length(); i++) { MonitorInfo* mon_info = cached_monitor_info-\u0026gt;at(i); oop owner = mon_info-\u0026gt;owner(); markOop mark = owner-\u0026gt;mark(); // 判断锁是否该类型的，并且开启了偏向模式  if ((owner-\u0026gt;klass() == k_o) \u0026amp;\u0026amp; mark-\u0026gt;has_bias_pattern()) { //执行偏向撤销，并且allow_rebias 为false，is_bulk 为true  revoke_bias(owner, false, true, requesting_thread); } } } // 撤销当前锁对象的偏向模式  revoke_bias(o, false, true, requesting_thread); } ... BiasedLocking::Condition status_code = BiasedLocking::BIAS_REVOKED; //在执行完批量操作后，如果允许重偏向，并且锁对象和类都处于偏向模式  //那么就让这个锁对象直接重偏向到当前线程，因为这里是安全点，所以直接设置即可，不需要考虑并发。  if (attempt_rebias_of_object \u0026amp;\u0026amp; o-\u0026gt;mark()-\u0026gt;has_bias_pattern() \u0026amp;\u0026amp; klass-\u0026gt;prototype_header()-\u0026gt;has_bias_pattern()) { // 构造一个偏向请求线程的mark word  markOop new_mark = markOopDesc::encode(requesting_thread, o-\u0026gt;mark()-\u0026gt;age(), klass-\u0026gt;prototype_header()-\u0026gt;bias_epoch()); // 更新当前锁对象的mark word  o-\u0026gt;set_mark(new_mark); status_code = BiasedLocking::BIAS_REVOKED_AND_REBIASED; ... } ... return status_code; } 这个方法的整体逻辑还是比较清晰的。\n 首先记录本次批量操作的时间 然后根据类型是批量重偏向还是批量撤销 然后都是遍历所有的线程栈，找到仍然在使用的锁对象  重偏向的修改epoch，然后执行偏向撤销 批量撤销的，就执行偏向撤销  批量操作完成之后，如果锁对象和class仍然处于偏向模式，并且是允许重偏向的，那么就把锁对象偏向到当前线程。  我觉的这里的一个关键点就是，要理解批量操作的锁对象，都是正在被线程使用的。其他没有被操作的锁对象，需要等待。\n偏向锁释放 CASE(_monitorexit): { oop lockee = STACK_OBJECT(-1); CHECK_NULL(lockee); // derefing\u0026#39;s lockee ought to provoke implicit null check  // find our monitor slot  BasicObjectLock* limit = istate-\u0026gt;monitor_base(); BasicObjectLock* most_recent = (BasicObjectLock*) istate-\u0026gt;stack_base(); //循环遍历线程栈中的Lock Record  while (most_recent != limit ) { //如果Lock Record的Obj指向的是当前锁对象，说明是当前锁对象的Lock Record  if ((most_recent)-\u0026gt;obj() == lockee) { BasicLock* lock = most_recent-\u0026gt;lock(); markOop header = lock-\u0026gt;displaced_header(); //将obj设置为Null  most_recent-\u0026gt;set_obj(NULL); //如果不是偏向模式（即是轻量级锁）,下面是轻量级模式。  if (!lockee-\u0026gt;mark()-\u0026gt;has_bias_pattern()) { bool call_vm = UseHeavyMonitors; // If it isn\u0026#39;t recursive we either must swap old header or call the runtime  if (header != NULL || call_vm) { //将对象头中的markoop替换为Lock Record中的markoop  if (call_vm || Atomic::cmpxchg_ptr(header, lockee-\u0026gt;mark_addr(), lock) != lock) { // restore object for the slow case  //如果替换失败，则还原Lock Record，并且执行锁升级的monitorexit  most_recent-\u0026gt;set_obj(lockee); CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception); } } } UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1); } most_recent++; } // Need to throw illegal monitor state exception  CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception); ShouldNotReachHere(); }  遍历当前线程栈中的所有的Lock Record， 如果Lock Record的obj指向的是自己，则说明当前的Lock Record属于当前锁对象。 将Lock Record的obj设置为空。如果是偏向锁，则就不做其他操作了。 如果是轻量级锁，后面再说明。  HashCode和偏向锁 在上面时，我们提到当调用hashCode的时候，会引起偏向撤销,我们先用Java代码模拟一下这个情况。\n在同步代码中调用锁的hashcode对锁状态的影响 public class HashCodeAndBiasLock { /* 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jol\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jol-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.14\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; */ public static void main(String[] args) throws InterruptedException { Thread.sleep(5000); BiasLock lock = new BiasLock(); System.out.println(\u0026#34;初始状态\u0026#34;); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); synchronized (lock){ System.out.println(\u0026#34;加锁状态\u0026#34;); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); lock.hashCode(); System.out.println(\u0026#34;hashcode后状态\u0026#34;); System.out.println(ClassLayout.parseInstance(lock).toPrintable()); } } } 执行结果 我们关注一下圈出来的部分\n大多数cpu使用的是小端序，数据的高位字节存放在地址的高端 低位字节存放在地址低端。锁标志位在对象头中处于最右边的高字节，所以在小端序中就会放到地址的高端，也就是最左边。\n 锁对象初始的时候是匿名偏向状态， 加锁之后，还是偏向状态，偏向了当前线程 调用hashcode之后，就升级到了重量级锁  那么下面我们就根据代码具体分析一下。 hashCode()是本地native方法，实现最终调用是synchronizer.cpp中的ObjectSynchronizer::FastHashCode\nintptr_t ObjectSynchronizer::FastHashCode(Thread * Self, oop obj) { //首先就判断了JVM是否启用了偏向锁（这个由参数配置），  if (UseBiasedLocking) { // NOTE: many places throughout the JVM do not expect a safepoint  // to be taken here, in particular most operations on perm gen  // objects. However, we only ever bias Java instances and all of  // the call sites of identity_hash that might revoke biases have  // been checked to make sure they can handle a safepoint. The  // added check of the bias pattern is to avoid useless calls to  // thread-local storage.  if (obj-\u0026gt;mark()-\u0026gt;has_bias_pattern()) { // Handle for oop obj in case of STW safepoint  Handle hobj(Self, obj); //然后判断当前是否是偏向模式（即偏向还没有被撤销），  //如果都是，则撤销偏向模式  BiasedLocking::revoke_and_rebias(hobj, false, JavaThread::current()); obj = hobj(); } } ObjectMonitor* monitor = NULL; markOop temp, test; intptr_t hash; markOop mark = ReadStableMark(obj); //无锁状态  //当在同步方法执行之前，调用hashcode,那么会进入这里  if (mark-\u0026gt;is_neutral()) { //这里会先去对象头中拿hash  hash = mark-\u0026gt;hash(); // this is a normal header  if (hash) { // if it has hash, just return it  return hash; } //如果为空，则重新计算hash，并设置到一个对象头中  hash = get_next_hash(Self, obj); // allocate a new hash code  temp = mark-\u0026gt;copy_set_hash(hash); // merge the hash code into header  // use (machine word version) atomic operation to install the hash  // 如果设置成功则返回计算的hashcode  test = (markOop) Atomic::cmpxchg_ptr(temp, obj-\u0026gt;mark_addr(), mark); if (test == mark) { return hash; } // If atomic operation failed, we must inflate the header  // into heavy weight monitor. We could add more code here  // for fast path, but it does not worth the complexity.  //这种是重量级锁的情况下，尝试从monitor中保存的对象头中获取hashcode，如果获取不到则升级到重量级锁  } else if (mark-\u0026gt;has_monitor()) { monitor = mark-\u0026gt;monitor(); temp = monitor-\u0026gt;header(); assert(temp-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); hash = temp-\u0026gt;hash(); if (hash) { return hash; } // Skip to the following code to reduce code size  //如果是轻量级锁,尝试再对象头中获取，如果获取不到则升级到重量级锁  } else if (Self-\u0026gt;is_lock_owned((address)mark-\u0026gt;locker())) { temp = mark-\u0026gt;displaced_mark_helper(); // this is a lightweight monitor owned  assert(temp-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); hash = temp-\u0026gt;hash(); // by current thread, check if the displaced  if (hash) { // header contains hash code  return hash; } // WARNING:  // The displaced header is strictly immutable.  // It can NOT be changed in ANY cases. So we have  // to inflate the header into heavyweight monitor  // even the current thread owns the lock. The reason  // is the BasicLock (stack slot) will be asynchronously  // read by other threads during the inflate() function.  // Any change to stack may not propagate to other threads  // correctly.  } // Inflate the monitor to set hash code  // 到这儿，说明没有获取到hashCode，首先直接将锁膨胀为轻量级锁，然后获取hashcode并且设置hsahcode  monitor = ObjectSynchronizer::inflate(Self, obj); // Load displaced header and check it has hash code  mark = monitor-\u0026gt;header(); assert(mark-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); hash = mark-\u0026gt;hash(); if (hash == 0) { hash = get_next_hash(Self, obj); temp = mark-\u0026gt;copy_set_hash(hash); // merge hash code into header  assert(temp-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); test = (markOop) Atomic::cmpxchg_ptr(temp, monitor, mark); if (test != mark) { // The only update to the header in the monitor (outside GC)  // is install the hash code. If someone add new usage of  // displaced header, please update this code  hash = test-\u0026gt;hash(); assert(test-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); assert(hash != 0, \u0026#34;Trivial unexpected object/monitor header usage.\u0026#34;); } } // We finally get the hash  return hash; 我们来分析一下执行流程。\n 如果JVM开启了偏向锁，并且锁处于偏向模式，就会调用revoke_and_rebias撤销偏向 如果锁对象处于无锁状态，就会计算hashcode，并设置到对象头中，如果设置成功，返回计算的hashcode 如果锁是处于重量级锁状态，就从Monitor中的保存的对象头中获取hashcode 如果处于轻量级，就从Lock Record保存的对象头中获取hashcode 如果上述操作失败了，或者没有获取到，则会把锁升级到重量级，然后重新计算并返回。  所以就能解释上面Java代码的情况了\n 执行hashcode()时，锁处于偏向状态，所以首先会执行revoke_and_bias,撤销偏向锁，然后进入revoke_bias，判断当前线程还存活，所以会升级到轻量级锁。 继续回到hashcode中执行，就会走到轻量级的判断，因为这时候还没所有生成过hashcode，所以Lock Record中的hashcode是空的，所以就会继续向下走升级到重量级锁。  关于偏向撤销的思考  其实这里我也一直有一个疑问，就是在很多情况下，直接重偏向应该是一个更好的选择，那为什么每次都要先进行偏向撤销？\n 我自己考虑可能会有两个方面的原因\n 首先重偏向的操作不能影响正在持有锁的线程。因为单单只根据对象头无法得知持有偏向锁线程的状态。所以正常的偏向只能发生在从匿名偏向到偏向的这个过程。而重偏向也只有在安全点中，也就是能够确认线程已经执行完同步代码的情况下才能发生（也就是 revoke_bias中最下面的那段逻辑） 另一个原因就是，既然会有锁升级，那就表示每个阶段的锁都有最适合自己的场景。既然已经有了多个线程尝试获取锁，那么就说明在一定程度上已经到了不适合偏向锁的场景了，如果强行使用偏向锁，那么就会无法利用到偏向锁的优势，反而造成锁性能下降。  偏向锁的优势就在于少了一次CAS操作，偏向锁在偏向之后，如果是同一个线程尝试加锁，只需要一次比较操作，就能加锁成功。 如果强行使用偏向锁，当一个线程尝试锁定一个已经偏向另一个线程的锁对象的时候，直接进行重偏向，那么这时候需要进行的操作就是\n 判断是不是偏向状态 判断是不是偏向的线程 还得等到安全点判断之前的线程是否还存活（这个是最要命的） CAS替换偏向线程ID 这样的话，就损失掉了偏向锁相对于轻量级锁的优势。而且多耗费了很多  所以JVM在遇到有多个线程尝试锁定同一个对象的时候，会直接锁升级。 所以有就有说到了上面的提到的不同锁，使用场景问题。 让偏向锁只工作在自己最优的没有线程竞争的环境下，从而达到最佳的性能。\n轻量级锁过程 轻量级锁被设计用于多个线程交替访问场景下的synchronized，适用一次CAS就能获取到锁。\n轻量级获取 当上面的偏向锁获取失败的时候，会升级到轻量级锁。 这时候锁对象的对象头格式也会发生相应的变化，在锁对象的对象头中，会存储一个指向持有锁的线程的线程栈中的一个Lock Record的指针。 被Lock Record指针锁顶替的对象头中其他字段的信息，为在Lock Record中存储。\nCASE(_monitorenter): { oop lockee = STACK_OBJECT(-1); ... if (entry != NULL) { ... // 上面省略的代码中如果CAS操作失败也会调用到InterpreterRuntime::monitorenter  // traditional lightweight locking  //轻量级锁  if (!success) { //设置当前的对象头为无锁状态，并且复制到Lock Record中的markoop中  markOop displaced = lockee-\u0026gt;mark()-\u0026gt;set_unlocked(); entry-\u0026gt;lock()-\u0026gt;set_displaced_header(displaced); bool call_vm = UseHeavyMonitors; //将对象头中的地址替换为指向Lock Record的指针，替换成功，则说明获取轻量级锁成功,则什么都不做。  //这里替换失败有两种情况  // 1.发生了竞争  // 2.是锁重入  //所以下面继续判断是否为所重入  if (call_vm || Atomic::cmpxchg_ptr(entry, lockee-\u0026gt;mark_addr(), displaced) != displaced) { // Is it simple recursive case?  //这里判断是不是锁重入，判断指向Lock Record的指针指向的地址是否属于当前线程栈  if (!call_vm \u0026amp;\u0026amp; THREAD-\u0026gt;is_lock_owned((address) displaced-\u0026gt;clear_lock_bits())) { //如果是轻量级锁的锁重入,说明前面set_displaced_header设置的是第一个Lock Record的地址，  //所以要重新将申请的Lock Record的displaced_header置为空,同样也会通过申请的displaced_header的个数来统计轻量级锁的重入次数  //栈的最高位的Lock Record的displaced_header不是空，重入锁退出锁的时候，会由低到高遍历退出，只在最后一个锁的时候使用CAS替换  entry-\u0026gt;lock()-\u0026gt;set_displaced_header(NULL); } else { //不是所重入，是发生了竞争，则进行锁升级  CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception); } } } UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1); } else { istate-\u0026gt;set_msg(more_monitors); UPDATE_PC_AND_RETURN(0); // Re-execute  } }  构建一个无锁状态的对象头，(也就是把对象头的后三位设置为001，其他位不变) 把这个无锁的对象头保存到Lock Record中的Displaced header中。 判断是否有UseHeavyMonitors参数，如果有，则直接走重量级锁 使用CAS操作，把指向当前Lock Record的对象头，替换到锁对象的对象头中。  如果CAS成功，则表示获取成功，则结束 如果CAS失败，则表示当前锁对象的对象头已经不是无锁状态，已经有线程轻量级锁定了这个对象  需要判断是不是当前线程，如果是当前线程则表示是重入 如果不是当前线程，则表示发生了线程争抢，另一个线程已经获取到了轻量级锁，则需要进行锁升级    轻量级锁重入处理 当发生了,轻量级锁重入，会把第二次重入的displaced header 设置为null，因为记录重入后的对象头是没有必要的，因为所有的重入锁都退出之后，最终还是要把最开始的那个lock record中的displaced header还原到锁对象头中。中间的重入操作都可能省略掉这个操作。 轻量级释放 CASE(_monitorexit): { oop lockee = STACK_OBJECT(-1); CHECK_NULL(lockee); // derefing\u0026#39;s lockee ought to provoke implicit null check  // find our monitor slot  BasicObjectLock* limit = istate-\u0026gt;monitor_base(); BasicObjectLock* most_recent = (BasicObjectLock*) istate-\u0026gt;stack_base(); //循环遍历线程栈中的Lock Record  while (most_recent != limit ) { //如果Lock Record的Obj指向的是当前锁对象，说明是当前锁对象的Lock Record  if ((most_recent)-\u0026gt;obj() == lockee) { BasicLock* lock = most_recent-\u0026gt;lock(); markOop header = lock-\u0026gt;displaced_header(); //将obj设置为Null  most_recent-\u0026gt;set_obj(NULL); //如果不是偏向模式（即是轻量级锁）  if (!lockee-\u0026gt;mark()-\u0026gt;has_bias_pattern()) { bool call_vm = UseHeavyMonitors; // If it isn\u0026#39;t recursive we either must swap old header or call the runtime  if (header != NULL || call_vm) { //将对象头中的markoop替换为Lock Record中的markoop  if (call_vm || Atomic::cmpxchg_ptr(header, lockee-\u0026gt;mark_addr(), lock) != lock) { // restore object for the slow case  //如果替换失败，则还原Lock Record，并且执行锁升级的monitorexit  //说明在持有轻量级锁期间，有另一个线程，尝试获取，导致锁已经升级到重量级了  most_recent-\u0026gt;set_obj(lockee); CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception); } } } UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1); } most_recent++; } // Need to throw illegal monitor state exception  CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception); ShouldNotReachHere(); }  循环遍历当前线程的线程栈，找到指向当前锁对象的Lock Record. 将Lock Record的obj设置为空，也就是不再让Lock Record指向锁对象。（这个动作偏向锁也会有） 判断如果是轻量级锁，然后判断如果Lock Record的Displaced header不为空，则通过CAS将Displaced header中的markoop替换回对象头中。前面讲轻量级锁获取的时候也有提到过，如果是轻量级锁重入，则Lock Record的Displaced header设置为空，这里退出的时候，会判断如果不为空则替换。 如果替换成功，则释放锁成功。如果替换失败，则说明当前锁被其他线程抢占过，所已经升级到了重量级。所以要执行InterpreterRuntime::monitorexit的退出逻辑，monitorexit中，主要做的是轻量级锁的退出和锁膨胀为重量级锁。\nIRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem)) #ifdef ASSERT thread-\u0026gt;last_frame().interpreter_frame_verify_monitor(elem); #endif Handle h_obj(thread, elem-\u0026gt;obj()); assert(Universe::heap()-\u0026gt;is_in_reserved_or_null(h_obj()), \u0026#34;must be NULL or an object\u0026#34;); if (elem == NULL || h_obj()-\u0026gt;is_unlocked()) { THROW(vmSymbols::java_lang_IllegalMonitorStateException()); } ObjectSynchronizer::slow_exit(h_obj(), elem-\u0026gt;lock(), thread); // Free entry. This must be done here, since a pending exception might be installed on // exit. If it is not cleared, the exception handling code will try to unlock the monitor again. elem-\u0026gt;set_obj(NULL); #ifdef ASSERT thread-\u0026gt;last_frame().interpreter_frame_verify_monitor(elem); #endif IRT_ENDvoid ObjectSynchronizer::fast_exit(oop object, BasicLock* lock, TRAPS) { assert(!object-\u0026gt;mark()-\u0026gt;has_bias_pattern(), \u0026#34;should not see bias pattern here\u0026#34;); // if displaced header is null, the previous enter is recursive enter, no-op markOop dhw = lock-\u0026gt;displaced_header(); markOop mark; //这里判断，Lock Record的displaced_header是否为空，如果是，当前的Lock Record是重入中的一个。 //如果没有持有轻量级锁，那就没必要执行膨胀了，直接返回。中间assert了一下是否已经是重量级锁，别的什么也没做。 if (dhw == NULL) { // Recursive stack-lock. // Diagnostics -- Could be: stack-locked, inflating, inflated. mark = object-\u0026gt;mark(); assert(!mark-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); if (mark-\u0026gt;has_locker() \u0026amp;\u0026amp; mark != markOopDesc::INFLATING()) { assert(THREAD-\u0026gt;is_lock_owned((address)mark-\u0026gt;locker()), \u0026#34;invariant\u0026#34;); } if (mark-\u0026gt;has_monitor()) { ObjectMonitor * m = mark-\u0026gt;monitor(); assert(((oop)(m-\u0026gt;object()))-\u0026gt;mark() == mark, \u0026#34;invariant\u0026#34;); assert(m-\u0026gt;is_entered(THREAD), \u0026#34;invariant\u0026#34;); } return; } //执行到这儿，说明Lock Record的displaced_header不为空，说明可能是轻量级锁，也可能已经膨胀为了重量级锁。 mark = object-\u0026gt;mark(); // If the object is stack-locked by the current thread, try to // swing the displaced header from the box back to the mark. //尝试将其强转为markOop，成功，则说明还是轻量级锁，则尝试用CAS将Lock Record的isplaced_header替换回对象头。 //则尝试释放轻量级锁，即通过CAS将displaced header替换回对象头中，替换成功则说明轻量级锁释放成功。 if (mark == (markOop) lock) { assert(dhw-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); if ((markOop) Atomic::cmpxchg_ptr (dhw, object-\u0026gt;mark_addr(), mark) == mark) { TEVENT(fast_exit: release stacklock); return; } } //开始执行锁的膨胀升级为重量级锁，并且执行exit ObjectSynchronizer::inflate(THREAD, object)-\u0026gt;exit(true, THREAD); } 这里判断，Lock Record的displaced_header是否为空，如果是，则说明已经没有持有当前轻量级级锁了。如果没有持有轻量级锁，那就没必要执行膨胀了，直接返回。中间assert了一下是否已经是重量级锁，别的什么也没做。\n 如果Lock Record的displaced_header不为空， 判断如果当前对象头还是轻量级锁，并且指向的是当前Lock Record，则尝试释放轻量级锁，即通过CAS将displaced header替换回对象头中，替换成功则说明轻量级锁释放成功。\n 如果前面的判断或者是替换都失败了，就开始执行ObjectSynchronizer::inflate进行锁膨胀为重量级锁。膨胀成功后ObjectSynchronizer::inflate的返回值为ObjectMonitor对象，ObjectMonitor就是用于实现重量级锁的。然后调用ObjectMonitor的exit方法进行锁的释放。\n  重量级锁 重量级锁被设计用于有线程竞争的场景的，在重量级模式下，没有获取到锁的线程，会先通过自旋，然后进入阻塞操作。避免大量无效的自旋，占用过多的CPU资源。 下面我们还是通过代码来分析一下。\n重量级锁获取 在偏向锁撤销之后，会调用到slow_enter方法，然后在进行一次轻量级获取，如果仍然失败，就会执行inflate，锁膨胀，并返回一下ObjectMonitor对象。\nvoid ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) { markOop mark = obj-\u0026gt;mark(); assert(!mark-\u0026gt;has_bias_pattern(), \u0026#34;should not see bias pattern here\u0026#34;); //无锁状态  if (mark-\u0026gt;is_neutral()) { // Anticipate successful CAS -- the ST of the displaced mark must  // be visible \u0026lt;= the ST performed by the CAS.  lock-\u0026gt;set_displaced_header(mark); if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-\u0026gt;mark_addr(), mark)) { TEVENT(slow_enter: release stacklock); return; } // Fall through to inflate() ...  // 轻量级锁重入  } else if (mark-\u0026gt;has_locker() \u0026amp;\u0026amp; THREAD-\u0026gt;is_lock_owned((address)mark-\u0026gt;locker())) { assert(lock != mark-\u0026gt;locker(), \u0026#34;must not re-lock the same lock\u0026#34;); assert(lock != (BasicLock*)obj-\u0026gt;mark(), \u0026#34;don\u0026#39;t relock with same BasicLock\u0026#34;); lock-\u0026gt;set_displaced_header(NULL); return; } // The object header will never be displaced to this lock,  // so it does not matter what the value is, except that it  // must be non-zero to avoid looking like a re-entrant lock,  // and must not look locked either.  // 现在这个lock是没有获取到锁的线程的lock record，现在存储的是什么并不重要，所以设置没有什么特殊意义的值。  // 不能为null，因为null代表重入  // 不能为0，10，01，因为他们都有相对的意义，所以只能为11了  lock-\u0026gt;set_displaced_header(markOopDesc::unused_mark()); //开始升级为重量级锁  ObjectSynchronizer::inflate(THREAD, obj())-\u0026gt;enter(THREAD); } 获取monitor对象 inflate ObjectMonitor * NOINLINE ObjectSynchronizer::inflate(Thread * Self, oop object) { // Inflate mutates the heap ...  // Relaxing assertion for bug 6320749.  assert(Universe::verify_in_progress() || !SafepointSynchronize::is_at_safepoint(), \u0026#34;invariant\u0026#34;); for (;;) { //获取锁对象的markoop  const markOop mark = object-\u0026gt;mark(); assert(!mark-\u0026gt;has_bias_pattern(), \u0026#34;invariant\u0026#34;); // The mark can be in one of the following states:  // * Inflated - just return  // * Stack-locked - coerce it to inflated  // * INFLATING - busy wait for conversion to complete  // * Neutral - aggressively inflate the object.  // * BIASED - Illegal. We should never see this  // CASE: inflated  //判断是否有Objectmonitor,如果有，说明已经膨胀过了，直接返回monitor  if (mark-\u0026gt;has_monitor()) { ObjectMonitor * inf = mark-\u0026gt;monitor(); assert(inf-\u0026gt;header()-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); assert(inf-\u0026gt;object() == object, \u0026#34;invariant\u0026#34;); assert(ObjectSynchronizer::verify_objmon_isinpool(inf), \u0026#34;monitor is invalid\u0026#34;); return inf; } // CASE: inflation in progress - inflating over a stack-lock.  // Some other thread is converting from stack-locked to inflated.  // Only that thread can complete inflation -- other threads must wait.  // The INFLATING value is transient.  // Currently, we spin/yield/park and poll the markword, waiting for inflation to finish.  // We could always eliminate polling by parking the thread on some auxiliary list.  //如果有其他线程正在执行膨胀，则当前线程不再去执行膨胀逻辑,进行忙等待，直到膨胀完成  if (mark == markOopDesc::INFLATING()) { TEVENT(Inflate: spin while INFLATING); ReadStableMark(object); continue; } // CASE: stack-locked  // Could be stack-locked either by this thread or by some other thread.  //  // Note that we allocate the objectmonitor speculatively, _before_ attempting  // to install INFLATING into the mark word. We originally installed INFLATING,  // allocated the objectmonitor, and then finally STed the address of the  // objectmonitor into the mark. This was correct, but artificially lengthened  // the interval in which INFLATED appeared in the mark, thus increasing  // the odds of inflation contention.  //  // We now use per-thread private objectmonitor free lists.  // These list are reprovisioned from the global free list outside the  // critical INFLATING...ST interval. A thread can transfer  // multiple objectmonitors en-mass from the global free list to its local free list.  // This reduces coherency traffic and lock contention on the global free list.  // Using such local free lists, it doesn\u0026#39;t matter if the omAlloc() call appears  // before or after the CAS(INFLATING) operation.  // See the comments in omAlloc().  //判断目前对象头的状态是否是轻量级锁的状态，则创建一个ObjectMonitor并进行初始化  if (mark-\u0026gt;has_locker()) { //创建一个ObjectMonitor  //omAlloc(Self)会尝试优先从tlab里面分配  ObjectMonitor * m = omAlloc(Self); // Optimistically prepare the objectmonitor - anticipate successful CAS  // We do this before the CAS in order to minimize the length of time  // in which INFLATING appears in the mark.  m-\u0026gt;Recycle(); m-\u0026gt;_Responsible = NULL; m-\u0026gt;_recursions = 0; m-\u0026gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit; // Consider: maintain by type/class  //设置对象的状态为膨胀中，设置失败则重新执行膨胀逻辑  //如果设置失败，则表示已经有线程膨胀完成了，所以continue，在进行上面是否有monitor的判断，然后膨胀完的monitor  markOop cmp = (markOop) Atomic::cmpxchg_ptr(markOopDesc::INFLATING(), object-\u0026gt;mark_addr(), mark); if (cmp != mark) { omRelease(Self, m, true); continue; // Interference -- just retry  } //这里描述了为什么需要添加一个 INFLATING状态  // We\u0026#39;ve successfully installed INFLATING (0) into the mark-word.  // This is the only case where 0 will appear in a mark-word.  // Only the singular thread that successfully swings the mark-word  // to 0 can perform (or more precisely, complete) inflation.  //  // Why do we CAS a 0 into the mark-word instead of just CASing the  // mark-word from the stack-locked value directly to the new inflated state?  // Consider what happens when a thread unlocks a stack-locked object.  // It attempts to use CAS to swing the displaced header value from the  // on-stack basiclock back into the object header. Recall also that the  // header value (hashcode, etc) can reside in (a) the object header, or  // (b) a displaced header associated with the stack-lock, or (c) a displaced  // header in an objectMonitor. The inflate() routine must copy the header  // value from the basiclock on the owner\u0026#39;s stack to the objectMonitor, all  // the while preserving the hashCode stability invariants. If the owner  // decides to release the lock while the value is 0, the unlock will fail  // and control will eventually pass from slow_exit() to inflate. The owner  // will then spin, waiting for the 0 value to disappear. Put another way,  // the 0 causes the owner to stall if the owner happens to try to  // drop the lock (restoring the header from the basiclock to the object)  // while inflation is in-progress. This protocol avoids races that might  // would otherwise permit hashCode values to change or \u0026#34;flicker\u0026#34; for an object.  // Critically, while object-\u0026gt;mark is 0 mark-\u0026gt;displaced_mark_helper() is stable.  // 0 serves as a \u0026#34;BUSY\u0026#34; inflate-in-progress indicator.  // fetch the displaced mark from the owner\u0026#39;s stack.  // The owner can\u0026#39;t die or unwind past the lock while our INFLATING  // object is in the mark. Furthermore the owner can\u0026#39;t complete  // an unlock on the object, either.  markOop dmw = mark-\u0026gt;displaced_mark_helper(); assert(dmw-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); // Setup monitor fields to proper values -- prepare the monitor  // 吧当前的锁对象头，保存到monitor中  m-\u0026gt;set_header(dmw); // Optimization: if the mark-\u0026gt;locker stack address is associated  // with this thread we could simply set m-\u0026gt;_owner = Self.  // Note that a thread can inflate an object  // that it has stack-locked -- as might happen in wait() -- directly  // with CAS. That is, we can avoid the xchg-NULL .... ST idiom.  //关键哈，把重量级Monitor的持有这，设置为当前整持有这个轻量级锁的线程的 Lock Record地址  m-\u0026gt;set_owner(mark-\u0026gt;locker()); m-\u0026gt;set_object(object); // TODO-FIXME: assert BasicLock-\u0026gt;dhw != 0.  // Must preserve store ordering. The monitor state must  // be stable at the time of publishing the monitor address.  guarantee(object-\u0026gt;mark() == markOopDesc::INFLATING(), \u0026#34;invariant\u0026#34;); //设置对象头指向当前的objectmonitor  object-\u0026gt;release_set_mark(markOopDesc::encode(m)); return m; } // CASE: neutral  // TODO-FIXME: for entry we currently inflate and then try to CAS _owner.  // If we know we\u0026#39;re inflating for entry it\u0026#39;s better to inflate by swinging a  // pre-locked objectMonitor pointer into the object header. A successful  // CAS inflates the object *and* confers ownership to the inflating thread.  // In the current implementation we use a 2-step mechanism where we CAS()  // to inflate and then CAS() again to try to swing _owner from NULL to Self.  // An inflateTry() method that we could call from fast_enter() and slow_enter()  // would be useful.  assert(mark-\u0026gt;is_neutral(), \u0026#34;invariant\u0026#34;); //创建ObjectMonitor  ObjectMonitor * m = omAlloc(Self); // prepare m for installation - set monitor to initial state  m-\u0026gt;Recycle(); m-\u0026gt;set_header(mark); m-\u0026gt;set_owner(NULL); m-\u0026gt;set_object(object); m-\u0026gt;_recursions = 0; m-\u0026gt;_Responsible = NULL; m-\u0026gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit; // consider: keep metastats by type/class  //把对象头替换为执行objectMonitor的指针  if (Atomic::cmpxchg_ptr (markOopDesc::encode(m), object-\u0026gt;mark_addr(), mark) != mark) { m-\u0026gt;set_object(NULL); m-\u0026gt;set_owner(NULL); m-\u0026gt;Recycle(); omRelease(Self, m, true); m = NULL; continue; // interference - the markword changed - just retry.  // The state-transitions are one-way, so there\u0026#39;s no chance of  // live-lock -- \u0026#34;Inflated\u0026#34; is an absorbing state.  } // Hopefully the performance counters are allocated on distinct  // cache lines to avoid false sharing on MP systems ...  OM_PERFDATA_OP(Inflations, inc()); TEVENT(Inflate: overwrite neutral); if (log_is_enabled(Debug, monitorinflation)) { if (object-\u0026gt;is_instance()) { ResourceMark rm; log_debug(monitorinflation)(\u0026#34;Inflating object \u0026#34; INTPTR_FORMAT \u0026#34; , mark \u0026#34; INTPTR_FORMAT \u0026#34; , type %s\u0026#34;, p2i(object), p2i(object-\u0026gt;mark()), object-\u0026gt;klass()-\u0026gt;external_name()); } } return m; } } inflate方法的功能是返回一个可用ObjectMonitor对象，如果没有就创建一个。inflate中是一个for循环，主要是为了处理多线程同时调用inflate的情况。然后会根据锁对象的状态进行不同的处理：\n 已经是重量级状态，说明膨胀已经完成已经有了ObjectMonitor，直接返回 如果是轻量级锁则需要进行膨胀操作 如果是膨胀中状态，则进行忙等待 如果是无锁状态则需要进行膨胀操作  其中轻量级锁和无锁状态需要进行膨胀操作，轻量级锁膨胀流程如下：\n 调用omAlloc分配一个ObjectMonitor对象(以下简称monitor)，在omAlloc方法中会先从线程私有的monitor集合omFreeList中分配对象，如果omFreeList中已经没有monitor对象，则从JVM全局的gFreeList中分配一批monitor到omFreeList中。 初始化monitor对象 将状态设置为膨胀中（INFLATING）状态 设置monitor的header字段为displaced mark word，obj字段为锁对象 设置owner字段为之前持有轻量级锁的线程的Lock Record，也就是膨胀完之后，要让之前持有锁的线程继续持有这个重量级锁，谁能用自己的Lock Record设置owner，就表示谁获取到了这个重量级锁 设置锁对象头的mark word为重量级锁状态，指向第一步分配的monitor对象  无锁状态下的膨胀流程如下：\n 调用omAlloc分配一个ObjectMonitor对象(以下简称monitor) 初始化monitor对象 设置monitor的header字段为 mark word，owner字段为null，obj字段为锁对象 设置锁对象头的mark word为重量级锁状态，指向第一步分配的monitor对象  进入重量级锁 enter 在获得了Monitor之后，线程就要进入Monitor，看看能不能获取到重量锁了\nvoid ATTR ObjectMonitor::enter(TRAPS) { Thread * const Self = THREAD ; void * cur ; // owner为null代表无锁状态，如果能CAS设置成功，则当前线程直接获得锁  cur = Atomic::cmpxchg_ptr (Self, \u0026amp;_owner, NULL) ; if (cur == NULL) { ... return ; } // 如果是重入的情况，则把重入计数器加1  if (cur == Self) { // TODO-FIXME: check for integer overflow! BUGID 6557169.  _recursions ++ ; return ; } // 当前线程是之前持有轻量级锁的线程。由轻量级锁膨胀且第一次调用enter方法，那cur是指向Lock Record的指针  // 这里也就是说，之前持有轻量级锁的线程，自己膨胀到重量级锁，同志们有印象是什么操作吗，就是在同步代码块中调用了hashcode呀，就会执行到这个逻辑  if (Self-\u0026gt;is_lock_owned ((address)cur)) { assert (_recursions == 0, \u0026#34;internal state error\u0026#34;); // 重入计数重置为1  // 因为之前就是这个线程持有轻量级锁，现在还是这个线程持有重量级锁，还是相当于锁重入了，所以_recursions设置为1，表示重入1次。  _recursions = 1 ; // 设置owner字段为当前线程（之前owner是指向Lock Record的指针）  _owner = Self ; return ; } ... // 在调用昂贵的系统同步操作之前，先尝试一轮自适应自旋  if (Knob_SpinEarly \u0026amp;\u0026amp; TrySpin (Self) \u0026gt; 0) { ... //自旋的过程中获得了锁，则直接返回  Self-\u0026gt;_Stalled = 0 ; return ; } ... { ... for (;;) { jt-\u0026gt;set_suspend_equivalent(); // 在该方法中调用系统同步操作  EnterI (THREAD) ; ... } Self-\u0026gt;set_current_pending_monitor(NULL); } ... } 我们看到，这个enter方法，还是通过CAS和自旋来尝试获得重量级锁，如果同构这两步能够获取成功，那么就能够避免切换到内核态去执行。 如果不能获取到，也不能让线程一直自旋获取，需要调用EnterI来获取锁，获取进入阻塞状态。\n重量级进入 EnterI 在进入到这个方法之前，我们在来熟悉一下ObjectMonitor中比较重要的属性，有的之前已经见到了，有的还没有\n   名称 作用     _header 保存锁对象的对象头markoop   _object 锁对象   _owner 正常情况下是持有锁的线程，如果是有轻量级膨胀上来的，那么会是当时轻量级Lock Reord   _recursions 重量级锁的重入次数   _EntryList 被阻塞的线程重新进入时，会将其放在当前队列中。其实这个队列是被wait()方法阻塞的线程，当调用notify/notifyAll时，会将准备唤醒的线程放在这个队列中。   _cxq 当对象锁已经被一个线程持有，其他所有的线程在尝试获取锁的时候，如果没有获取到，将其挂起后都会被放在这个队列上。   _WaitSet 调用wait()方法阻塞的线程，都会放在当前队列中   _succ 线程是在线程释放锁是被设置，其含义是Heir presumptive，也就是假定继承人   _Responsible 当竞争发生时，选取一个线程作为_Responsible，_Responsible线程调用的是有时间限制的park方法，其目的是防止出现搁浅现象。    void NOINLINE ObjectMonitor::EnterI(TRAPS) { Thread * const Self = THREAD; assert(Self-\u0026gt;is_Java_thread(), \u0026#34;invariant\u0026#34;); assert(((JavaThread *) Self)-\u0026gt;thread_state() == _thread_blocked, \u0026#34;invariant\u0026#34;); // Try the lock - TATAS  if (TryLock (Self) \u0026gt; 0) { assert(_succ != Self, \u0026#34;invariant\u0026#34;); assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(_Responsible != Self, \u0026#34;invariant\u0026#34;); return; } DeferredInitialize(); // We try one round of spinning *before* enqueueing Self.  //  // If the _owner is ready but OFFPROC we could use a YieldTo()  // operation to donate the remainder of this thread\u0026#39;s quantum  // to the owner. This has subtle but beneficial affinity  // effects.  // 再尝试一轮自旋  // 我们看到这里又同样的逻辑执行了2次，为什么这样呢，  if (TrySpin (Self) \u0026gt; 0) { assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(_succ != Self, \u0026#34;invariant\u0026#34;); assert(_Responsible != Self, \u0026#34;invariant\u0026#34;); return; } // The Spin failed -- Enqueue and park the thread ...  assert(_succ != Self, \u0026#34;invariant\u0026#34;); assert(_owner != Self, \u0026#34;invariant\u0026#34;); assert(_Responsible != Self, \u0026#34;invariant\u0026#34;); // Enqueue \u0026#34;Self\u0026#34; on ObjectMonitor\u0026#39;s _cxq.  //  // Node acts as a proxy for Self.  // As an aside, if were to ever rewrite the synchronization code mostly  // in Java, WaitNodes, ObjectMonitors, and Events would become 1st-class  // Java objects. This would avoid awkward lifecycle and liveness issues,  // as well as eliminate a subset of ABA issues.  // TODO: eliminate ObjectWaiter and enqueue either Threads or Events.  ObjectWaiter node(Self); Self-\u0026gt;_ParkEvent-\u0026gt;reset(); node._prev = (ObjectWaiter *) 0xBAD; node.TState = ObjectWaiter::TS_CXQ; // Push \u0026#34;Self\u0026#34; onto the front of the _cxq.  // Once on cxq/EntryList, Self stays on-queue until it acquires the lock.  // Note that spinning tends to reduce the rate at which threads  // enqueue and dequeue on EntryList|cxq.  ObjectWaiter * nxt; for (;;) { node._next = nxt = _cxq; //尝试将当前线程放在cxq队列的头部，如果放成功了则跳出循环  if (Atomic::cmpxchg_ptr(\u0026amp;node, \u0026amp;_cxq, nxt) == nxt) break; // Interference - the CAS failed because _cxq changed. Just retry.  // As an optional optimization we retry the lock.  //放失败了，则说明cxq对象被改变了，则尝试获取锁。  //获取成功则直接返回，获取失败，在继续尝试将线程放在Cxq队列的头部  if (TryLock (Self) \u0026gt; 0) { assert(_succ != Self, \u0026#34;invariant\u0026#34;); assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(_Responsible != Self, \u0026#34;invariant\u0026#34;); return; } } // Check for cxq|EntryList edge transition to non-null. This indicates  // the onset of contention. While contention persists exiting threads  // will use a ST:MEMBAR:LD 1-1 exit protocol. When contention abates exit  // operations revert to the faster 1-0 mode. This enter operation may interleave  // (race) a concurrent 1-0 exit operation, resulting in stranding, so we  // arrange for one of the contending thread to use a timed park() operations  // to detect and recover from the race. (Stranding is form of progress failure  // where the monitor is unlocked but all the contending threads remain parked).  // That is, at least one of the contended threads will periodically poll _owner.  // One of the contending threads will become the designated \u0026#34;Responsible\u0026#34; thread.  // The Responsible thread uses a timed park instead of a normal indefinite park  // operation -- it periodically wakes and checks for and recovers from potential  // strandings admitted by 1-0 exit operations. We need at most one Responsible  // thread per-monitor at any given moment. Only threads on cxq|EntryList may  // be responsible for a monitor.  //  // Currently, one of the contended threads takes on the added role of \u0026#34;Responsible\u0026#34;.  // A viable alternative would be to use a dedicated \u0026#34;stranding checker\u0026#34; thread  // that periodically iterated over all the threads (or active monitors) and unparked  // successors where there was risk of stranding. This would help eliminate the  // timer scalability issues we see on some platforms as we\u0026#39;d only have one thread  // -- the checker -- parked on a timer.  //这里判断的是，如果nex==null(说明cxq队列为空)，并且entryList为空。  //那说明当前线程是第一个阻塞或者等待当前锁的线程  //也就是说，这个线程是进入monitor的第一个线程，那么就把这个线程设置为_Responsible  if ((SyncFlags \u0026amp; 16) == 0 \u0026amp;\u0026amp; nxt == NULL \u0026amp;\u0026amp; _EntryList == NULL) { // Try to assume the role of responsible thread for the monitor.  // CONSIDER: ST vs CAS vs { if (Responsible==null) Responsible=Self }  //通过cas将_Responsible指针指向Self  Atomic::cmpxchg_ptr(Self, \u0026amp;_Responsible, NULL); } // The lock might have been released while this thread was occupied queueing  // itself onto _cxq. To close the race and avoid \u0026#34;stranding\u0026#34; and  // progress-liveness failure we must resample-retry _owner before parking.  // Note the Dekker/Lamport duality: ST cxq; MEMBAR; LD Owner.  // In this case the ST-MEMBAR is accomplished with CAS().  //  // TODO: Defer all thread state transitions until park-time.  // Since state transitions are heavy and inefficient we\u0026#39;d like  // to defer the state transitions until absolutely necessary,  // and in doing so avoid some transitions ...  TEVENT(Inflated enter - Contention); int nWakeups = 0; int recheckInterval = 1; //执行到这儿，说明线程已经被成功放在了cxq队列的头部，  //然后下面进入一个循环，只有成功获取到了锁，才能够跳出循环。  for (;;) { //再次尝试获取锁  if (TryLock(Self) \u0026gt; 0) break; assert(_owner != Self, \u0026#34;invariant\u0026#34;); //如果_Responsible指针为NULL，则再次尝试让_Responsible指向当前线程  if ((SyncFlags \u0026amp; 2) \u0026amp;\u0026amp; _Responsible == NULL) { Atomic::cmpxchg_ptr(Self, \u0026amp;_Responsible, NULL); } // park self  //如果_Responsible成功指向了当前线程，说明当前线程是第一个被阻塞或者等待获取锁的线程。  //则会执行一个简单的退避算法。执行有等待时间的park操作,第一次是1ms  //每次到时间后自己去尝试获取锁，获取失败后继续睡眠，每次睡眠的时间是上一次的8倍。  if (_Responsible == Self || (SyncFlags \u0026amp; 1)) { TEVENT(Inflated enter - park TIMED); Self-\u0026gt;_ParkEvent-\u0026gt;park((jlong) recheckInterval); // Increase the recheckInterval, but clamp the value.  recheckInterval *= 8; if (recheckInterval \u0026gt; MAX_RECHECK_INTERVAL) { recheckInterval = MAX_RECHECK_INTERVAL; } } else { //如果当前线程不是第一个阻塞或者等待锁的线程，则直接park。  TEVENT(Inflated enter - park UNTIMED); Self-\u0026gt;_ParkEvent-\u0026gt;park(); } if (TryLock(Self) \u0026gt; 0) break; // The lock is still contested.  // Keep a tally of the # of futile wakeups.  // Note that the counter is not protected by a lock or updated by atomics.  // That is by design - we trade \u0026#34;lossy\u0026#34; counters which are exposed to  // races during updates for a lower probe effect.  TEVENT(Inflated enter - Futile wakeup); // This PerfData object can be used in parallel with a safepoint.  // See the work around in PerfDataManager::destroy().  OM_PERFDATA_OP(FutileWakeups, inc()); ++nWakeups; // Assuming this is not a spurious wakeup we\u0026#39;ll normally find _succ == Self.  // We can defer clearing _succ until after the spin completes  // TrySpin() must tolerate being called with _succ == Self.  // Try yet another round of adaptive spinning.  if ((Knob_SpinAfterFutile \u0026amp; 1) \u0026amp;\u0026amp; TrySpin(Self) \u0026gt; 0) break; // We can find that we were unpark()ed and redesignated _succ while  // we were spinning. That\u0026#39;s harmless. If we iterate and call park(),  // park() will consume the event and return immediately and we\u0026#39;ll  // just spin again. This pattern can repeat, leaving _succ to simply  // spin on a CPU. Enable Knob_ResetEvent to clear pending unparks().  // Alternately, we can sample fired() here, and if set, forgo spinning  // in the next iteration.  if ((Knob_ResetEvent \u0026amp; 1) \u0026amp;\u0026amp; Self-\u0026gt;_ParkEvent-\u0026gt;fired()) { Self-\u0026gt;_ParkEvent-\u0026gt;reset(); OrderAccess::fence(); } if (_succ == Self) _succ = NULL; // Invariant: after clearing _succ a thread *must* retry _owner before parking.  OrderAccess::fence(); } //执行到这里，说明当前线程成功获取了锁，所以下面要做的事情，就是要将当前线程从当前锁的阻塞队列上去掉，  // Egress :  // Self has acquired the lock -- Unlink Self from the cxq or EntryList.  // Normally we\u0026#39;ll find Self on the EntryList .  // From the perspective of the lock owner (this thread), the  // EntryList is stable and cxq is prepend-only.  // The head of cxq is volatile but the interior is stable.  // In addition, Self.TState is stable.  assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(object() != NULL, \u0026#34;invariant\u0026#34;); // I\u0026#39;d like to write:  // guarantee (((oop)(object()))-\u0026gt;mark() == markOopDesc::encode(this), \u0026#34;invariant\u0026#34;) ;  // but as we\u0026#39;re at a safepoint that\u0026#39;s not safe.  //从队列中去掉当前线程的操作  UnlinkAfterAcquire(Self, \u0026amp;node); if (_succ == Self) _succ = NULL; assert(_succ != Self, \u0026#34;invariant\u0026#34;); //如果_Responsible是当前线程，则将_Responsible设置为NULL  if (_Responsible == Self) { _Responsible = NULL; OrderAccess::fence(); // Dekker pivot-point  } return; }  首先还是尝试获取锁，获取失败后再尝试自旋一下，自旋依旧失败，之后是真正的挂起逻辑。 当时这里进行了2轮自旋，尝试自旋获得锁，我们可以理解，是为了尽可能的在用户态获得锁，那为什么要执行2次呢？\n// We try one round of spinning *before* enqueueing Self. // // If the _owner is ready but OFFPROC we could use a YieldTo() // operation to donate the remainder of this thread\u0026#39;s quantum // to the owner. This has subtle but beneficial affinity // effects.  上面的注释给了我们答案，这么做会有一些微秒的亲和力影响。\n什么是亲和力？这是很多操作系统中都有的一种 CPU 执行调度逻辑，说的是，如果在过去一段时间内，某个线程尝试获取某种资源一直失败，那么系统在后面会倾向于将该资源分配给这个线程。这里我们前后两次执行，就是告诉系统当前线程「迫切」想要获得这个 cas 资源，如果可以用的话尽量分配给它。当然这种亲和力不是一种得到保证的协议，因此这种操作只能是一种积极的、并且人畜无害的操作。\n 执行真正挂起逻辑之前，首先将自己包装成一个ObjectWaiter对象，并通过CAS放在_cxq队列的头部。\n 执行真正挂起逻辑的时候，有一个指针_Responsible，当cxq队列和_EntryList为空，并且_Responsible为空的时候，说明当前线程是第一个等待锁的线程，就通过CAS将_Responsible指向当前线程。 然后，进入到一个无限循环中，只有成功获取了锁，才能退出循环。 _Responsible的作用是什么呢\n// Check for cxq|EntryList edge transition to non-null. This indicates // the onset of contention. While contention persists exiting threads // will use a ST:MEMBAR:LD 1-1 exit protocol. When contention abates exit // operations revert to the faster 1-0 mode. This enter operation may interleave // (race) a concurrent 1-0 exit operation, resulting in stranding, so we // arrange for one of the contending thread to use a timed park() operations // to detect and recover from the race. (Stranding is form of progress failure // where the monitor is unlocked but all the contending threads remain parked). // That is, at least one of the contended threads will periodically poll _owner. // One of the contending threads will become the designated \u0026#34;Responsible\u0026#34; thread. // The Responsible thread uses a timed park instead of a normal indefinite park // operation -- it periodically wakes and checks for and recovers from potential // strandings admitted by 1-0 exit operations. We need at most one Responsible // thread per-monitor at any given moment. Only threads on cxq|EntryList may // be responsible for a monitor. 上面的注释中说到，重量级操作中，是有可能发生搁浅(搁浅是指：Monitor已解锁但所有竞争线程均已park，就是没有线程去尝试获取锁)，为了避免这种情况。需要指定一个线程，定期唤醒去执行执行检查,或者说去尝试获取锁。保证至少有一个线程能够获取锁。\n 如果_Responsible指向的是当前程，就通过一个简单的退避算法进行有条件的挂起，第一次1ms，第二次8ms，每次下一次都是上一次睡眠时间的8倍，但时间自动唤醒自己并尝试获取锁。\n 如果_Responsible指向的不是当前线程，则当前线程会执行park将自己挂起，只有当前得到锁的线程释放锁的时候，才有机会被唤醒并且竞争锁。\n 最后，当获取到锁之后，就会跳出循环，填出循环后需要做一些后续处理，需要把自己从等待队列中移除，\n 如果如果是_Responsible线程获取到了了，那么就需要把_Responsible设置为null，等待其他线程被唤醒的使用重新设置为_Responsible。\n  降到这里其实加锁过程，就差不多完成了，可能会有一些疑惑，为什么 EntryList cxq 这些都没怎么用到呢？ 别急在重量级锁退出的时候，就会用到了，我们机械往下分析。\n自旋锁和适应性自旋 我们看到在重量级代码中，有很多次的出现了自旋的操作，这么做的目的就是，尽量在用户态解决战斗，防止线程无谓地进行状态切换。所以我们能从中知道，尽量避免无效的状态切换对于一个高性能的系统有多么重要。\n但是要想不切换到内核态，就必须要给线程找点事情做，所以就需要线程进行自旋。上面在重量级锁的获取中，看到了很多采用TryLock,来尝试自旋获取锁。这个其实就是我们经常说的自旋锁。\n我觉得准确来说自旋不能算作一种锁，在Java里它只能算是一种获取重量级锁的优化方式。在线程占有锁时间比较短的情况下，能够避免其他等待锁线程切换到内核态进入阻塞状态\n自旋锁在JDK 1.4.2中就已经引入，只不过默认是关闭的，可以使用-XX:+UseSpinning参数来开启，在JDK 1.6中就已经改为默认开启了。 自旋等待不能代替阻塞，因为自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源， 而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。 自旋次数的默认值是10次，用户可以使用参数-XX:PreBlockSpin来更改。\n在JDK 1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。 另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。\n重量级锁释放 上面我们理清了 ObjectMonitor enter 的逻辑，我们知道了如下几件事情：\n ObjectMonitor 内部通过一个 CXQ 队列保存所有的等待线程 在实际进入队列之前，会反复尝试 lock，在某些系统上会存在 CPU 亲和力的优化 入队的时候，通过 ObjectWaiter 对象将当前线程包裹起来，并且入到 CXQ 队列的头部 入队成功以后，会根据当前线程是否为第一个等待线程做不同的处理，如果是第一个这个线程会被设置为_Responsible。 如果是第一个等待线程，会根据一个简单的「退避算法」来有条件的 wait，并定时醒来继续尝试获取 如果不是第一个等待线程，那么会执行无限期等待 如果_Responsible线程获取到重量级锁，会将_Responsible设置为null 线程的 park 在 posix 系统上是通过 pthread 的 condition wait 实现的  当一个线程获得对象锁成功之后，就可以执行自定义的同步代码块了。执行完成之后会执行到 ObjectMonitor 的 exit 函数中，释放当前对象锁，方便下一个线程来获取这个锁，下面我们逐步分析下 exit 的实现过程。\nexit 函数的实现比较长，但是整体上的结构比较清晰：\nvoid ATTR ObjectMonitor::exit(bool not_suspended, TRAPS) { Thread * Self = THREAD ; // 如果_owner不是当前线程  if (THREAD != _owner) { // 当前线程是之前持有轻量级锁的线程。由轻量级锁膨胀后还没调用过enter方法，_owner会是指向Lock Record的指针。  if (THREAD-\u0026gt;is_lock_owned((address) _owner)) { assert (_recursions == 0, \u0026#34;invariant\u0026#34;) ; //在这时把owner修改为指向当前线程，应该是为了方便后面进行处理吧，因为只有这一种情况下是owner指向的不是线程。  _owner = THREAD ; _recursions = 0 ; } else { // 异常情况:当前不是持有锁的线程  TEVENT (Exit - Throw IMSX) ; assert(false, \u0026#34;Non-balanced monitor enter/exit!\u0026#34;); if (false) { THROW(vmSymbols::java_lang_IllegalMonitorStateException()); } return; } } // 重入计数器还不为0，则计数器-1后返回,因为这表明这只是一次重量级锁的重入，只需要吧重入次数减一即可。  if (_recursions != 0) { _recursions--; // this is simple recursive enter  TEVENT (Inflated exit - recursive) ; return ; } // _Responsible设置为null，一直不知道这个SyncFlags是什么东西，也不知道代表什么意思，苦恼  if ((SyncFlags \u0026amp; 4) == 0) { _Responsible = NULL ; } ... for (;;) { assert (THREAD == _owner, \u0026#34;invariant\u0026#34;) ; // Knob_ExitPolicy默认为0  if (Knob_ExitPolicy == 0) { // code 1：先释放锁，这时如果有其他线程进入同步块则能获得锁  OrderAccess::release_store_ptr (\u0026amp;_owner, NULL) ; // drop the lock  OrderAccess::storeload() ; // See if we need to wake a successor  // code 2：如果没有等待的线程(cxq和entryList都为空)或已经有假定继承人_succ不为空  // 那么表示不需要继续唤醒了，返回即可  if ((intptr_t(_EntryList)|intptr_t(_cxq)) == 0 || _succ != NULL) { TEVENT (Inflated exit - simple egress) ; return ; } TEVENT (Inflated exit - complex egress) ; // code 3：要执行之后的操作需要重新获得锁，即设置_owner为当前线程  // 不满足上面的条件，表示需要挑一个线程唤醒，要操作_cxq 和 entryList，需要重新获取重量级锁  // 如果获取失败了，则表示此时重量级锁，已经被其他线程获取了，直接返回就行  // 如果获取成功了则下面需要按照不同的QMode进行处理  if (Atomic::cmpxchg_ptr (THREAD, \u0026amp;_owner, NULL) != NULL) { return ; } TEVENT (Exit - Reacquired) ; }else{ //此处代码忽略掉了  } ... ObjectWaiter * w = NULL ; // code 4：根据QMode的不同会有不同的唤醒策略，默认为0  int QMode = Knob_QMode ; if (QMode == 2 \u0026amp;\u0026amp; _cxq != NULL) { // QMode == 2 : cxq中的线程有更高优先级，直接唤醒cxq的队首线程  w = _cxq ; assert (w != NULL, \u0026#34;invariant\u0026#34;) ; assert (w-\u0026gt;TState == ObjectWaiter::TS_CXQ, \u0026#34;Invariant\u0026#34;) ; ExitEpilog (Self, w) ; return ; } if (QMode == 3 \u0026amp;\u0026amp; _cxq != NULL) { // 将cxq中的元素插入到EntryList的末尾  w = _cxq ; for (;;) { assert (w != NULL, \u0026#34;Invariant\u0026#34;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, \u0026amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , \u0026#34;invariant\u0026#34;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-\u0026gt;_next) { guarantee (p-\u0026gt;TState == ObjectWaiter::TS_CXQ, \u0026#34;Invariant\u0026#34;) ; p-\u0026gt;TState = ObjectWaiter::TS_ENTER ; p-\u0026gt;_prev = q ; q = p ; } // Append the RATs to the EntryList  // TODO: organize EntryList as a CDLL so we can locate the tail in constant-time.  ObjectWaiter * Tail ; for (Tail = _EntryList ; Tail != NULL \u0026amp;\u0026amp; Tail-\u0026gt;_next != NULL ; Tail = Tail-\u0026gt;_next) ; if (Tail == NULL) { _EntryList = w ; } else { Tail-\u0026gt;_next = w ; w-\u0026gt;_prev = Tail ; } // Fall thru into code that tries to wake a successor from EntryList  } if (QMode == 4 \u0026amp;\u0026amp; _cxq != NULL) { // 将cxq插入到EntryList的队首  w = _cxq ; for (;;) { assert (w != NULL, \u0026#34;Invariant\u0026#34;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, \u0026amp;_cxq, w) ; if (u == w) break ; w = u ; } assert (w != NULL , \u0026#34;invariant\u0026#34;) ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-\u0026gt;_next) { guarantee (p-\u0026gt;TState == ObjectWaiter::TS_CXQ, \u0026#34;Invariant\u0026#34;) ; p-\u0026gt;TState = ObjectWaiter::TS_ENTER ; p-\u0026gt;_prev = q ; q = p ; } // Prepend the RATs to the EntryList  if (_EntryList != NULL) { q-\u0026gt;_next = _EntryList ; _EntryList-\u0026gt;_prev = q ; } _EntryList = w ; // Fall thru into code that tries to wake a successor from EntryList  } w = _EntryList ; if (w != NULL) { // 如果EntryList不为空，则直接唤醒EntryList的队首元素  assert (w-\u0026gt;TState == ObjectWaiter::TS_ENTER, \u0026#34;invariant\u0026#34;) ; ExitEpilog (Self, w) ; return ; } // EntryList为null，则处理cxq中的元素  w = _cxq ; if (w == NULL) continue ; // 因为之后要将cxq的元素移动到EntryList，所以这里将cxq字段设置为null  for (;;) { assert (w != NULL, \u0026#34;Invariant\u0026#34;) ; ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr (NULL, \u0026amp;_cxq, w) ; if (u == w) break ; w = u ; } TEVENT (Inflated exit - drain cxq into EntryList) ; assert (w != NULL , \u0026#34;invariant\u0026#34;) ; assert (_EntryList == NULL , \u0026#34;invariant\u0026#34;) ; if (QMode == 1) { // QMode == 1 : 将cxq中的元素转移到EntryList，并反转顺序  ObjectWaiter * s = NULL ; ObjectWaiter * t = w ; ObjectWaiter * u = NULL ; while (t != NULL) { guarantee (t-\u0026gt;TState == ObjectWaiter::TS_CXQ, \u0026#34;invariant\u0026#34;) ; t-\u0026gt;TState = ObjectWaiter::TS_ENTER ; u = t-\u0026gt;_next ; t-\u0026gt;_prev = u ; t-\u0026gt;_next = s ; s = t; t = u ; } _EntryList = s ; assert (s != NULL, \u0026#34;invariant\u0026#34;) ; } else { // QMode == 0 or QMode == 2‘  // 将cxq中的元素转移到EntryList  _EntryList = w ; ObjectWaiter * q = NULL ; ObjectWaiter * p ; for (p = w ; p != NULL ; p = p-\u0026gt;_next) { guarantee (p-\u0026gt;TState == ObjectWaiter::TS_CXQ, \u0026#34;Invariant\u0026#34;) ; p-\u0026gt;TState = ObjectWaiter::TS_ENTER ; p-\u0026gt;_prev = q ; q = p ; } } // _succ不为null，说明已经有个继承人了，所以不需要当前线程去唤醒，减少上下文切换的比率  if (_succ != NULL) continue; w = _EntryList ; // 唤醒EntryList第一个元素  if (w != NULL) { guarantee (w-\u0026gt;TState == ObjectWaiter::TS_ENTER, \u0026#34;invariant\u0026#34;) ; ExitEpilog (Self, w) ; return ; } } } 上面的 exit 函数整体上分为如下几个部分：\n 首先判断owner是否是当前线程，因为只有获得当前锁的线程，才能执行exit。 对重入次数进行减1操作。 接下来是个无限循环，只有成功释放了锁，才会跳出循环。在循环中，主要做的事情是：\n 这里根据不同的退出策略执行了一段不同的逻辑，但是大致做的事情都差不多，这里我们只分析默认为0的情况。\n 首先释放掉当前线程对重量级锁的占用(设置owner为null)，此时如果其他线程来抢占锁，是可以抢占成功的，有点类似ReenrantLock的非公平锁的意思。\n 然后判断了cxq队列和_EntryList是否都是空，或者是已经设置了假定继承人，如果是，就直接返回。因为没有线程需要唤醒，或者等待假定继承人去获得锁即可。\n 如果不满足上面条件，说明需要挑选一个线程来获取锁，那么这里因为需要操作_cxq和_EntryList，所以需要重新CAS获取重量级锁。\n 如果这里CAS获取失败，说明已经有其他线程获取到了锁，则直接返回即可\n  下面就需要根据策略从_cxq和_EntryList中挑选一个线程唤醒了。\n  默认唤醒策略 默认的QMode为0，所以我们就先来分析这个策略的逻辑。 很奇怪，代码中，并没有单独判断QMode=0的这个种情况，所以我们需要把其他的逻辑去掉，剩下的就是QMode=0的逻辑了\nvoid ObjectMonitor::exit(bool not_suspended, TRAPS) { for (;;) { ... ObjectWaiter * w = NULL; int QMode = Knob_QMode; if (QMode == 2 \u0026amp;\u0026amp; _cxq != NULL){ ... } if (QMode == 3 \u0026amp;\u0026amp; _cxq != NULL){ ... } if (QMode == 4 \u0026amp;\u0026amp; _cxq != NULL){ ... } w = _EntryList; //优先从EntryList中唤醒线程  //判断entryList是否为空  if (w != NULL) { //如果不为空，唤醒entryList的头节点  ExitEpilog(Self, w); return; } //先把 cxq赋值给 w，然后清空cxq  w = _cxq; // Drain _cxq into EntryList - bulk transfer.  // First, detach _cxq.  // The following loop is tantamount to: w = swap(\u0026amp;cxq, NULL)  for (;;) { ObjectWaiter * u = (ObjectWaiter *) Atomic::cmpxchg_ptr(NULL, \u0026amp;_cxq, w); if (u == w) break; w = u; } if (QMode == 1) { ... }else { // QMode == 0 or QMode == 2  //将cxq中的元素转移到EntryList  //并将cxq转化为双向类别  _EntryList = w; ObjectWaiter * q = NULL; ObjectWaiter * p; for (p = w; p != NULL; p = p-\u0026gt;_next) { p-\u0026gt;TState = ObjectWaiter::TS_ENTER; p-\u0026gt;_prev = q; q = p; } } //唤醒entryList中的头部节点  w = _EntryList; if (w != NULL) { ExitEpilog(Self, w); return; } } } 总结一下就是\n 在默认情况下,所有等待锁的线程，会先放到_cxq队列中，后来的会放到_cxq的头部。 当之前持有锁的线程，执行完了同步代码，触发了锁退出逻辑。 在默认QMode=0的情况下下，其他模式我们先不分析了，首先会判断EntryList是否不为空，如果不为空，则唤醒EntryList的头节点的线程。 在首次重量级锁退出的时候，EntryList肯定为空，则会继续向下走，会把_cxq中的节点，转移到_EntryList中，并把修改为双向节点。(可以知道，默认模式下，是在锁第一次释放的时候，把所有等待锁的节点移动到EntryList中) 然后唤醒EntryList的头部节点。  根据这个逻辑，表现在Java程序中。有 T1,T2,T3,T4 四个线程按顺序去获得锁，那么最终获得锁的顺序是。 1. T1 2. T4 3. T3 4. T2\nT4是最后进来的线程会放在在cxq队列的头部，在T1释放的时候，会转移到EntryList的头部，然后首先被唤醒。\n我们来验证一下\npackage com.zhou.techstack.thread; import java.util.concurrent.TimeUnit; public class ThreadSyncOrder { public static void main(String[] args) { Object lock = new Object(); Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread 1 start!!!!!!\u0026#34;); synchronized (lock) { System.out.println(\u0026#34;Thread 1 get lock!!!!!!\u0026#34;); sleepSeconds(5); } Thread t5 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread 5 start!!!!!!\u0026#34;); synchronized (lock) { System.out.println(\u0026#34;Thread 5 get lock!!!!!!\u0026#34;); } }); t5.start(); }); Thread t2 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread 2 start!!!!!!\u0026#34;); synchronized (lock) { System.out.println(\u0026#34;Thread 2 get lock!!!!!!\u0026#34;); sleepSeconds(1); } }); Thread t3 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread 3 start!!!!!!\u0026#34;); synchronized (lock) { System.out.println(\u0026#34;Thread 3 get lock!!!!!!\u0026#34;); sleepSeconds(1); } }); Thread t4 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Thread 4 start!!!!!!\u0026#34;); synchronized (lock) { System.out.println(\u0026#34;Thread 4 get lock!!!!!!\u0026#34;); sleepSeconds(1); } }); t1.start(); sleepSeconds(1); t2.start(); sleepSeconds(1); t3.start(); sleepSeconds(1); t4.start(); } private static void sleepSeconds(int seconds) { try { TimeUnit.SECONDS.sleep(seconds); } catch (InterruptedException e) { e.printStackTrace(); } } } 这个代码，我们在上面的逻辑基础上，有添加了一个逻辑，就是T1在释放锁之后，又创建了一个线程T5。 我们看一下执行结果\nThread 1 start!!!!!! Thread 1 get lock!!!!!! Thread 2 start!!!!!! Thread 3 start!!!!!! Thread 4 start!!!!!! Thread 4 get lock!!!!!! Thread 5 start!!!!!! Thread 3 get lock!!!!!! Thread 2 get lock!!!!!! Thread 5 get lock!!!!!!  首先 T1第一个启动，并且获得了锁，这个没有什么问题。 接着T2,T3,T4相继启动，这时候我们根据上面的逻辑可以得知，这几个线程都会加入到_cxq中，并且顺序是 T4-\u0026gt;T3-\u0026gt;T2。 接着T1执行完毕，释放锁，这时候会把_cxq中的节点移动到EntryList中，并且唤醒头节点T4。然后T1紧接着创建T5，并启动，这时候T5，也会被加入到_cxq的头结点，只不过因为在释放的时候，_cxq中的节点已经移动到了EntryList，所以这时_cxq中只有T5一个节点。 接着T4执行完毕，释放锁，这时因为EntryList不为空，所以唤醒此时EntryList的头结点T3 同样T3执行完毕，释放锁，唤醒T2 T2执行完毕后，EntryList又变成空，所以会继续将_cxq中的节点移动到EntryList，然后唤醒头结点T5  其他唤醒策略 这里对于其他策略，我们就暂时不做分析了，但是大致的逻辑都是对_cxq和EntryList进行操作，调整他们的优先级，顺序，包括优先_cxq啊，反转_cxq啊等等。 有兴趣的同学也可以自己查看源码，或者查阅下面的参考文章。\nwait、notify、natifyAll wait 我们知道调用 lock.wait()之后，当前持有锁的线程，就会丢掉锁，并进入阻塞状态，等到调用 lock.notify()的时候才会被唤醒 下面我们来看源码来分析一下wait的实现原理。\nint ObjectSynchronizer::wait(Handle obj, jlong millis, TRAPS) { //如果使用偏向锁，首先撤销偏向。  //因为wait需要将线程放在ObjectMonitor的waitSet队列中，要wait必须要膨胀为重量级锁。  if (UseBiasedLocking) { BiasedLocking::revoke_and_rebias(obj, false, THREAD); assert(!obj-\u0026gt;mark()-\u0026gt;has_bias_pattern(), \u0026#34;biases should be revoked by now\u0026#34;); } if (millis \u0026lt; 0) { TEVENT(wait - throw IAX); THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \u0026#34;timeout value is negative\u0026#34;); } //膨胀为重量级锁，如果已经是重量级锁， inflate方法会直接返回当前的ObjectMonitor  ObjectMonitor* monitor = ObjectSynchronizer::inflate(THREAD, obj()); DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis); //调用ObjectMonitor的wait方法  monitor-\u0026gt;wait(millis, true, THREAD); // This dummy call is in place to get around dtrace bug 6254741. Once  // that\u0026#39;s fixed we can uncomment the following line, remove the call  // and change this function back into a \u0026#34;void\u0026#34; func.  // DTRACE_MONITOR_PROBE(waited, monitor, obj(), THREAD);  return dtrace_waited_probe(monitor, obj, THREAD); } 通过这个方法我们可以知道，如果是在偏向模式和轻量级模式的同步代码中调用了wait()方法，那么也会导致锁升级到重量级模式。\n然后就看ObjectMonitor的wait方法\nvoid ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) { Thread * const Self = THREAD; assert(Self-\u0026gt;is_Java_thread(), \u0026#34;Must be Java thread!\u0026#34;); JavaThread *jt = (JavaThread *)THREAD; DeferredInitialize(); // Throw IMSX or IEX.  CHECK_OWNER(); EventJavaMonitorWait event; // check for a pending interrupt  //检查是否被中断，中断了就就直接抛异常  if (interruptible \u0026amp;\u0026amp; Thread::is_interrupted(Self, true) \u0026amp;\u0026amp; !HAS_PENDING_EXCEPTION) { // post monitor waited event. Note that this is past-tense, we are done waiting.  if (JvmtiExport::should_post_monitor_waited()) { // Note: \u0026#39;false\u0026#39; parameter is passed here because the  // wait was not timed out due to thread interrupt.  JvmtiExport::post_monitor_waited(jt, this, false); // In this short circuit of the monitor wait protocol, the  // current thread never drops ownership of the monitor and  // never gets added to the wait queue so the current thread  // cannot be made the successor. This means that the  // JVMTI_EVENT_MONITOR_WAITED event handler cannot accidentally  // consume an unpark() meant for the ParkEvent associated with  // this ObjectMonitor.  } if (event.should_commit()) { post_monitor_wait_event(\u0026amp;event, 0, millis, false); } TEVENT(Wait - Throw IEX); THROW(vmSymbols::java_lang_InterruptedException()); return; } TEVENT(Wait); assert(Self-\u0026gt;_Stalled == 0, \u0026#34;invariant\u0026#34;); Self-\u0026gt;_Stalled = intptr_t(this); //设置当前线程等到的OObjectMonitor为当前的ObjectMonitor  jt-\u0026gt;set_current_waiting_monitor(this); // create a node to be put into the queue  // Critically, after we reset() the event but prior to park(), we must check  // for a pending interrupt.  //将当前线程封装成ObjectWaiter  ObjectWaiter node(Self); node.TState = ObjectWaiter::TS_WAIT; Self-\u0026gt;_ParkEvent-\u0026gt;reset(); OrderAccess::fence(); // ST into Event; membar ; LD interrupted-flag  // Enter the waiting queue, which is a circular doubly linked list in this case  // but it could be a priority queue or any data structure.  // _WaitSetLock protects the wait queue. Normally the wait queue is accessed only  // by the the owner of the monitor *except* in the case where park()  // returns because of a timeout of interrupt. Contention is exceptionally rare  // so we use a simple spin-lock instead of a heavier-weight blocking lock.  //获取一个SpinLock  Thread::SpinAcquire(\u0026amp;_WaitSetLock, \u0026#34;WaitSet - add\u0026#34;); //将当前线程添加到WaitSet队列的最后面  AddWaiter(\u0026amp;node); //释放SpinLock  Thread::SpinRelease(\u0026amp;_WaitSetLock); if ((SyncFlags \u0026amp; 4) == 0) { _Responsible = NULL; } intptr_t save = _recursions; // record the old recursion count  _waiters++; // increment the number of waiters  _recursions = 0; // set the recursion level to be 1  //释放锁对象  exit(true, Self); // exit the monitor  guarantee(_owner != Self, \u0026#34;invariant\u0026#34;); // The thread is on the WaitSet list - now park() it.  // On MP systems it\u0026#39;s conceivable that a brief spin before we park  // could be profitable.  //  // TODO-FIXME: change the following logic to a loop of the form  // while (!timeout \u0026amp;\u0026amp; !interrupted \u0026amp;\u0026amp; _notified == 0) park()  // 下面进入阻塞状态  // 如果调用的wait()，则使用park进入没有超时时间的阻塞  // 如果调用的wait(time),是使用park(time)进入有超时时间的阻塞  // 进入阻塞之后，有三种会被唤醒的情况  // 1. 阻塞时间到了  // 2. 线程被中断了  // 3. 线程被notify唤醒  int ret = OS_OK; int WasNotified = 0; { // State transition wrappers  OSThread* osthread = Self-\u0026gt;osthread(); OSThreadWaitState osts(osthread, true); { ThreadBlockInVM tbivm(jt); // Thread is in thread_blocked state and oop access is unsafe.  jt-\u0026gt;set_suspend_equivalent(); if (interruptible \u0026amp;\u0026amp; (Thread::is_interrupted(THREAD, false) || HAS_PENDING_EXCEPTION)) { // Intentionally empty  } else if (node._notified == 0) { // 根据入参 millis 判断是否有条件的挂起。这里挂起后，就不会继续往下执行了。  //除非timeout到时了，或者中断，或者notify/notifyAll  if (millis \u0026lt;= 0) { Self-\u0026gt;_ParkEvent-\u0026gt;park(); } else { ret = Self-\u0026gt;_ParkEvent-\u0026gt;park(millis); } } // were we externally suspended while we were waiting?  if (ExitSuspendEquivalent (jt)) { // TODO-FIXME: add -- if succ == Self then succ = null.  jt-\u0026gt;java_suspend_self(); } } // Exit thread safepoint: transition _thread_blocked -\u0026gt; _thread_in_vm  // Node may be on the WaitSet, the EntryList (or cxq), or in transition  // from the WaitSet to the EntryList.  // See if we need to remove Node from the WaitSet.  // We use double-checked locking to avoid grabbing _WaitSetLock  // if the thread is not on the wait queue.  //  // Note that we don\u0026#39;t need a fence before the fetch of TState.  // In the worst case we\u0026#39;ll fetch a old-stale value of TS_WAIT previously  // written by the is thread. (perhaps the fetch might even be satisfied  // by a look-aside into the processor\u0026#39;s own store buffer, although given  // the length of the code path between the prior ST and this load that\u0026#39;s  // highly unlikely). If the following LD fetches a stale TS_WAIT value  // then we\u0026#39;ll acquire the lock and then re-fetch a fresh TState value.  // That is, we fail toward safety.  //执行到这儿，说明park的线程，已经被唤醒了，可能是timeout到时了，或者中断，或者notify/notifyAll  //首先要将其从WaitSet队列中移除。因为要操作waitSet，所以也要先获取锁  if (node.TState == ObjectWaiter::TS_WAIT) { Thread::SpinAcquire(\u0026amp;_WaitSetLock, \u0026#34;WaitSet - unlink\u0026#34;); if (node.TState == ObjectWaiter::TS_WAIT) { DequeueSpecificWaiter(\u0026amp;node); // unlink from WaitSet  assert(node._notified == 0, \u0026#34;invariant\u0026#34;); node.TState = ObjectWaiter::TS_RUN; } Thread::SpinRelease(\u0026amp;_WaitSetLock); } // The thread is now either on off-list (TS_RUN),  // on the EntryList (TS_ENTER), or on the cxq (TS_CXQ).  // The Node\u0026#39;s TState variable is stable from the perspective of this thread.  // No other threads will asynchronously modify TState.  guarantee(node.TState != ObjectWaiter::TS_WAIT, \u0026#34;invariant\u0026#34;); OrderAccess::loadload(); if (_succ == Self) _succ = NULL; //WasNotified用于判断，当前节点是否是通过notify唤醒的  WasNotified = node._notified; // Reentry phase -- reacquire the monitor.  // re-enter contended monitor after object.wait().  // retain OBJECT_WAIT state until re-enter successfully completes  // Thread state is thread_in_vm and oop access is again safe,  // although the raw address of the object may have changed.  // (Don\u0026#39;t cache naked oops over safepoints, of course).  // post monitor waited event. Note that this is past-tense, we are done waiting.  if (JvmtiExport::should_post_monitor_waited()) { JvmtiExport::post_monitor_waited(jt, this, ret == OS_TIMEOUT); if (node._notified != 0 \u0026amp;\u0026amp; _succ == Self) { // In this part of the monitor wait-notify-reenter protocol it  // is possible (and normal) for another thread to do a fastpath  // monitor enter-exit while this thread is still trying to get  // to the reenter portion of the protocol.  //  // The ObjectMonitor was notified and the current thread is  // the successor which also means that an unpark() has already  // been done. The JVMTI_EVENT_MONITOR_WAITED event handler can  // consume the unpark() that was done when the successor was  // set because the same ParkEvent is shared between Java  // monitors and JVM/TI RawMonitors (for now).  //  // We redo the unpark() to ensure forward progress, i.e., we  // don\u0026#39;t want all pending threads hanging (parked) with none  // entering the unlocked monitor.  node._event-\u0026gt;unpark(); } } if (event.should_commit()) { post_monitor_wait_event(\u0026amp;event, node._notifier_tid, millis, ret == OS_TIMEOUT); } OrderAccess::fence(); assert(Self-\u0026gt;_Stalled != 0, \u0026#34;invariant\u0026#34;); Self-\u0026gt;_Stalled = 0; assert(_owner != Self, \u0026#34;invariant\u0026#34;); //要继续执行，必须重新获取锁才可以，这里就是重新获取锁的逻辑。  //是经过了一定的阻塞时间，自己唤醒的，那么需要重新尝试获取锁，通过enter方法。  ObjectWaiter::TStates v = node.TState; if (v == ObjectWaiter::TS_RUN) { enter(Self); } else { guarantee(v == ObjectWaiter::TS_ENTER || v == ObjectWaiter::TS_CXQ, \u0026#34;invariant\u0026#34;); ReenterI(Self, \u0026amp;node); node.wait_reenter_end(this); } // Self has reacquired the lock.  // Lifecycle - the node representing Self must not appear on any queues.  // Node is about to go out-of-scope, but even if it were immortal we wouldn\u0026#39;t  // want residual elements associated with this thread left on any lists.  guarantee(node.TState == ObjectWaiter::TS_RUN, \u0026#34;invariant\u0026#34;); assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(_succ != Self, \u0026#34;invariant\u0026#34;); } // OSThreadWaitState()  //执行到这儿，说明线程被唤醒，并且重新获取了锁。  //设置当前线程wait的Monitor为NULL  jt-\u0026gt;set_current_waiting_monitor(NULL); guarantee(_recursions == 0, \u0026#34;invariant\u0026#34;); _recursions = save; // restore the old recursion count  _waiters--; // decrement the number of waiters  // Verify a few postconditions  assert(_owner == Self, \u0026#34;invariant\u0026#34;); assert(_succ != Self, \u0026#34;invariant\u0026#34;); assert(((oop)(object()))-\u0026gt;mark() == markOopDesc::encode(this), \u0026#34;invariant\u0026#34;); if (SyncFlags \u0026amp; 32) { OrderAccess::fence(); } // check if the notification happened  //是否是notify唤醒的，如果不是，判断如果是中断，需要抛出中断异常  //判断是否是中断唤醒，如果是抛出中断异常  if (!WasNotified) { // no, it could be timeout or Thread.interrupt() or both  // check for interrupt event, otherwise it is timeout  if (interruptible \u0026amp;\u0026amp; Thread::is_interrupted(Self, true) \u0026amp;\u0026amp; !HAS_PENDING_EXCEPTION) { TEVENT(Wait - throw IEX from epilog); THROW(vmSymbols::java_lang_InterruptedException()); } } } wait方法的主要逻辑是\n 将线程封装成ObjectWaiter。 添加到WaitSet队列，WaitSet是一个双向循环队列，将其添加到了队列的末尾。(操作WaitSet的时候，都需要获得一个SpinLock) 调用exit方法释放锁，exit是退出synchronized的逻辑，详细可看synchronized实现原理 将线程挂起，这里挂起根据入参millis进行了有条件的挂起（是否到时间自动唤醒）。挂起之后，线程就不再执行了，必须等待当前线程被唤醒才会继续执行。  线程被唤醒有三种情况： 到时间自动唤醒， 中断唤醒， notify/notifyAll唤醒( 这里准确来说是，notify之后，被移动到了cxq队列，然后在exit的逻辑中获取到了锁，被唤醒)。  唤醒之后从WaitSet中移除。 判断是怎么唤醒的  自己到时间唤醒，调用enter重新尝试获取锁 notify唤醒, 中断唤醒，抛出中断异常。   notify 根据java中关于notify的注释中说，notify会随机挑选一个处于阻塞状态的线程唤醒。那真的是随机吗？ 下面我们根据看源码来分析一下。\nvoid ObjectSynchronizer::notify(Handle obj, TRAPS) { //如果使用偏向，先撤销偏向  if (UseBiasedLocking) { BiasedLocking::revoke_and_rebias(obj, false, THREAD); assert(!obj-\u0026gt;mark()-\u0026gt;has_bias_pattern(), \u0026#34;biases should be revoked by now\u0026#34;); } //判断如果是轻量级锁，直接返回  markOop mark = obj-\u0026gt;mark(); if (mark-\u0026gt;has_locker() \u0026amp;\u0026amp; THREAD-\u0026gt;is_lock_owned((address)mark-\u0026gt;locker())) { return; } //获取重量级锁的ObjectMonitor并执行其notify方法  ObjectSynchronizer::inflate(THREAD, obj())-\u0026gt;notify(THREAD); } 首先和wait一样，在调用notify后，也肯定会升级到重量级锁。\nvoid ObjectMonitor::INotify(Thread * Self) { //获取notify策略，默认为2  const int policy = Knob_MoveNotifyee; Thread::SpinAcquire(\u0026amp;_WaitSetLock, \u0026#34;WaitSet - notify\u0026#34;); //取出 waitSet的头结点  ObjectWaiter * iterator = DequeueWaiter(); if (iterator != NULL) { // Disposition - what might we do with iterator ?  // a. add it directly to the EntryList - either tail (policy == 1)  // or head (policy == 0).  // b. push it onto the front of the _cxq (policy == 2).  // For now we use (b).  if (policy != 4) { iterator-\u0026gt;TState = ObjectWaiter::TS_ENTER; } //设置线程是通过notify唤醒  iterator-\u0026gt;_notified = 1; iterator-\u0026gt;_notifier_tid = Self-\u0026gt;osthread()-\u0026gt;thread_id(); ObjectWaiter * list = _EntryList; //下面根据不同的策略进行唤醒。  if (policy == 0) { // prepend to EntryList  //添加到EntryList队列的队首  if (list == NULL) { iterator-\u0026gt;_next = iterator-\u0026gt;_prev = NULL; _EntryList = iterator; } else { list-\u0026gt;_prev = iterator; iterator-\u0026gt;_next = list; iterator-\u0026gt;_prev = NULL; _EntryList = iterator; } } else if (policy == 1) { // append to EntryList  //添加到EntryList队列的队尾  if (list == NULL) { iterator-\u0026gt;_next = iterator-\u0026gt;_prev = NULL; _EntryList = iterator; } else { // CONSIDER: finding the tail currently requires a linear-time walk of  // the EntryList. We can make tail access constant-time by converting to  // a CDLL instead of using our current DLL.  ObjectWaiter * tail; for (tail = list; tail-\u0026gt;_next != NULL; tail = tail-\u0026gt;_next) /* empty */; assert(tail != NULL \u0026amp;\u0026amp; tail-\u0026gt;_next == NULL, \u0026#34;invariant\u0026#34;); tail-\u0026gt;_next = iterator; iterator-\u0026gt;_prev = tail; iterator-\u0026gt;_next = NULL; } } else if (policy == 2) { // prepend to cxq  //添加到CXQ队列的队首  if (list == NULL) { iterator-\u0026gt;_next = iterator-\u0026gt;_prev = NULL; _EntryList = iterator; } else { iterator-\u0026gt;TState = ObjectWaiter::TS_CXQ; for (;;) { ObjectWaiter * front = _cxq; iterator-\u0026gt;_next = front; if (Atomic::cmpxchg_ptr(iterator, \u0026amp;_cxq, front) == front) { break; } } } } else if (policy == 3) { // append to cxq  //添加CXQ队列的队尾  iterator-\u0026gt;TState = ObjectWaiter::TS_CXQ; for (;;) { ObjectWaiter * tail = _cxq; if (tail == NULL) { iterator-\u0026gt;_next = NULL; if (Atomic::cmpxchg_ptr(iterator, \u0026amp;_cxq, NULL) == NULL) { break; } } else { while (tail-\u0026gt;_next != NULL) tail = tail-\u0026gt;_next; tail-\u0026gt;_next = iterator; iterator-\u0026gt;_prev = tail; iterator-\u0026gt;_next = NULL; break; } } } else { ParkEvent * ev = iterator-\u0026gt;_event; iterator-\u0026gt;TState = ObjectWaiter::TS_RUN; OrderAccess::fence(); ev-\u0026gt;unpark(); } // _WaitSetLock protects the wait queue, not the EntryList. We could  // move the add-to-EntryList operation, above, outside the critical section  // protected by _WaitSetLock. In practice that\u0026#39;s not useful. With the  // exception of wait() timeouts and interrupts the monitor owner  // is the only thread that grabs _WaitSetLock. There\u0026#39;s almost no contention  // on _WaitSetLock so it\u0026#39;s not profitable to reduce the length of the  // critical section.  if (policy \u0026lt; 4) { iterator-\u0026gt;wait_reenter_begin(this); } } Thread::SpinRelease(\u0026amp;_WaitSetLock); } 这里我们看到这个逻辑就比较简单了，就是从waitSet中取出头节点，然后根据策略，放到cxq或者entryList的不同位置。 根据不同的唤醒策略进行不同的操作：\n policy == 0 ： 取出WaitSet的队首元素，添加到EntryList队列的队首。 policy == 1 ： 取出WaitSet的队首元素，添加到EntryList队列的队尾 policy == 2 ： 取出WaitSet的队首元素，添加到CXQ队列的队首(默认策略) policy == 3 ： 取出WaitSet的队首元素，添加CXQ队列的队尾  我们可以看到，notify方法并没有真正的去唤醒阻塞线程，只是把线程从waitSet移动到了cxq的头部，然后等待其他线程释放重量级锁之后，在exit方法中，真正的唤醒。\nnotifyAll void ObjectMonitor::notifyAll(TRAPS) { CHECK_OWNER(); if (_WaitSet == NULL) { TEVENT(Empty-NotifyAll); return; } DTRACE_MONITOR_PROBE(notifyAll, this, object(), THREAD); int tally = 0; while (_WaitSet != NULL) { tally++; INotify(THREAD); } OM_PERFDATA_OP(Notifications, inc(tally)); } 上面看完notify，在看notifyAll就比较简单了。他是循环调用了notify方法，也就是把waitSet中的所有节点都添加到了cxq的头部。\ncxq、entryList、waitSet总结 首先声明一下我们只分析默认策略下的情况。\n 所有获取重量级锁失败的线程，都会首先加入cxq队列，并放到队列的头部 当之前持有锁的线程，执行完同步代码释放锁之后，会优先从entryList队列选择下一个去竞争锁的线程(头结点) 如果entryList队列为空，则会把cxq队列拷贝到entryList中，并清空cxq队列，然后唤醒entryList的头结点 当持有锁的线程，调用了wait方法，当前线程会释放锁，然后把这个线程加入到waitSet的尾部。  当调用notify方法的时候，会取出waitSet的头结点，然后放到cxq的头结点中(就像重新获取了一次) 当阻塞一段时间自动唤醒后，会调用enter方法重新获取锁，这时候如果获取失败，也会放到cxq的头结点中 当被interrupt唤醒，会调用enter方法重新获取锁，这时候如果获取失败，也会放到cxq的头结点中。并且抛出中断异常  我们看到线程wait之后，最终唤醒之后，都会加入到cxq队列。  其他知识点(瞎写的) 安全点 安全点的官方定义是在程序执行期间的所有GC Root已知并且所有堆对象的内容一致的点。 在这个期间，所有的用户线程都会停顿，然后由vm线程来执行一些操作 比如我们已经知道 - 偏向锁的撤销， - 批量重偏向， - 批量撤销 - CMS中的某些步骤\n当然这里只是简单的提一下。\njvm线程如何执行任务 在JVM中，每种需要VMThread执行的操作都被封装成了VM_Operation。然后具体的任务继承VM_Operation,然后把需要执行的逻辑放在doit方法中，比如批量向撤销操作就被封装成了VM_BulkRevokeBias。\n在上面的revoke_and_bias代码中，执行安全点偏向撤销的代码：\nVM_BulkRevokeBias bulk_revoke(\u0026amp;obj, (JavaThread*) THREAD, (heuristics == HR_BULK_REBIAS), attempt_rebias); VMThread::execute(\u0026amp;bulk_revoke); return bulk_revoke.status_code(); 他在doit方法中执行的逻辑是\nvirtual void doit() { _status_code = bulk_revoke_or_rebias_at_safepoint((*_obj)(), _bulk_rebias, _attempt_rebias_of_object, _requesting_thread); clean_up_cached_monitor_info(); } 他的继承关系是 VM_BulkRevokeBias -\u0026gt; VM_RevokeBias -\u0026gt; VM_Operation VMThread在执行的时候，会检查每个操作对象的evaluation_mode,来判断这个操作能不能并发的执行。 evaluation_mode这个方法是是定义在父类VM_Operation，默认是safepoint也就是需要所有线程都进入安全点，也就是需要stw。 子类可以选择重写这个方法。有下面几种选择\nenum Mode { _safepoint, // blocking, safepoint, vm_op C-heap allocated  _no_safepoint,// blocking, no safepoint, vm_op C-Heap allocated  _concurrent, // non-blocking,no safepoint, vm_op C-Heap allocated  _async_safepoint // non-blocking,safepoint, vm_op C-Heap allocated  }; JVM中使用的CAS方法 在JVM代码中，实现CAS是借助于下面这个方法。\ncmpxchg_ptr(intptr_t exchange_value, volatile intptr_t* dest, intptr_t compare_value)  cmpxchg_ptr这个方法的三个参数分别是  第一个 字段变化的值 exchange value 第二个 需要修改的字段地址 address 第三个 比较值， compare value，也就是只有当字段是这个值的时候，才能发生交换。 方法的返回值，如果交换成功，返回compare value   下面借助一个例子来说明这个方法的作用\n//构建一个匿名偏向的对象头 markOop header = (markOop) ((uintptr_t) mark \u0026amp; ((uintptr_t)markOopDesc::biased_lock_mask_in_place |(uintptr_t)markOopDesc::age_mask_in_place |epoch_mask_in_place)); //构建一个偏向当前线程的对象头 markOop new_header = (markOop) ((uintptr_t) header | thread_ident); //执行CAS操作 if (Atomic::cmpxchg_ptr((void*)new_header, lockee-\u0026gt;mark_addr(), header) == header) { //成功 }else{ //失败 }  根据上面的代码，的意思就是，如果锁对象的对象头的值为匿名偏向状态，那么把锁对象的对象头修改为偏向当前线程的对象头  参考文章 [java-并发之基石篇]\n[死磕Synchronized底层实现]\n[从源码分析Synchronized实现原理]\n[Wait与notify/notifyAll源码分析]\n","permalink":"https://balvboy.github.io/blog/synchronized/","summary":"Java对象头 锁升级和对象头关系很密切，所以我先了解一下对象头。 我们先来看一下64位系统下对象头的结构，对象头结构分为两部分Mark Word","title":"Java同步机制(一)-Synchronized"},{"content":" Redis的线程 从接触到Redis开始，就了解到Redis的一个重要特性就是单线程。 带着这个特性，我通过命令top -H -p 2582查看了Redis Server内部开启的线程，发现Redis中并非只有1个线程，而是有4个。 这里面肯定有一主线程是负责Redis的操作的，那剩下的3个线程是负责什么的呢。\n我们在Redis的源码中寻找一下答案\nRedis源码分析 1.main方法 server.supervised = redisIsSupervised(server.supervised_mode); int background = server.daemonize \u0026amp;\u0026amp; !server.supervised; //判断Redis的启动模式 if (background) daemonize(); initServer(); //初始化server服务 if (background || server.pidfile) createPidFile(); redisSetProcTitle(argv[0]); redisAsciiArt(); checkTcpBacklogSettings(); 2.initServer函数 if (server.cluster_enabled) clusterInit(); replicationScriptCacheInit(); scriptingInit(1); slowlogInit(); latencyMonitorInit(); //初始化 background io bioInit(); server.initial_memory_usage = zmalloc_used_memory(); 这里我们主要关注bioInit();方法，bio这里就是background IO的简写\n3.BIO  /* Background I/O service for Redis. * * This file implements operations that we need to perform in the background. * Currently there is only a single operation, that is a background close(2) * system call. This is needed as when the process is the last owner of a * reference to a file closing it means unlinking it, and the deletion of the * file is slow, blocking the server. * * In the future we\u0026#39;ll either continue implementing new things we need or * we\u0026#39;ll switch to libeio. However there are probably long term uses for this * file as we may want to put here Redis specific background tasks (for instance * it is not impossible that we\u0026#39;ll need a non blocking FLUSHDB/FLUSHALL * implementation). 从上面的描述可以看出BIO目前只包括一个操作，就是后台 close内核函数操作，因为这个操作牵扯到很重的文件IO，文件IO会严重阻塞redis-server，所以需要开辟线程来单独处理这些操作。\nvoid bioInit(void) { pthread_attr_t attr; pthread_t thread; size_t stacksize; int j; /* Initialization of state vars and objects */ for (j = 0; j \u0026lt; BIO_NUM_OPS; j++) { pthread_mutex_init(\u0026amp;bio_mutex[j],NULL); pthread_cond_init(\u0026amp;bio_newjob_cond[j],NULL); pthread_cond_init(\u0026amp;bio_step_cond[j],NULL); bio_jobs[j] = listCreate(); bio_pending[j] = 0; } /* Set the stack size as by default it may be small in some system */ pthread_attr_init(\u0026amp;attr); pthread_attr_getstacksize(\u0026amp;attr,\u0026amp;stacksize); if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */ while (stacksize \u0026lt; REDIS_THREAD_STACK_SIZE) stacksize *= 2; pthread_attr_setstacksize(\u0026amp;attr, stacksize); /* Ready to spawn our threads. We use the single argument the thread * function accepts in order to pass the job ID the thread is * responsible of. */ for (j = 0; j \u0026lt; BIO_NUM_OPS; j++) { //循环创建bio线程  void *arg = (void*)(unsigned long) j; if (pthread_create(\u0026amp;thread,\u0026amp;attr,bioProcessBackgroundJobs,arg) != 0) { serverLog(LL_WARNING,\u0026#34;Fatal: Can\u0026#39;t initialize Background Jobs.\u0026#34;); exit(1); } bio_threads[j] = thread; } } 这个函数，从名字就可以看出它的主要功能是完成BIO的初始化操作，在源代码中我们找到了线程开辟操作，这里的思路是线程池，那么问题来了，BIO线程池中到底开辟几个线程呢？\n通过观察第121行，可以看到BIO_NUM_OPS参数影响了BIO线程池的线程量，那么这个数值到底为多少呢，我们稍微跟踪一下就可以获取：\n42 #define BIO_NUM_OPS 3 //bio.h文件 现在可以看出BIO_NUM_OPS默认数值为3，这个数值加上1个主线程，正好是图片中的4个线程。\n4. BIO线程执行的操作 while(1) { listNode *ln; /* The loop always starts with the lock hold. */ if (listLength(bio_jobs[type]) == 0) { pthread_cond_wait(\u0026amp;bio_newjob_cond[type],\u0026amp;bio_mutex[type]); continue; } /* Pop the job from the queue. */ ln = listFirst(bio_jobs[type]); //从任务队列中获取任务  job = ln-\u0026gt;value; /* It is now possible to unlock the background system as we know have * a stand alone job structure to process.*/ pthread_mutex_unlock(\u0026amp;bio_mutex[type]); /* Process the job accordingly to its type. */ if (type == BIO_CLOSE_FILE) { //文件关闭操作  close((long)job-\u0026gt;arg1); } else if (type == BIO_AOF_FSYNC) { //异步文件同步操作  redis_fsync((long)job-\u0026gt;arg1); } else if (type == BIO_LAZY_FREE) { //redis内存懒释放  /* What we free changes depending on what arguments are set: * arg1 -\u0026gt; free the object at pointer. * arg2 \u0026amp; arg3 -\u0026gt; free two dictionaries (a Redis DB). * only arg3 -\u0026gt; free the skiplist. */ if (job-\u0026gt;arg1) lazyfreeFreeObjectFromBioThread(job-\u0026gt;arg1); //懒释放对象  else if (job-\u0026gt;arg2 \u0026amp;\u0026amp; job-\u0026gt;arg3) lazyfreeFreeDatabaseFromBioThread(job-\u0026gt;arg2,job-\u0026gt;arg3);//懒释数据库  else if (job-\u0026gt;arg3) lazyfreeFreeSlotsMapFromBioThread(job-\u0026gt;arg3);//懒释放槽位型Map内存  } else { serverPanic(\u0026#34;Wrong job type in bioProcessBackgroundJobs().\u0026#34;); } zfree(job); 通过最初的现象，我们可以看出Redis-server开辟了四个线程，并通过源代码分析，我们可以看出后三个线程是BIO线程，这三个线程完成的功能是一样的，主要包括：从BIO任务队列中取出任务，文件描述符关闭、磁盘文件同步、内存对象懒释放操作。 其他的任务均由主线程完成。\nRedis单线程的优势 我们看到Redis在处理大多数命令的时候，是通过单线程来处理的这可能给Redis带来下面的优势 1. 使用单线程模型也能并发的处理客户端的请求； 2. 使用单线程模型能带来更好的可维护性，方便开发和调试； 3. Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU；\n单线程也能并发 这里首先要说一下一个老生常谈的问题，并发和并行的区别。 这里用一个例子来说明 \u0026gt; 例如，一个调酒师能够照顾几个顾客，而一次只能准备一种饮料。因此，他可以在没有并行的情况下提供并发。\n所以说并发是，在一个时间段内能够处理多个请求即可，而并行是在同一个时刻能够处理多个请求。\n而Redis就可以理解为，上面的例子中提到的调酒师，Redis通过IO 多路复用技术就能够方便的实现同时照看成百上千个顾客,但是Redis在同一时刻只能处理一个顾客的请求。\n但是因为Redis几乎所有操作都是在内存中完成，所以他的每个操作的耗时都非常短，这里有一个计算机各个硬件执行时间的对比。 我们看到内存的读取访问时间是在纳秒级别，而到了硬盘就到了毫秒级。所以Redis这样的以内存操作为主的服务，能够达到每秒 10W甚至100W的并发都是有可能的(当然这个和很多情况有关，比如key的大小，命令的时间复杂度等等)。 同样在这种主要针对内存操作的情况下，Redis对于CPU的消耗是相对比较小的。所以CPU通常并不会成为Redis的瓶颈。 \u0026gt; It’s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU. \u0026gt; FAQ\n如果说你想更好的让Redis利用CPU，或者说Redis的并发量还不能满足你的要求，Redis给出的官方建议是，使用分片的方式将不同的请求交给不同的 Redis 服务器来处理，而不是在同一个 Redis 服务中引入大量的多线程操作。 \u0026gt; However, to maximize CPU usage you can start multiple instances of Redis in the same box and treat them as different servers. At some point a single box may not be enough anyway, so if you want to use multiple CPUs you can start thinking of some way to shard earlier. \u0026gt; FAQ\n可维护性 可维护性对于一个项目来说非常重要，如果代码难以调试和测试，问题也经常难以复现，这对于任何一个项目来说都会严重地影响项目的可维护性。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，代码的执行过程不再是串行的，多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。\n性能瓶颈 上面也提到了，CPU一般不会成为Redis的瓶颈，Redis 并不是 CPU 密集型的服务，如果不开启 AOF 备份，所有 Redis 的操作都会在内存中完成不会涉及任何的 I/O 操作，这些数据的读写由于只发生在内存中，所以处理速度是非常快的；整个服务的瓶颈在于网络传输带来的延迟和等待客户端的数据传输，也就是网络 I/O，所以使用多线程模型处理全部的外部请求可能不是一个好的方案。\n AOF 是 Redis 的一种持久化机制，它会在每次收到来自客户端的写请求时，将其记录到日志中，每次 Redis 服务器启动时都会重放 AOF 日志构建原始的数据集，保证数据的持久性。\n 多线程虽然会帮助我们更充分地利用 CPU 资源，但是操作系统上线程的切换也不是免费的，线程切换其实会带来额外的开销，其中包括：\n 保存线程 1 的执行上下文； 加载线程 2 的执行上下文；  频繁的对线程的上下文进行切换可能还会导致性能地急剧下降，这可能会导致我们不仅没有提升请求处理的平均速度，反而进行了负优化，所以这也是为什么 Redis 对于使用多线程技术非常谨慎。\n引入多线程  However with Redis 4.0 we started to make Redis more threaded. For now this is limited to deleting objects in the background, and to blocking commands implemented via Redis modules. For the next releases, the plan is to make Redis more and more threaded.\n 从4.0版本开始，Redis加入了一些可以被其他线程异步处理的删除操作。\n删除操作 我们可以在 Redis 在中使用 DEL 命令来删除一个键对应的值，如果待删除的键值对占用了较小的内存空间，那么哪怕是同步地删除这些键值对也不会消耗太多的时间。\n但是对于 Redis 中的一些超大键值对，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，影响 Redis 服务处理请求的 PCT99 和可用性。\n总结 Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；（因为单线程的Redis已经这么快了，而且瓶颈不在CPU，并且开发起来更简单，所以顺理成章的使用了单线程） 而 Redis 引入多线程操作也是出于性能上的考虑(目前只是针对一些大键的删除)，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。\n参考 [Redis-Server 线程模型源码剖析]\n[为什么Redis使用单线程模型]\n[Redis is single-threaded, then how does it do concurrent I/O?]\n[为什么说Redis是单线程的以及Redis为什么这么快！]\n","permalink":"https://balvboy.github.io/blog/redis_single_thread/","summary":"Redis的线程 从接触到Redis开始，就了解到Redis的一个重要特性就是单线程。 带着这个特性，我通过命令top -H -p 2582查看了Redi","title":"Redis为何使用单线程 "},{"content":" 什么是HTTPS HTTPS简单的说就是安全版的HTTP。 因为HTTP协议的数据都是明文进行传输的，所以对于一些敏感信息的传输就很不安全，为了安全传输敏感数据，网景公司设计了SSL（Secure Socket Layer），在HTTP的基础上添加了一个安全传输层，对所有的数据都加密后再进行传输，客户端和服务器端收到加密数据后按照之前约定好的秘钥解密。\nHTTPS是如何保证安全的 HTTPS的安全性是建立在密码学的基础之上的，有很多算法起到了至关重要的作用。\nHTTPS的交互过程 通过上面的描述，我们已经能大概知道HTTPS是使用加密算法在浏览器和服务器之前传递秘钥，然后再使用秘钥完成信息的加解密。所以这个秘钥是如何生成的，还有秘钥是如何在浏览器和服务器之间传递的就成了HTTPS的关键，下面我们来详细的了解一下这个过程。\n1.交互流程  Client Hello 客户端（通常是浏览器）先向服务器发出加密通信的请求,请求大概中包括下面内容  支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数 Random Number-RNc，稍后用于生成\u0026rdquo;对话密钥\u0026rdquo;。 支持的加解密方法，比如对称加密支持AES，秘钥交换算法支持RSA、DH，签名算法支持sha256等。(在更高版本的TLS协议中，交换的是密码学套件，所谓的套件就是一整套的加解密，秘钥交换方案)。 支持的压缩方法。  服务器收到请求,然后响应  确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数Random Number-RNs，稍后用于生成\u0026rdquo;对话密钥\u0026rdquo;。 确认使用的加密方法、秘钥交换算法、签名算法等等。 把服务器证书发送给客户端。 服务器要求验证客户端(浏览器)的证书(可选，大部分的服务器都不会要求)。  客户端收到服务器证书之后，会检查证书的有效性，如果服务器证书并不是经过CA机构认证的，浏览器就会在这个时候给用户提出警告。 客户端收到服务器验证客户端证书的请求，会将自己证书发送给服务器。客户端如果没有证书，则需要发送一个不包含证的证书消息。如果服务器需要客户端身份验证才能继续握手，则可能会使用致命的握手失败警报进行响应。(双向认证一般只存在于银行等一些安全性要求比较高的场景中，像早些时候我们使用的网银，里面存储的就是证书，用来在交易的时候和服务器端进行双向认证，保证安全) 服务器收到客户端证书，校验客户端证书是否有效 客户端把把上面流程中发送的所有消息(除了Client Hello)，使用客户端的私钥进行签名，然后发送给服务器。 服务器也保存着之前客户端发送的消息，然后用客户端发送过来的公钥，进行验签。 客户端生成一个Pre-Master-Secret随机数，然后使用服务器证书中的公钥加密，发送给服务器端。 服务器端收到Pre-Master-Secret的加密数据，因为是使用它的公钥加密的，所以可以使用私钥解密得到Pre-Master-Secret。 这时候客户端和服务端都同时知道了，RNc、RNs、Pre-Master-Secret这三个随机数，然后客户端和服务器端使用相同的PRF算法计算得到一个Master-Secret。然后可以从Master-Secret中再生成作为最终客户端和服务器端消息对称加密的秘钥，和对消息进行认证的MAC秘钥。  参考:TLS协议 TLS RFC\n2.Pre-Master-Secret Pre-Master-Secret前两个字节是TLS的版本号，这是一个比较重要的用来核对握手数据的版本号，因为在Client Hello阶段，客户端会发送一份加密套件列表和当前支持的SSL/TLS的版本号给服务端，而且是使用明文传送的，如果握手的数据包被破解之后，攻击者很有可能串改数据包，选择一个安全性较低的加密套件和版本给服务端，从而对数据进行破解。 所以，服务端需要对密文中解密出来对的Pre-Master-Secret中的版本号跟之前Client Hello阶段的版本号进行对比，如果版本号变低，则说明被篡改，则立即停止发送任何消息。\n参考：pre-master secret \n3.Master-Secret 客户端和服务端在生成Master-Secret的之后，会把Master-Secret作为PRF的参数，继续运算，最终得到下面6个秘钥，分别用于MAC算法和加解密算法。\n   秘钥名称 秘钥作用     client write MAC key 客户端对发送数据进行MAC计算使用的秘钥，服务端使用同样的秘钥确认数据的完整性   server write MAC key 服务端对返回数据进行MAC计算使用的秘钥，客户端使用同一个秘钥验证完整性   client write key 对称加密key，客户端数据加密，服务端解密   server write key 服务端加密，客户端解密   client write IV 初始化向量，运用于分组对称加密   server write IV 初始化向量，运用于分组对称加密    参考: TLS 中的密钥计算\n4.PRF算法 PRF表示（Pseudo-random Function）伪随机函数\nMaster-secret和最终的6个秘钥都是依靠PRF来生成的。\nPRF是利用hash函数来实现，然后依赖递归可以生成无限长度的序列。具体使用哪种hash算吗，在TLS1.2之后需要的密码学套件中指定。\n然后master-secret和6个秘钥只需要PRF生成满足他们所需要的长度即可。\n比如Master-Secret的长度一直都是48位。\n参考: TLS 中的密钥计算\n5.双向认证 其实我们日常访问的绝大多数网站，都是单向认证的(也就是说并没有上面流程中的3、4、5、6步骤)，这里为例展示HTTPS的完整交互流程，所以分析的是双向认证。 服务器可以选择是否要真正客户端的证书。这里以使用NGINX配置HTTPS为例。 如果我们在NGINX的HTTPS相关配置中添加了下面这个配置，就表示需要验证客户端的证书。\nssl_verify_client on; 6.密码学套件 密码学套件是TLS发展了一段时间积累了很多密码学使用的经验之后提出的一整套的解决方案。一个套件中包含了应用于整个握手和传输使用到的所有非对称加密，对称加密和哈希算法，甚至包括证书的类型。\n密码学套件是SSLv3开始提出的概念，从此，零散的密码学选择问题变成了一个整体的密码学套件选择的问题。后续的版本在升级的时候会产生新的安全强度更高的密码学套件，同时抛弃比较弱的密码学套件\n密码套件分为三大部分：密钥交换算法，数据加密算法，消息验证算法。\n下面来分析一个密码学套件的名称，来解释一下它包含的意思\nTLS_DHE_RSA_WITH_AES_256_CBC_SHA226 * WITH前面表示使用的非对称加密算法，WITH后面表示使用的对称加密和完整性校验算法\n TLS:表示TLS协议，如果未来TLS改名，这个名字可能会变，否则会一直是这个名字 DHE_RSA:这里又两个算法，表示第一个是约定密钥交换的算法，第二个是约定证书的验证算法。如果只有一个，表示这两中操作都是用同一个算法。 AES_256_CBC:指的是AES这种对称加密算法的256位算法的CBC模式，AES本身是一类对称加密算法的统称，实际的使用时要指定位数和计算模式，CBC就是一种基于块的计算模式。 SHA:表示用来校验数据完整性生成MAC，使用的算法，在TLS1.2之后也表示PRF算法使用的算法。  除了这种比较好理解的密码学套件，还有见到一些比较奇怪的，比如 ALL:!EXPORT:!LOW:!aNULL:!SSLv2 我来解释一下，上面出现的字段，更为详细的大家可以去查看下面的文章。 * ALL:表示所有除了明文(eNULL)传递意外的密码学套件 * !EXPORT:EXPORT表示有出口限制的密码学算法，前面加上!,就表示排除掉包含这些算法的密码学套件。 * !LOW:表示排除掉标记为密码强度比较低的算法。 * !aNULL:表示排除不提供身份验证算法的套件。 * !SSLv2:表示排除所有SSLv2的套件。\n大家可以使用openssl ciphers xxx命令查看套件表达式，所包含的密码学套件\n参考: 密码学套件 密码学套件表达式\nHTTPS中的算法 除了了解HTTPS的交互流程，HTTPS中使用的算法及算法的作用，也是我们必须要了解的一部分。 下面会按照算法的作用进行分类，并简单的介绍其中比较常见算法的作用，单并不会对算法的原理做过多的说明(主要是我也弄不明白)，会把相关的讲解原理的文章链接提供出来，大家有兴趣的可以自行去了解。\nHTTPS中算法，根据算法的用途可以分为几大类 * 加密算法 - 加密传递的信息，包括对称加密和非对称加密 * 秘钥传递算法 - 在客户端和服务器端传递加密使用的key，当然通过上面的流程我们知道并不是直接传递加密的key * 信息摘要/签名算法 - 对传递的信息摘要，确保信息在传递过程中不会被篡改\n1.加密算法 加密算法基本可以分为两种 对称加密和非对称加密\n对称加密 顾名思义就是加密和解密都是用一个同样的秘钥，它的优点就行加解密的速度很快，缺点就是尤其需要注意秘钥的传输，不能泄露。 包含的算法有 AES DES RC4等，常用的是AES\n非对称加密-RSA 非对称加密有一对秘钥公钥和私钥。使用公钥加密，然后使用私钥解密。公钥可以公开的发送给任何人。使用公钥加密的内容，只有私钥可以解开。安全性比对称加密大大提高。缺点是和对称加密相比速度较慢，加解密耗费的计算资源较多。\n这里我们先只需要了解RSA之所以安全的原因是，大整数的因数分解，是一件非常困难的事情。目前，除了暴力破解，还没有发现别的有效方法。\n所以这个大整数越大，RSA被破解的难度也就越高。\n具体的算法可以了解下面的两篇文章。\nRSA算法原理1 RSA算法原理2\n2.秘钥交换算法 常见的秘钥交换算法有下面几种： * RSA：算法实现简单，诞生于 1977 年，历史悠久，经过了长时间的破解测试，安全性高。缺点就是需要比较大的素数（目前常用的是 2048 位）来保证安全强度，很消耗 CPU 运算资源。RSA 是目前唯一一个既能用于密钥交换又能用于证书签名的算法。\n DH：diffie-hellman 密钥交换算法，诞生时间比较早（1977 年），但是 1999 年才公开。缺点是比较消耗 CPU 性能。\n ECDHE：使用椭圆曲线（ECC）的 DH 算法，优点是能用较小的素数（256 位）实现 RSA 相同的安全等级。缺点是算法实现复杂，用于密钥交换的历史不长，没有经过长时间的安全攻击测试。\n ECDH：不支持 PFS，安全性低，同时无法实现 false start。\n DHE：不支持 ECC。非常消耗 CPU 资源 。\n  因为这些算法都用到了数论的一些知识，我自己也是似懂非懂。但是他们有一个共同点就是都是运用了质数和模运算相关的数学原理和公式，感觉他们之间应该也是有一定的关联和关系。(后悔没有好好学数学呀)\n参考： RSA和DH算法 ECDHE-wiki DH-wiki Nginx SSL 性能优化\n3.摘要/签名算法 HTTPS中常见的有MD5、SHA256、MAC、HMAC等，下面主要说明一下这些算法的区别和联系。\n1. MD5 是一种消息摘要算法(Message-Digest Algorithm),一种被广泛使用的密码散列函数(Hash Function)，针对任意长度的输入，可以产生出一个定长128位（16字节）的散列值。\n2. SHA SHA表示安全哈希算法(Secure Hash Algorithm)，经过了很长时间的发展SHA算法已经发展成了一个拥有众多算法的SHA家族。常见的有SHA0、SHA1、SHA2(包含SHA224、SHA256等)、SHA3。0，1，2，3表示SHA算法大的版本，每个大版本中又根据输出字节长度的不同分为和不同的算法。比如SHA256 使用的是SHA2，输出的是256字节。更详细的大家可以看下面wiki百科中的内容，很详细。\nSHA称作安全哈希算法的原因是，它相比MD5算法，需要更多的计算次数，最终的输出长度也要长，(SHA0和SHA1是160字节。SHA256是256字节)。如果想要破解需要付出比MD5高的多的计算次数。\n经过长时间的发展，MD5和SHA0、SHA1已经被认为不安全，已经不再建议使用。 SHA2是目前被最常使用的算法，目前还没有针对SHA2的有效攻击。 SHA3是2015年才发布的，还没有大规模的取代SHA2。\n参考 SHA算法家族\n3. MAC 和 HMAC 相对于上面的MD5和SHA，这两种算法对于我算是比较陌生的。\nMAC是消息认证码(Message Authentication Code)的简称。它和上面两种算法的区别是MAC的计算需要一个Key(上面HTTPS流程中就生了计算MAC的KEY)。只有知道了KEY才能正确的计算出对应的MAC。\nHMAC的全称是密钥散列消息认证码(Keyed-hash message authentication code)。是指用秘钥并使用Hash散列算法生成认证码的一类算法的总称。\n那么MAC算法和HMAC算法是什么关系呢？\n我觉得可以这么理解。 MAC只是定义了一个概念\u0026mdash;使用一个key，给一段消息生成一个授权码；但是生成这个授权码的算法它并没有定义。所以如果你使用SHA256这种Hash散列算法来生成授权码，那么这种算法就可以被称为HMAC-SHA256。 所以HMAC是MAC的一类实现方式，就像快排是排序算法中的一种实现方式一样。\n参考： MAC-Wiki Difference between MAC and HMAC?\n4. Salted Hash 和 HMAC 加盐Hash和HMAC在某种程度上很相似，但是在使用场景上还是有很大的区别。目前还有没找到解释的比较好的文章，后面再进行补充 * [ ] todo\nHTTPS证书 现在HTTPS基本已经成为了一个网站的标配。想要给一个网站添加对HTTPS的支持，就需要针对这个网站的域名申请证书。\nHTTPS证书类型 这里顺便说明一下目前的HTTPS证书大概分为3类。 * 域名型HTTPS 证书（DVSSL）：信任等级一般，只需验证网站的真实性便可颁发证书保护网站； * 企业型HTTPS 证书（OVSSL）：信任等级强，须要验证企业的身份，审核严格，安全性更高； * 增强型HTTPS 证书（EVSSL）：信任等级最高，一般用于银行证券等金融机构，审核严格，安全性最高，同时可以激活绿色网址栏。\n我们看到越是高等级的证书，审核的严格程度也就越高。并在浏览器中会有一定程度的展示，也会给用户一种更为安全的感觉，当然价格也是更加昂贵。\nHTTPS证书内容和结构  Certificate  Version Number（证书版本） Serial Number(序列号) Signature Algorithm ID（该和客户端使用的签名算法） Issuer Name(证书签发者 DN) Validity period(有效期)  Not Before(生效开始时间) Not After(有效结束时间)  Subject name(证书使用者) Subject Public Key Info(证书)  Public Key Algorithm(公钥算法) Subject Public Key(证书公钥)  Issuer Unique Identifier (optional)(签发者唯一身份信息，可选) Subject Unique Identifier (optional)(使用者唯一身份信息，可选) Extensions (optional)(扩展字段)  \u0026hellip;  Signature(CA机构对证书的签名)   参考 X.509 wiki X.509 数字证书的基本原理及应用 X.509证书的读取与解释\n如何获得HTTPS证书 简单来说获的HTTPS证书有两种方式 * 在有CA认证的机构申请 * 自己生成\n1.通过CA机构申请 申请CA机构认证的证书大致需要以下步骤\n1.1 生成CSR(Certificate Signing Request)文件 主要方式有两种，本地生成和在线生成\n 通过openssl命令本地生成CSR\nopenssl req -new -nodes -sha256 -newkey rsa:2048 -keyout myprivate.key -out mydomain.csr -new 指定生成一个新的CSR， nodes指定私钥文件不被加密, sha256 指定摘要算法， keyout生成私钥, newkey rsa:2048 指定私钥类型和长度， 最终生成CSR文件mydomain.csr。 通过线上网站生成，一般需要填写下面的内容。   线上的工具会把公钥加入到CSR文件中，并同时生成私钥。\n参考:在线CSR申请\n1.2 CA机构对证书签名 接下来就需要按照CA机构的要求，和想要申请的证书类型，提交相关材料。\nCA收到CSR并验证相关材料，并审核通过之后。需要进行的很重要的一个步骤就是:使用CA机构的私钥对提供证书中的内容进行签名，并把签名的结果存放在证书的数字签名部分。\nCA机构签名完，并发送给我们之后，我们就能够把证书部署在我们的服务器中了。\n2.自己生成证书 参考 自己生成HTTPS证书\n大家可以参考上面的文章自己创建一个证书试试。 自己创建的证书同样可以完成上面的步骤。只不过有一点就是，因为自己生成的证书没有得到CA机构的私钥签名，所以当浏览器通过HTTPS握手获得服务器证书的时候，没有办法确定这个证书是否就是来自请求的服务器。 这个时候浏览器就会给出该网站不安全的提示。\n如果客户端不能确认证书是安全，但是却贸然使用，就会有受到中间人攻击的风险。\n中间人攻击 具体的概念大家可以去下面的文章中了解一下，我们这里直接举例说明一下。\n这种中间人攻击的方式，常见于公共的未加密的WIFI。 * A想和B通讯，建立连接，并请求了B的证书。 * C通过提供公共WIFI的方式，监听了A和B的通讯，拦截了B发送给A的证书，并把证书替换成自己的。 * 如果A没有证书检验机制的话，那么A并不能发现证书已经被替换了。 * A还是以为在和B通讯。就会使用已经被替换了的证书中的公钥(也就是C的公钥)进行加密。 * C拦截到消息，使用自己的私钥解密，获得原始的请求数据。然后就能随意篡改，然后使用B的公钥加密，在发送给B，达到了攻击的目的。\n中间人攻击还有另外一种方式，危害性更大。 如果有恶意程序在我们的手机或者浏览器中安装了一个证书，并且诱导我们把这书设置为信任证书。 那么如果有其他恶意程序，在和我们的终端进行HTTPS握手的时候，发送给我们使用上面的证书签名的证书，那么我们的终端将无法识别这个恶意证书。导致中间人攻击的发生。\n要抵御中间人攻击的一个有效方式就是，充分利用证书的认证机制，还有对于证书的安装和信任要各位谨慎。\n参考：中间人攻击-Wiki\n证书认证链 上面的HTTPS流程中提到，客户端收到服务端证书之后，会进行验证。HTTPS证书的认证是链状的，每一个证书都需要它上级的证书来验证是否有效。\n链式结构 目前我们常见的证书链中一般分为3级。不过中间证书这部分，也有可能又分为多级。但是也是保持这样的链式结构。\n 根证书(Root CA)  中介(中间)证书(Intermediates)  终端实体证书(End-user)    终端证书的签发者是中间证书。 中间证书的签发者是上级中间或者根证书。 根证书的签发者是他自己。\nHTTPS的证书链，是一个自顶向下的信任链，每一个证书都需要它的上级证书来验证有效。所以根证书的作用就尤为重要，如果系统根证书被篡改，系统的安全性就受到威胁。\n根证书一般是通过系统，或者浏览器内置到我们的电脑的中的。系统更新或者浏览器更新的时候，也有可能会添加新的根证书。\n所以不要轻易的信任根证书，除非你是开发者，了解自己的所作所为。\n参考: 数字证书\n验证证书 我们以wiki百科的证书链来举例 当我们和wiki的服务器建立HTTPS连接的时候，会获得wiki的(End-User)证书(后面简称为WK证书)。\n服务器获得WK证书后，会用下面的几个方式来验证证书。\n1.证书有效性时间验证 CA在颁发证书时，都为每个证书设定了有效期，包括开始时间与结束时间。系统当前时间不在证书起止时间的话，都认为证书是无效的。\n2.证书完整性验证 上面证书链的时候说到每个证书需要他的上级证书来确保证书的有效性。这个确保的方式就是数字签名。\n所以我们只需要，使用CA证书中的公钥和对应的签名算法来验证一下签名，就能够确认证书的有效性。\n那么现在有一个问题就是，如何获取WK证书的上一级证书呢？ 这里两种可能 1. 这个证书已经存在于你的电脑中了，直接使用就可以 2. 你的电脑中还没有这个证书，需要下载(这里有个疑问就是，根据什么区下载这个证书，很有可能是签发者的DN，但是查了很多资料，并没有找到证据)\n拿到CA证书之后，就能够使用CA证书中的公钥对WK证书验签了。\n一样的道理，CA证书的有效性需要CA的上级证书，也就是Root证书来证明。验证的过程是基本一致的。\n参考: HTTPS 精读之 TLS 证书校验 证书有效性验证、根证书\n3.IP/域名验证 在申请域名的时候，都会指定证书所针对的域名。所以这里就是验证，当前请求的域名，是否在这个证书所包含的域名列表中。\n证书里面的域名范围通常使用通配符来表示。 但是以*.example.com的二级域名范围就不能包含a.b.example.com这个三级域名。\n4.证书吊销验证 浏览器获取到服务器证书后，需要判断该证书是不是已经被CA机构吊销。如果已经吊销需要浏览器给出提示。\n这里只大概说一下证书的吊销校验主要分2种 1. 通过CRL(Certificate Revocation List) 证书吊销列表 需要定时的去更新CA机构提供的CRL文件，这个里面记录了改CA机构下所有被吊销的证书。CRL目前正在被OCSP取代，因为CRL不及时，并且每个CRL文件，比较大，影响用户体验。 2. 通过OCSP(Online Certificate Status Protocol) 在线证书状态协议 这是一个实时的通过证书的序列号去查询证书状态的协议，但是这个有一个问题是，因为每次建立HTTPS链接都需要请求这个接口，所以如果这个接口响应慢的话，十分影响用户的体验。所以需要浏览器这边有一个策略，就是如果在一定时间内OCSP没有响应，那怎么处理。 如果强依赖OCSP的话，会容易引起OCSP的单点故障。\n详细的胡啊 参考： 你不在意的证书吊销机制 PKI体系中的证书吊销\n总结 HTTPS的相关总结就先到这里，不知道有没有解决大家的疑问。如果有疑问或者问题，欢迎大家在评论区继续沟通。\n参考 HTTPS 基本过程\nTLS 协议\n数字证书\n你不在意的证书吊销机制\nPKI体系中的证书吊销\nHTTPS 精读之 TLS 证书校验\n证书有效性验证、根证书\n数字证书\n中间人攻击-Wiki\n自己生成HTTPS证书\n在线CSR申请\nX.509 wiki\nX.509 数字证书的基本原理及应用\nX.509证书的读取与解释\nMAC-Wiki\nDifference between MAC and HMAC?\nSHA算法家族\nRSA和DH算法\nECDHE-wiki\nDH-wiki\nRSA算法原理1\nRSA算法原理2\n密码学套件\n密码学套件表达式\nTLS 中的密钥计算\npre-master secret \nTLS协议\nTLS RFC\nNginx SSL 性能优化\n","permalink":"https://balvboy.github.io/blog/http/","summary":"什么是HTTPS HTTPS简单的说就是安全版的HTTP。 因为HTTP协议的数据都是明文进行传输的，所以对于一些敏感信息的传输就很不安全，为了","title":"HTTPS详解 "},{"content":" 字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会把字符编码放到一边，很少有机会或者会想到去专门系统的了解一下字符编码知识。\n我之前也写过一些编码的文章，但是回过头在去看的时候，发现这也不对，那也不对，主要就是因为当时了解的比较片面。这次希望能够把常见的几种编码，和在编程中常见的编码问题搞清楚。\n字符编码和字符集  字符集 字符集的意思就是所有字符的集合，并且每一个字符都有一个唯一的编号。 字符编码 字符编码就是把字符集内字符的编号转换成二进制数据的一种规则。  所以说字符集和字符编码并不是一个东西，字符编码需要依赖于字符集。但是大多数字符编码的名称就是它对应字符集的名称，比如 - ASCII字符集和ASCII字符编码 - GBK字符集和GBK字符编码\n但是有一个例外就是基于Unicode字符集的UTF系列的字符编码，这个我们后面会重点说。 下面简单介绍几个我们比较熟悉的字符集，不会详细讨论设计细节，如果大家有需要可以去查看字符集的维基百科。后面后给出链接。\nASCII ASCII可以认为是最早的字符集，它定义了128个字符，其中包括32个不可见字符(比如一些控制字符 换行，回车等)，还有96个可见字符(大写小写字母，标点符号等)。 ASCII的字符编码也比较简单，就是用二进制来表示字符的序号，因为它一共只有128个，所以只需要用到一个字节的后7位。\nASCII维基百科\nISO 8859-1 ISO 8859-1 这个也是我们很熟悉的字符集，这个字符集是以ASCII为基础，并扩充了一些拉丁字母，也被叫做Latin-1字符集。 因为拉丁国家众多，有很多国家都对这个字符集进行了修改或者扩充。 虽然有这么多的字符集，但是他们有一个共同点，他们都是采用的单字节的编码方式。\nISO-8859-1维基百科\nGBK GBK的全称是汉字内码扩展规范。 其中 - GB是国标的首字母 - K 是扩展的首字母\nGBK的其他信息，我们不做太多说明，有兴趣的可以去维基百科查看\nGBK维基百科\nGBK的编码方式 GBK分为单字节和双字节编码，单字节编码兼容ASCII字符集。 这张图片是GBK的编码分区图。 - 首字节 0-128(不包括128)，都是单字节的编码区域 - 首字节 128-255，第二字节 0-64，这部分区域没有字符，如果出现在这个区域，会被解析为� - 首字节 128-255，第二字节 64-255，这部分主要是中文符号。\n根据上面的编码分区图，我们可以知道GBK是如何区分一个字节是是单字节编码，还是双字节编码的第一个字节，这个很重要，在下面乱码的解析中，我们会分析。 - 如果小于128，则表示是单字节编码 - 如果大于128，则表示是双字节编码\nUnicode 因为世界上的国家有很多，使用的语言和文字也大相径庭，每个国家都有自己使用的字符集和编码，所以有必要使用一个统一的字符集来解决字符集分裂的问题。Unicode就是为了解决这个问题而诞生的。\nUnicode中，是为每种语言都分配了一个区域，并且可以说是涵盖了世界上的所有的字符。  比如Unicode中的前128个字符和ASCII中的字符位置保持一致。 比如中文在Unicode的位置是 4E00-9FFF (19968-40959)  Unicode字符列表\nUnicode和UCS UCS是Universal Multiple-Octet Coded Character Set的简称\nUnicode和UCS的关系可以这么理解。 - 在历史中，有两个机构想要统一世界上的所有字符 - 国际标准化组织(ISO),设计出来的字符集就是UCS - 统一码联盟，设计出来的是Unicode - 后来，他们认识到，世界不需要两个不兼容的字符集，所以开始对这两个字符集进行合并。 - 从Unicode 2.0开始，Unicode采用了与UCS相同的字库和字码使两个字符集互相兼容。 - 但是各自依然保持独立。\nUCS维基百科 Unicode维基百科\nUTF字符编码 需要明白的是，Unicode只是一个符号集，它只规定了符号的序号。字符集中的符号序号涵盖了1个字节，2个字节，3个字节，4个字节。 - 比如汉字的序号范围是 4E00到9FFF，在两字节的范围内。\n那这里就有两个问题， - 第一个问题是，如何有3个字节计算机怎么知道这3个字节是表示一个符号，还是表示3个单字节符号呢？ - 第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用3个或4个字节表示，那么每个英文字母前都必然有2到3个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。\n为了解决这两个问题，就出现了基于Unicode字符集的字符编码，UTF(Unicode/UCS Transformation Format)。 UTF编码又可以分为 - UTF-8 - 最小可以用一个字节来表示字符，以单字节（8位）为单位对Unicode进行编码 - UTF-16 - 最小需要用2个字节来表示，以2个字节（16位）为单位对Unicode进行编码 - UTF-32 - 最小需要4个字节来表示。以4个字节（32位）为单位对Unicode进行编码\nUTF-8是使用最多的编码方式，下面我们会详细分析一下。 UTF-16和UTF-32我们使用较少，所以就不做分析了，有兴趣的同学可以自行了解一下。\n冷知识：Java的String中保存字符的value字段，使用的是UTF-16编码来存储的 Unicode转换格式维基百科 UTF-8维基百科 UTF-16维基百科 UTF-32维基百科\nUTF-8 UTF-8可以说是目前互联网中最常用的字符编码方式了。 截止到2019年11月， 在所有网页中，UTF-8编码应用率高达94.3%（其中一些仅是ASCII编码，因为它是UTF-8的子集），而在排名最高的1000个网页中占96％。\nUTF-8编码规则  若果Unicode值小于128，则字节的第一位为0，后面的7位为这个符号的Unicode码。比如字母 “A” 的Unicode值是 65。这个规则只试用于 ASCII中定义的字符。所以也解决了上面中的因为字符空间占用问题。使用UTF-8表示英文字符同样只需要1个字节。 对于Unicode值大于128的字符（所有的非ASCII中定于的字符）。假定表示该自己在Unicode中的值，需要n(n\u0026gt;=1)个字节，则使用UTF-8编码是，第一个字节的前n+1位都设置为1，第n+2位设置为0，后面字节的前2位都设置为10。剩下没有设置的二进制位，全部为这个符号的Unicode值。 所以UTF-8表示ASCII字符 需要一个字节。 表示其他的非ASCII 字符，主要用改字符在Unicode中的位置转成2进制所占用的字节数+1个 字节。 也就是说，如果这个字符在Unicde中的位置，需要1个字节来表示，那么UTF-8需要2个字节来表示这个字符，以此类推。  总结一下规则就是； 所以这里总结一个UTF-8的规则就是，用第一个字节的前N位 有几个连续的1来表示，这个字符占了几个字节，然后后面紧连着几个字节如果以10开头则表示，这个字节适合第一个字节一起表示一个字符\n 如果一个字节是0开头，则表示是一个单字节字符 如果是11开头，则表示是一个双字节字符 如果是111开头，则表示是一个3字节字符，  比如汉字中它的UTF-8编码是 1110 0100，10 111000，10 101101  如果是1111开头，则表示是一个4字节字符  UTF-8能够被广为使用的一个原因就是它兼容ASCII。 ASCII是UTF-8的一个子集。因为一个纯ASCII字符串也是一个合法的UTF-8字符串，所以现存的ASCII文本不需要转换。为传统的扩展ASCII字符集设计的软件通常可以不经修改或很少修改就能与UTF-8一起使用。 因为在Unicode出现之前，ASCII就是使用最广的语言。\nUTF-8编码转换分析 我们还以汉字中为例,它的UTF-8编码是 11100100，10111000，10101101,我们下面来分析一下，如何计算出来的这个结果\n 我们先去网上查一下“中”对应的Unicode码：\\u4e2d 对应的10进制 是 20013，也就是表示中是Unicode中的第20013个字符。 对应的二进制是 ：100111000101101（15位）为了方便转在前面加一个0，转为16位 01001110，00101101。 表示“中”在Unicode中的值，需要2个字节，所以参照上面规则，UTF-8表示这个“中”需要2+1 = 3 个字节 按照上面的规则 n =2 ,所以第一个字节的前2+1位设置为1 ，第4位设置为0，后面2个字节的前两位 都设置为 10 得到1110  ****  , 10  ******  , 10  ******  剩下的位置填写 中的Unicode码的二进制 。剩下的位置共 4+6+6 = 16位，中的Unicode码的二进制也为16位，填入剩余的位置即可。 得到 1110 0100，10 111000，10 101101 。  代码中的乱码问题 乱码的出现 下面我们来聊一聊代码中经常遇到的乱码问题。 先说结论，乱码就是对字符编码(字符转成二进制)和解码(二进制转成字符)使用的编码不同。\n举例说明一下： 计算机A 给 计算机B发送消息,内容为 \u0026ldquo;中国\u0026rdquo;。 - 计算机A中使用的编码是UTF-8,中国这两个字对应的UTF-8编码是E4B8AD E59BBD,对应的二进制是111001001011100010101101111001011001101110111101 - 计算机B，使用的编码是GBK,它收到网络中的数据，按照GBK的编码方式去解码。 - 然后结果必然是和期望的结果不同,解码的结果是涓浗;\n上面的过程，我们可以用一段代码来表示 @Test public void testConvert(){ String str = \u0026#34;中国\u0026#34;; byte[] utfBytes =str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); String gbkStr = new String(utfBytes,Charset.forName(\u0026#34;GBK\u0026#34;)); System.out.println(gbkStr); } 下面我们来分析一下这个乱码是如何产生的。 - 计算机B收到的二进制数据是 11100100 10111000 10101101 11100101 10011011 10111101 - B是使用GBK编码进行解码，所以我们按照上面的解码规则来解析 - 首先看第一个字节，大于128，所以是一个双字节编码，则读取前两个字节11100100 10111000 - 转换为16进制是E4B8，在GBK中对应的符号是涓 - 然后看第3个字节，同样大于128，所以也是双字节，然后读取第3和第4的字节10101101 11100101 - 转换为16进制是ADE5,查询GBK码表，显示这个位置并没有字符，所以显示为，但是其实这里是有一个特殊的填充字符的。和找不到字符的情况还是有区别的。下面我们会分析。 - - 然后查询第5个字节，同样大于128，所以也是双字节，然后读取第5和第6的字节`10011011 10111101` - 转换为16进制是9BBD,查询GBK码表，对应的字符时`浗`。 从乱码变回正常字符 通过上面的分析，我们知道我们接受到的字节数据是没有问题的，只要我们使用正确的编码对字节进行解码，就可以了。 \u0026gt; 但是一般在开发过程中，框架都帮我们完成了解码的工作，比如Tomcat。就是说我们获得就已经是乱码了。\n所以说，如果我们能通过乱码，按照相同的编码方式来编码，就能拿到原始的字节数据，然后在使用正确的解码方式来解码，就能够得到正确的数据。\n我们同样用程序来模拟一下上面的过程。（代码中使用的是Hutool的HexUtil工具类）\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;中国\u0026#34;; byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 一般情况下，我们使用获得乱码的编码方式，再对乱码进行编码，就能获得原始的字节数据。然后在使用正确的编码方式来解码，就能获得正确的字符。\n例外情况 但是也有一种例外情况，如果你变成了乱码，然后在重新编码回来，是无法获得原始的字节数据的，也就没有办法再变成正确的字符了。\n下面还是举例来说明一下\n@Test public void testFixLuanma() throws UnsupportedEncodingException { //1.获得乱码的数据，因为有些字符(比如)没有办法在编辑器中显示出来，所以使用方法来代替  String gbkString = getGbkString(); System.out.println(\u0026#34;乱码字符:\u0026#34; + gbkString); //2.通过乱码获得原始的字节数据。  byte[] gbksBytes = gbkString.getBytes(\u0026#34;GBK\u0026#34;); System.out.println(\u0026#34;gbk编码字节\u0026#34;+HexUtil.encodeHexStr(gbksBytes)); //3. 通过正确的编码方式来解码  String utfString = new String(gbksBytes, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;正常的字符:\u0026#34; + utfString); } public String getGbkString() { String str = \u0026#34;干\u0026#34;; System.out.println(\u0026#34;原字符:\u0026#34; + str); byte[] utfBytes = str.getBytes(Charset.forName(\u0026#34;UTF-8\u0026#34;)); System.out.println(\u0026#34;utf8编码字节:\u0026#34;+HexUtil.encodeHexStr(utfBytes)); String gbkStr = new String(utfBytes, Charset.forName(\u0026#34;GBK\u0026#34;)); return gbkStr; } 我们发现，和上面一样的代码，对于不同的原字符，就出现了截然不同的结果。\n我们来分析一下原因。\n 首先我们使用UTF-8对原字符干编码，得到的结果是e5b9b2,转为二进制是11100101 10111001 10110010 使用GBK编码，对这段数据进行解码  首先读取第一个字节，大于128，认定是一个双字节字符，所以读取前两个字节11100101 10111001，对应的16进制是e5b9。 查询GBK码表，对应的字符是骞。 然后读取第三个字节，大于128，认定是一个双字节字符，但是这个只有一个字节，所以是有问题的，就被解析成�。  然后使用GBK编码对乱码重新编码，得到的字节数据是e5b93f 我们看到�,这个字符被编码成了3f。 使用UTF8编码对e5b93f解码，得到�?。  所以说，这里失败的原因是，当转换成GBK编码的时候，因为字节数为3个，所以最后1个字节被认为是错误的编码，被转成了通用错误字符�,导致再转成UTF-8的时候，无法还原成原始的字节数据。\n总结一下  GBK编码图中有一部分非法编码区，落在这个编码区的字符，或者不符合GBK编码规则的字符(比如大于128，但是只有一个字节)，会被解析成�。那么就会造成数据丢失，就无法转换成正确的数据了。 如果原始字节数据，是偶数字节，那么有很大可能都能被GBK正确解码，那么还是能够通过GBK编码获得原始数据的，那就能够重新获得正确的字符 有一种比较常见的情况是，发送方使用UTF-8格式的编码，接收方默认使用ISO-8859-1(Tomcat在不指定解码的时候，默认就是)。因为ISO-8859-1是单字节编码，所以虽然会是转换成乱码，但是每个字节都会有对应的字符，所以当再次使用ISO-8859-1编码，就不回发生数据丢失的情况，会原原本本的得到原始的字节数据，在按照UTF-8解码就可以了。 所以说如果一段字节数据，在使用某种编码解码A时，出现了不在该编码类型A的编码区中的数据。那么再次使用编码类型A编码时，就会出现数据丢失，导致无法还原会正确的字符。  GBK偶数字节乱码修复测试  我们看到原始字符是干哈哈哈，4个字符，使用UTF-8编码16进制是e5b9b2e59388e59388e59388，一共12字节。 使用GBK解码，正好2个自己对应一个字符，得到6个字符。 虽然文字看起来像乱码。 但是每个字节都有用到，没有发生数据丢失，这样我们再次使用gbk编码之后，就能重新得到e5b9b2e59388e59388e59388，原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈哈了。  ISO-8859-1乱码修复测试  这次测试的原始字符换成了干哈哈，UTF-8编码后16进制是e5b9b2e59388e59388 9个字节。 使用ISO-8859-1解码，得到了乱码，我们选中得到的字符，看到其实是9个字符 所以每个每个字节都对应了1个字符，没有数据丢失。 再使用ISO-8859-1对乱码编码，就重新得到了e5b9b2e59388e59388原始字节数据。 然后再次使用UTF-8解码就得到原始字符干哈哈了。  ","permalink":"https://balvboy.github.io/blog/encoding/","summary":"字符编码 字符编码是我们在开发过程中无法逃避的问题，经常遇到各种各样的乱码。通常我们会在几个地方设置一下字符编码方式，然后乱码解决了，然后就会","title":"字符集和字符编码 "},{"content":"一、cron介绍  crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。 通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\n 我理解cron是一个表达式，用来表示一个任务的周期性执行时间。\n二、cron格式 2.1、完整格式 ┌─秒(0-59) | ┌─分鐘(0-59) | │ ┌─小時(0-23) | | │ ┌─日 day of month(1-31) | | | | ┌─月(1-12) | | | | | ┌─星期 day of week(0-7，0和7都表示星期日) | | | | | | ┌─年(可以省略不写) * * * * * * * 开始的时候我把cron的格式分为了两种，分别是Linux crontab中的格式和Java中使用的格式。后面想了想，觉得cron的格式应该只有一种，就是上面的这种包含 7个字段的格式。然后不同的cron实现对于cron格式的实现程度不同。\n比如Linux的crontab，它只能支持5个字段，不能支持秒和年\n2.2、crontab格式 ┌─分鐘（0 - 59） │ ┌─小時（0 - 23） | │ ┌─日 day of month(1-31) | | | ┌─月（1 - 12） | | | | ┌─星期 day of week(0-7，0和7都表示星期日) * * * * * linux-crontab-校验\n2.3、cron格式总结 因为在网上一直没有找到准确的官方的cron的定义，所以上面的都是我自己的理解。我认为cron这种很通用的表达式，它的定义应该不会太分裂\n三、day of week中数字的定义 在查看文档和测试的过程中发现，同样的一个表达式，会得出不同的执行结果，后来发现是因为对于day-of-week的定义大致分为两种\n3.1、crontab中的定义 在类Unix的系统中的crontab命令中，数字0和7都代表周日,然后1-6分别表示MON-SAT(周一到周六)；\n这里0和7都表示周日，是有一定的历史原因的，是为了兼容之前不同版本的Unix系统。\n This is a matter of portability. In early Unices, some versions of cron accepted 0 as Sunday, and some accepted 7 as Sunday \u0026ndash; this format is an attempt to be portable with both.\n Day of week {0-7} in crontab has 8 options, but we have only 7 days in a week\n3.2、Java中的定义 在Java的不同实现中,我找到了2个，分别是Spring的实现和Quartz的实现\n Spring的CronSequenceGenerator和Linux保持一致；顺便说一下这个类是Spring中@Scheduled注解的默认cron解析类\n Quartz的CronExpression的实现CronExpression和Linux不同，它不支持0，然后1-7分别是SUN-SAT(周日-周六)\n  3.3、解决办法 鉴于不同的实现中，对于day of week数字的定义的区别，最好的办法就是使用星期的简写来代替数字，例如SUN,MON,TUE等等，这样就能保证你的cron不管在哪个Java的cron实现中都能正确运行。\n四、cron每个字段支持的输入 | Field Name | Allowed Values | Allowed Special Characters| |\u0026ndash;|\u0026ndash;|\u0026ndash;| |Seconds | 0-59 | , - * /| |Minutes | 0-59 | , - * /| |Hours | 0-23 | , - * / | |Day-of-month | 1-31 | , - * ? / L W| |Month | 1-12 or JAN-DEC | , - * /| |Day-of-Week | 0-7 or SUN,MON,TUE,WED,THU,FRI,SAT| , - * ? / L #| |Year (Optional)| empty, 1970-2199|, - * /|\n五、cron特殊字符说明 这里先说一下我的理解，对于cron中的特殊字符，应该是有一套比较统一的规则定义，只不过在在不同的cron的实现里，有的只选择实现了一部分的规则。\n就像Linux中的crontab命令，只实现了下面的几种基本特殊字符。\nJava的实现中，Quartz算是实现的功能比较全的，基本上完全实现了所有的特殊字符的功能。\n所以在我们写cron表达式的时候，一定要清楚，我们的表示是会用在什么地方，支持什么样的写法，像我工作中比较常用的就是在Spring中@Scheduled注解，和elastic-job创建定时任务（cron解析使用Quartz）\n5.1、基本特殊字符    字符 描述 举例 解释     , 表示几个会生效的值 1,2,3 in Minutes 表示在第1和第2和第3分钟 都会生效   - 表示生效的范围 1-10 in Minutes 表示在第1到第10分钟会生效   * 表示所有的值都会生效， * in Minutes 表示每分钟都会生效   / 表示增量，可以理解为每隔多长时间 0/30 in Minutes 表示第0分钟生效，然后每隔30分钟生效一次    5.2、? 字符说明  The \u0026lsquo;?\u0026rsquo; character is allowed for the day-of-month and day-of-week fields. It is used to specify \u0026lsquo;no specific value\u0026rsquo;. This is useful when you need to specify something in one of the two fields, but not the other.\n?号只能用在day-of-month和day-of-week字段中。通常用来表示为\u0026rsquo;没有指定的值\u0026rsquo;。当你需要在两个字段之一中指定某些内容而不是另一个字段时，这非常有用。\n 我们使用cron的初衷是想让这个任务定期的执行，比如每个月1日执行什么，或者每周1执行什么。当一个任务在每个月1日，执行的时候，我们通常不会要求它是星期几，同样每周1执行的任务，我们也不会关心当天是几月几号。也就是说，在极大多数的情况下，我们不需要这两个字段同时满足。\n所以说，通常情况下，我们在指定了这两个其中一个字段之后，会把另一个字段设置为'?'。\n或许有人说，我就要每个月1号、并且还必须得是星期一的0点0分0秒，它才能执行，当然我们也能实现(这种同时制定month和week的表达式，不是所有的都支持,比如Quartz就不支持week和month同时设置)\n0 0 0 1 * 1 接下来7次的执行时间 -------------------------- 2020-06-01 00:00:00 2021-02-01 00:00:00 2021-03-01 00:00:00 2021-11-01 00:00:00 2022-08-01 00:00:00 2023-05-01 00:00:00 2024-01-01 00:00:00 spring-cron-online\n那这个时间真的是你想要的吗？\n5.3、L 字符说明 L其实是LAST的简写，就是最后的意思，它可以用在 day-of-month和day-of-week字段中。 它在两个字段中的意思有一些不同\n day-of-month：直接使用L表示这个月的最后一天，如果是1月那就是31号，如果是平年的2月，那就是28号 day-of-month: 使用 L-3,表示这个月的倒数第3天 day-of-week：如果直接使用L,则表示星期六（是从周日开始的，所以周六是最后一天） day-of-week: MONL(为了避免数字造成的混淆直接使用字母)，表示这个月的最后一个周一  5.4、W 字符说明 W在这里代表的是WeekDay(工作日的意思)，它只能使用在day-of-month字段中。 在表达式的使用中，它的作用是指定在同一个月内，离指定日期最近的工作日。\n举例1\n0 0 0 15W * ? 这个表达式字面意思是，在离每个月15号最近的工作日的 0点0分0秒触发 1. 如果15号是 周一到周五中的某一天，那么就在当天触发 2. 如果15号是 周六，那么离周六最近的工作日就是周五(前一天)，那么就会在周五触发； 3. 如果15号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 这个有一个大前提就是，必须是同一个月内的。通过下面的例子来说明一下\n举例2\n0 0 0 1W * ? 这个表达式字面意思是，在离每个月1号最近的工作日的 0点0分0秒触发 1. 如果1号是 周一到周五中的某一天，那么就在当天触发（这个没问题） 2. 如果1号是 周日，那么离周日最近的工作日是周一(后一天)，那么就是在周一触发； 3. 如果1号是 周六，关键在这里，距离周六最近的工作日是周五(前一天，1号的前一天已经是上个月了)，但是因为大前提是必须是同一个月的，所以只能在后两天的周一触发 5.5、# 字符说明  The \u0026lsquo;#\u0026rsquo; character is allowed for the day-of-week field. This character is used to specify \u0026ldquo;the nth\u0026rdquo; XXX day of the month.\nIf the \u0026lsquo;#\u0026rsquo; character is used, there can only be one expression in the day-of-week field (\u0026ldquo;3#1,6#3\u0026rdquo; is not valid, since there are two expressions).\n # 号只能用在 day-of-week字段中，表示某个月的第几个星期几; 同时说明一下 #前面的是表示星期几，#后面的数字表示第几，还有如果day-of-week使用了#。\n如果day-of-week字段中出现了#,那么day-of-week中就只能有且只有这一种表达式。\n举例\n0 0 0 ? * MON#2 每个月的第二个星期一 0点0分0秒 六、常见cron 每个月的工作日上午9点0分0秒\n0 0 9 ? * MON-FRI 每个月的最后一个周一上午9点0分0秒\n0 0 9 ? * MONL 每个月的最后一个工作日上午9点0分0秒\n0 0 9 LW * ? 这里需要注意的就是 W必须要写在后面 在工作日每隔10分钟执行一次\n0 */10 * ? * MON-FRI 六、参考文章 Quartz-CronExpression\nquartz-cron-校验\nlinux-man-crontab\nlinux-easycron\ncron-wiki\n","permalink":"https://balvboy.github.io/blog/cron/","summary":"\u003ch1 id=\"一-cron介绍\"\u003e一、cron介绍\u003c/h1\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003ecrontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语chronos(χρόνος)，原意是时间。\n通常，crontab储存的指令被守护进程激活，crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"cron表达式 "},{"content":" 微信公众号 ","permalink":"https://balvboy.github.io/wechat/","summary":" 微信公众号 ","title":""},{"content":"","permalink":"https://balvboy.github.io/search/","summary":"search","title":"Search"}]