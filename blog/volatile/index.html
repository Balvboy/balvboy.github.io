<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Java同步机制(二)-Volatile | ZhouYang's Blog</title><meta name=keywords content="volatile"><meta name=description content="volatile"><meta name=author content="    &#34;zhouyang&#34;"><link rel=canonical href=https://balvboy.github.io/blog/volatile/><meta name=google-site-verification content="XYZabc"><link href=/assets/css/stylesheet.min.3f6a79d84dce1064322991082a04723d5157c86c73768c45927919cf00b4462f.css integrity="sha256-P2p52E3OEGQyKZEIKgRyPVFXyGxzdoxFknkZzwC0Ri8=" rel="preload stylesheet" as=style><link rel=icon href=https://balvboy.github.io/img/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://balvboy.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://balvboy.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://balvboy.github.io/img/favicon.ico><link rel=mask-icon href=https://balvboy.github.io/img/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-146899866-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Java同步机制(二)-Volatile"><meta property="og:description" content="volatile"><meta property="og:type" content="article"><meta property="og:url" content="https://balvboy.github.io/blog/volatile/"><meta property="og:image" content="https://balvboy.github.io/img/z.jpg"><meta property="article:published_time" content="2021-05-21T00:00:00+00:00"><meta property="article:modified_time" content="2021-05-21T00:00:00+00:00"><meta property="og:site_name" content="Life is Fantastic"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://balvboy.github.io/img/z.jpg"><meta name=twitter:title content="Java同步机制(二)-Volatile"><meta name=twitter:description content="volatile"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Java同步机制(二)-Volatile","name":"Java同步机制(二)-Volatile","description":"volatile在Java中的语义 对于volatile我们都比较熟悉，volatile在Java中有两种作用\n 保障字段在多线程之间的可见性 防止指令进行重排序(编译器层面和CPU层面，后面会说明)  下面我就来看一下jvm是如何实现这两种作用的\nJVM对volatile的实现 volatile关键字只能用来修饰属性。对于属性有获取和设置两种操作，所以我们 …","keywords":["volatile"],"articleBody":" volatile在Java中的语义 对于volatile我们都比较熟悉，volatile在Java中有两种作用\n 保障字段在多线程之间的可见性 防止指令进行重排序(编译器层面和CPU层面，后面会说明)  下面我就来看一下jvm是如何实现这两种作用的\nJVM对volatile的实现 volatile关键字只能用来修饰属性。对于属性有获取和设置两种操作，所以我们就从这两种操作入手分析一下JVM对volitile的处理。\n上面的两种操作在字节码中对应着 getfield，getstatic和putfield，putfield这四种字节码。\n我们去bytecodeinterpreter.cpp看一下对应的实现逻辑。(说明一下，JVM现在使用的是模板编译器的，但是字节码编译器可读性比较好，用来学习还是比较合适的)\n我们找到上面几个字节码的执行位置\n... CASE(_getfield): CASE(_getstatic): { ... if (cache-is_volatile()) { if (support_IRIW_for_not_multiple_copy_atomic_cpu) { OrderAccess::fence(); } ... } ... } ... CASE(_putfield): CASE(_putstatic): { ... if (cache-is_volatile()) { ... OrderAccess::storeload(); } ... }  可以看到，在访问对象字段的时候，会先判断它是不是volatile的，如果是的话，并且当前CPU平台支持多核核atomic操作的话（现代的绝大多数的CPU都支持），然后就调用OrderAccess::fence()。 在设置字段的时候，会使用OrderAccess::storeload(); 这两个就是JVM提供的内存屏障。\nJVM提供的内存屏障 JVM中，所有内存屏障的使用都由OrderAccess来提供。在OrderAccess.hpp中说明了JVM提供的几种内存屏障。\n// Memory Access Ordering Model // // This interface is based on the JSR-133 Cookbook for Compiler Writers. // // In the following, the terms 'previous', 'subsequent', 'before', // 'after', 'preceding' and 'succeeding' refer to program order. The // terms 'down' and 'below' refer to forward load or store motion // relative to program order, while 'up' and 'above' refer to backward // motion. // // We define four primitive memory barrier operations. // // LoadLoad: Load1(s); LoadLoad; Load2 // // Ensures that Load1 completes (obtains the value it loads from memory) // before Load2 and any subsequent load operations. Loads before Load1 // may *not* float below Load2 and any subsequent load operations. // // StoreStore: Store1(s); StoreStore; Store2 // // Ensures that Store1 completes (the effect on memory of Store1 is made // visible to other processors) before Store2 and any subsequent store // operations. Stores before Store1 may *not* float below Store2 and any // subsequent store operations. // // LoadStore: Load1(s); LoadStore; Store2 // // Ensures that Load1 completes before Store2 and any subsequent store // operations. Loads before Load1 may *not* float below Store2 and any // subsequent store operations. // // StoreLoad: Store1(s); StoreLoad; Load2 // // Ensures that Store1 completes before Load2 and any subsequent load // operations. Stores before Store1 may *not* float below Load2 and any // subsequent load operations.  // 省略 acquire and release 部分内容  // Finally, we define a \"fence\" operation, as a bidirectional barrier. // It guarantees that any memory access preceding the fence is not // reordered w.r.t. any memory accesses subsequent to the fence in program // order. This may be used to prevent sequences of loads from floating up // above sequences of stores.  通过上面的注释我们知道，JVM根据JSR-133 Cook Book定义了4种基本的内存屏障操作，并由下面的几种作用。\n   内存屏障 使用方法 作用     LoadLoad Load1 LoadLoad Load2 确保Load1一定是在\nLoad2以及其后的指令之前完成   StoreStore Store1 StoreStore Store2 确保 Store1 一定是在\nStore2 以及其后的指令之前完成\n（同时，Store1的写入数据会立即被其他 CPU看到   LoadStore Load1 LoadStore Store2 确保 Load1 一定是在\nStore2 以及其后的指令之前完成   StoreLoad Store1 StoreLoad Load2 确保 Store1 一定在 Load2 以及其后的指令之前完成    我们看到，在常见的4中基本内存屏障之后，还单独定义了fence操作，fence操作的功能可以说涵盖了上面的4中基本屏障。它可以保证fence前的任何操作op1都在op2之前完成。\nJVM为每种屏障类型都定义了一个单独的方法，带代码中如果需要某种屏障可能直接调用。\nstatic void loadload(); static void storestore(); static void loadstore(); static void storeload(); static void acquire(); static void release(); static void fence();  volatile和硬件的关系 volatile在上面提到的两个功能，都是通过JVM定义的内存屏障来实现的。 而JVM定义的内存屏障可以理解是一个规范，它要求不管在什么平台上都要有同样的效 果。但是最终还是要依靠硬件来实现。所以们可以看到，在JVM中对于各种硬件平台都有对应的内存屏障实现。\n因为我们在服务器领域还是使用Linux比较多，而且大部分使用的是Intel的CPU，所以下面我们先关注一下linux_x86的实现\nlinux_x86内存屏障实现 static inline void compiler_barrier() { __asm__ volatile (\"\" : : : \"memory\"); } inline void OrderAccess::loadload() { compiler_barrier(); } inline void OrderAccess::storestore() { compiler_barrier(); } inline void OrderAccess::loadstore() { compiler_barrier(); } inline void OrderAccess::storeload() { fence(); } inline void OrderAccess::acquire() { compiler_barrier(); } inline void OrderAccess::release() { compiler_barrier(); } inline void OrderAccess::fence() { if (os::is_MP()) { // always use locked addl since mfence is sometimes expensive #ifdef AMD64  __asm__ volatile (\"lock; addl $0,0(%%rsp)\" : : : \"cc\", \"memory\"); #else  __asm__ volatile (\"lock; addl $0,0(%%esp)\" : : : \"cc\", \"memory\"); #endif  } compiler_barrier(); }  我们看上面用到的fence()和storeload()方法，都其实最终调用的都是fence()方法。其他的都是调用的compiler_barrier()方法。 然后这里两个方法里面都是使用的内嵌汇编指令的方式，所以我们下来分析一下这个内嵌汇编指令的格式。\n内嵌汇编指令 内嵌汇编指令的格式是\n__asm__　__volatile__(\"Instruction List\" : Output : Input : Clobber/Modify);\n __asm__或asm 用来声明一个内联汇编表达式，所以任何一个内联汇编表达式都是以它开头的，是必不可少的。 __volatile__或volatile 是可选的。如果用了它，表示防止编译器对代码块进行优化。  而这里的优化是针对代码块而言的，使用嵌入式汇编的代码分成三块： 嵌入式汇编之前的代码块 嵌入式汇编代码块 嵌入式汇编之后的c代码块 所以使用了volatile修饰的内嵌汇编的意思是，防止编译器对汇编代码块及前后的代码进行重排序等优化。  Instruction List 是要执行的汇编指令序列。它可以是空的。 Output和Input是汇编指令中的输入和输出，都可以为空，这里我们不做过多分析 Clobber/Modify是寄存器/内存修改标示。通知GCC当前内联汇编语句可能会对某些寄存器或内存进行修改,希望GCC在编译时能够将这一点考虑进去,这会对GCC在编译的时候有一些影响，但具体是什么影响我们就不深究了。  了解了内嵌汇编代码的格式，我们再来看上面的两个方法。\ncompiler_barrier()：__asm__ volatile (\"\" : : : \"memory\");\n禁止编译器对汇编代码前后的代码块，进行重排序等优化，并且告诉编译器我修改了memory中的内容\nfence():__asm__ volatile (\"lock; addl $0,0(%%esp)\" : : : \"cc\", \"memory\");\n禁止编译器对汇编代码前后的代码块，进行重排序等优化,并且执行 lock; addl $0,0(%%esp)这条汇编指令，并且告诉编译器我修改了memory中的内容\nLock前缀指令 通过上面我们已经知道，JVM通过使用带有volatile关键字的内嵌汇编的方便，解决了编译器重排序的问题。那么CPU级别的重排序，和内存间的可见性是怎么实现的呢，下面我们就要用到Lock指令了。\n我们看到在fence()方法内嵌的汇编代码中，使用了lock前缀指令，那lock前缀指令在这里起到的是什么作用呢。\nLock前缀指令的作用 在Intel 用户开发手册中关于lock前缀有这样的描述。\nIntel开发手册下载地址\n8.1- LOCKED ATOMIC OPERATIONS\n The processor uses three interdependent mechanisms for carrying out locked atomic operations:\n• Guaranteed atomic operations\n• Bus locking, using the LOCK# signal and the LOCK instruction prefix\n• Cache coherency protocols that ensure that atomic operations can be carried out on cached data structures (cache lock); this mechanism is present in the Pentium 4, Intel Xeon, and P6 family processors\n 意思是，我们有3种方式可以实现CPU的原子操作\n 使用被保证的原子操作，比如读写1byte等 使用lock指令作为指令前缀 使用缓存一致性协议  所以使用lock指令作为前缀，能够把它后面的一个或者几个操作’包装’为一个原子操作。不过你可能会想，那这么说来lock的作用和我们使用它的目前好像不大一样啊，可见性呢？重排序呢？别急我们继续看。\nLock前缀保证可见性 lock前缀指令的实现方法，在早期CPU和现代CPU中有很大不同,我们还是引用开发手册中的描述\n8.1.2-Bus Locking\n In the case of the Intel386, Intel486, and Pentium processors, explicitly locked instructions will result in the asser- tion of the LOCK# signal. It is the responsibility of the hardware designer to make the LOCK# signal available in system hardware to control memory accesses among processors.\nFor the P6 and more recent processor families, if the memory area being accessed is cached internally in the processor, the LOCK# signal is generally not asserted; instead, locking is only applied to the processor’s caches\n 意思是，在早期的CPU中，当使用lock前缀指令时候，会导致产生一个LOCK#信号，通过总线锁定对应的内存，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放。 在后来的处理器的处理逻辑中，如果要操作的内存，已经cache到了处理器的缓存中，那么将不会产生LOCK#信号，则通过缓存一致性协议来完成原子性的保证。\n8.1.4-Effects of a LOCK Operation on Internal Processor Caches\n For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is cached in the processor that is performing the LOCK operation as write-back memory and is completely contained in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow it’s cache coherency mechanism to ensure that the operation is carried out atomically. This operation is called “cache locking.” The cache coherency mechanism automatically prevents two or more processors that have cached the same area of memory from simultaneously modifying data in that area.\n 意思是：在LOCK操作中被锁定的内存区域是缓存在执行LOCK操作的处理器中，作为回写存储器，并且完全包含在缓存行中。在一个缓存行中，处理器可能不会在总线上发出LOCK#信号。相反，它将在内部修改内存位置，并允许它的缓存一致性机制确保该操作是原子式进行的。这种操作被称为”高速缓存锁定”。缓存一致性机制会自动防止两个或更多的处理器在缓存同一区域的内存上同时修改该区域的数据。\n显而易见，使用总线锁定的方式代价要大得多。不过目前在大多数情况下，我们在使用lock指令的时候，都是通过缓存一致性协议来保证的后面操作的原子性操作。但是有一些情况同样也会导致不能使用高速缓存锁定，而只能使用总线锁定，比如涉及到的数据跨越多个CacheLine，CPU不支持缓存锁定等。\n 在 Pentium 和早期的 IA-32 处理器中，lock 前缀会使处理器执行当前指令时产生一个 LOCK# 信号，会对总线进行锁定，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放 后来的处理器，加锁操作是由高速缓存锁代替总线锁来处理。 因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存。 这种场景多缓存的数据一致通过缓存一致性协议(MESI)来保证。  所以总结一下，当我们使用lock前缀指令的时候会发生这两件事\n 要操作的数据在缓存中，会导致其他CPU的缓存行失效 如果数据不再内存中，则会使用总线锁定，把内存中的数据读入或者写出到内存。同时也会导致其他CPU的缓存行失效。  所以使用lock前缀指令，会通过触发缓存一致性协议导致关联的缓存行失效，从而保证可见性。\n可见性我们知道了，那么防止指令重排序的作用呢？我们继续在用户手册中寻找一下答案。\nLock前缀防止指令重排 8.2.5 Strengthening or Weakening the Memory-Ordering Model\n The Intel 64 and IA-32 architectures provide several mechanisms for strengthening or weakening the memory- ordering model to handle special programming situations. These mechanisms include:\n• The I/O instructions, locking instructions, the LOCK prefix, and serializing instructions force stronger ordering on the processor.\n• The SFENCE instruction (introduced to the IA-32 architecture in the Pentium III processor) and the LFENCE and MFENCE instructions (introduced in the Pentium 4 processor) provide memory-ordering and serialization capabilities for specific types of memory operations.\n… 省略部分\nSynchronization mechanisms in multiple-processor systems may depend upon a strong memory-ordering model. Here, a program can use a locking instruction such as the XCHG instruction or the LOCK prefix to ensure that a read-modify-write operation on memory is carried out atomically. Locking operations typically operate like I/O operations in that they wait for all previous instructions to complete and for all buffered writes to drain to memory\n 意思是，Intel处理器提供了几种机制用来加强或者削弱内存排序。其中使用IO相关指令、锁定指令、LOCK前缀指令、序列化相关指令都能够强化 排序。(这里强化的意思是，更加按照指令流的顺序来执行,也就是减少处理器的重排序)\n在程序中可以使用锁定指令，或者lock前缀指令来强化排序，它们会等待所有先前的指令完成，并等待所有缓冲的写操作耗尽到内存中。\n所以我们看到，JVM通过内嵌lock前缀的汇编指令，保证了可见性和防止了内存重排序。\nLock前缀指令的其他应用 我们经常使用的CAS的底层，也是使用lock前缀实现的，使用lock指令保证了后面的操作的原子性。\n为何x86只实现了storeload内存屏障 还有一点我们在上面的x86的实现中看到，只有fence()方法，和storeload()方法使用lock前缀指令，其他的几种都是只是实现了编译器级别的内存屏障，也就是只能防止编译器的指令重排序。这是为什么呢？\n同样我们在操作手册中寻找一下答案，在操作手册的 8.2.3-Examples Illustrating the Memory-Ordering章节，说明x86处理器对store和load指令的重排序情况\n 8.2.3.2 Neither Loads Nor Stores Are Reordered with Like Operations 8.2.3.3 Stores Are Not Reordered With Earlier Loads 8.2.3.4 Loads May Be Reordered with Earlier Stores to Different Locations  意思是 - load指令和store指令，都不能喝同类型的指令之间发生重排序，也就是 load1,load2 和 store1，store2 是不会发生重排序的 - store指令和前面出现的load指令，不会重排序，也就是 load1,store2 不会发生重排序。 - load指令，和它前面出现的store指令之间可能会发生重排序。\n看到这，我们能知道，x86的CPU，在不添加任何内存屏障的情况下，已经支持了loadload,storestore,loadstore屏障了。只有storeload这种需要单独添加内存屏障来保证不会重排序。\n所以对于x86处理器原生支持的3种屏障，只需要保证编译器不会发生重排序即可。\n所以说，volatile的实现和硬件平台关系非常密切。下面这个是在不同硬件下，发生重排序的情况。\n   处理器 Load-Load Load-Store Store-Store Store-Load 数据依赖     x86 N N N Y N   PowerPC Y Y Y Y N   ia64 Y Y Y Y N    我们看到，x86在loadload,loadStore.storestore 和有数据依赖的时候不会发生重排序。 另外两种平台，只有在有数据依赖的时候不会发生重排序。\n所以JVM需要根据不同平台来进行不同的处理。\n为何x86下JVM使用LOCK前缀实现内存屏障 在Intel的处理器平台下内存屏障分为两类：\n 本身是内存屏障，比如“lfence”，“sfence”和“mfence”汇编指令 本身不是内存屏障，但是被LOCK指令前缀修饰，其组合成为一个内存屏障。在X86指令体系中，其中一类内存屏障常使用“LOCK指令前缀加上一个空操作”方式实现，比如lock addl $0x0,(%esp)  所以有一个疑问，为什么JVM选择使用lock前缀指令来实现内存屏障而不使用专门的内存屏障指令呢？\n我在JVM的源码中搜索了一下mfence,搜索到了下面几段注释\nmacroAssembler_x86.cpp\n// We have a classic Dekker-style idiom: // ST m-_owner = 0 ; MEMBAR; LD m-_succ // There are a number of ways to implement the barrier: // (1) lock:andl \u0026m-_owner, 0 // is fast, but mask doesn't currently support the \"ANDL M,IMM32\" form. // LOCK: ANDL [ebx+Offset(_Owner)-2], 0 // Encodes as 81 31 OFF32 IMM32 or 83 63 OFF8 IMM8 // (2) If supported, an explicit MFENCE is appealing. // In older IA32 processors MFENCE is slower than lock:add or xchg // particularly if the write-buffer is full as might be the case if // if stores closely precede the fence or fence-equivalent instruction. // See https://blogs.oracle.com/dave/entry/instruction_selection_for_volatile_fences // as the situation has changed with Nehalem and Shanghai. // (3) In lieu of an explicit fence, use lock:addl to the top-of-stack // The $lines underlying the top-of-stack should be in M-state. // The locked add instruction is serializing, of course. // (4) Use xchg, which is serializing // mov boxReg, 0; xchgl boxReg, [tmpReg + Offset(_owner)-2] also works // (5) ST m-_owner = 0 and then execute lock:orl \u0026m-_succ, 0. // The integer condition codes will tell us if succ was 0. // Since _succ and _owner should reside in the same $line and // we just stored into _owner, it's likely that the $line // remains in M-state for the lock:orl. // // We currently use (3), although it's likely that switching to (2) // is correct for the future.  orderAccess_linux_x86.inline.hpp\n// always use locked addl since mfence is sometimes expensive  大概意思就是说，mfence目前有几个缺点\n1.并不是所有cpu都支持这个指令。 2. 在最早前的CPU中性能比lock前缀差一些。 3. 有时mfence的性能损耗比较严重\n所以基于以上考虑，目前还是使用lock前缀(我查看的jvm源码是jdk11的)，但是未来很有可能改为使用mfence指令。\nInstruction selection for volatile fences : MFENCE vs LOCK:ADD\n缓存一致性协议 在上面我们不止一次的提到了缓存一致性协议，那么缓存一致性协议具体是什么样的呢？下面我们来简单的了解一下。\n现在处理器处理能力上要远胜于主内存（DRAM），主内存执行一次内存读写操作，所需的时间可能足够处理器执行上百条的指令，为了弥补处理器与主内存处理能力之间的鸿沟，引入了高速缓（Cache),来保存一些CPU从内存读取的数据，下次用到该数据直接从缓存中获取即可，以加快读取速度，随着多核时代的到来,每块CPU都有多个内核，每个内核都有自己的缓存，这样就会出现同一个数据的副本就会存在于多个缓存中，在读写的时候就会出现数据 不一致的情况。\n缓存行 数据在缓存中不是以独立的项来存储的，它不是一个单独的变量，也不是一个单独的指针,它在数据缓存中以缓存行存在的，也称缓存行为缓存条目。目前主流的CPU Cache的Cache Line大小通常是64字节，并且它有效地引用主内存中的一块地址。\n局部性原理 局部性原理：在CPU访问存储设备时，无论是存取数据或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。\n 时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如程序中的循环、递归对数据的循环访问， 主要体现在指令读取的局部性 空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如程序中的数据组的读取或者对象的连续创建， 对内存都是顺序的读写，主要体现在对程序数据引用的局部性  MESI协议 MESI是众多缓存一致性协议中的一种，也在Intel系列中广泛使用的缓存一致性协议 缓存行（Cache line）的状态有Modified、Exclusive、 Share 、Invalid，而MESI 命名正是以这4中状态的首字母来命名的。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一。\n   状态 描述 监听任务     M 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。   E 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。 缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。   S 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）   I 该Cache line无效。 无    监听任务  一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回主内存 一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。 一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S  嗅探协议 上面提到的监听任务大多数都是通过嗅探(snooping)协议来完成的\n “窥探”背后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源， 所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道， 而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知， 它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。\n MESI读取缓存流程 CPU1需要读取数据X，会根据数据的地址在自己的缓存L1A中找到对应的缓存行,然后判断缓存行的状态\n 如果缓存行的状态是M、E、S，说明该缓存行的数据对于当前读请求是可用的，则可以直接使用 如果缓存行的状态是I，则说明该缓存行的数据是无效的，则CPU1会向总线发送Read消息，说’我现在需要地址A的数据，谁可以提供？‘，其它处理器会CPU2监听总线上的消息，收到消息后，会从消息中解析出需要读取的地址， 然后在自己缓存中查找缓存行，这时候根据找到缓存行的状态会有以下几种情况  状态为S/E , CPU2会构造Read Response消息，将相应缓存行中的数据放到消息中，发送到总线同时更新自己缓存行的状态为S，CPU1收到响应消息后，会将消息中的数据存入相应的缓存行中，同时更新缓存行的状态为S 状态为M，会先将自己缓存行中的数据写入主内存，并响应Read Response消息同时将L1B中的相应的缓存行状态更新为S 状态为I或者在自己的缓存中不存在X的数据，那么主内存会构造Read Response消息，从主内存读取包含指定地址的块号数据放入消息（缓存行大小和内存块大小一致所以可以存放的下），并将消息发送到总线  CPU1获接收到总线消息之后，解析出数据保存在自己的缓存中  MESI写缓存流程 CPU1 需要写入数据X\n 为E/M时，说明当前CPU1已经拥有了相应数据的所有权，此时CPU1会直接将数据写入缓存行中，并更新缓存行状态为M，此时不需要向总线发送任何消息。 S时，说明数据被共享，其它CPU中有可能存有该数据的副本，则CPUA向总线发送Invalidate 消息以获取数据的所有权，其它处理器（CPU2)收到Invalidate消息后,会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据， 并回复Invalidate Acknowledge消息，CPU1收到所有处理器的响应消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M I时，说明当前处理器中不包含该数据的有效副本，则CPU1向总线发送Read Invalidate消息，表明我要读数据X，希望主存告诉我X的值，同时请示其它处理器将自己缓存中包含该数据的缓存行并且状态不是I的缓存行置为无效` 其它处理器（CPUB)收到Invalidate消息后，如果缓存行不为I的话，会将其高速缓存中相应的缓存行状态更新为I，表示已经逻辑删除相应的副本数据，并回复Invalidate Acknowledge消息 主内存收到Read消息后，会响应Read Response消息将需要读取的数据告诉CPU1 CPU1收到所有处理器的Invalidate Acknowledge消息和主内存的Read Response消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为E，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为M  MESI的状态变化  Local Read：表示本内核读本Cache中的值 Local Write：表示本内核写本Cache中的值 Remote Read：表示其它内核读其Cache中的值 Remote Write：表示其它内核写其Cache中的值 箭头表示本Cache line状态的迁移，环形箭头表示状态不变  StoreBuffer和Invalidate Queue 说了缓存一致性协议，好像就能够解决问题了，但是，在这里你会发现，又有新的问题出现了。MESI协议中：当cpu0写数据到本地cache的时候，如果不是M或者E状态，需要发送一个invalidate消息给cpu1，只有收到cpu1的ack之后cpu0才能继续执行， 在这个过程中cpu0需要等待，这大大影响了性能。于是CPU设计者引入了Store Buffer，这个buffer处于CPU与cache之间。\nStore Buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给缓存一致性协议。但是Store Buffer仍然引入了一些复杂性,那就是缓存数据和Store Buffer数据不一致的问题。\nStore Forwarding 为了解决上面的问题，修改为了下面的架构，这种设计叫做Store forwarding，当CPU执行load操作的时候，不但要看cache，还有看Store Buffer是否有内容，如果Store Buffer有该数据，那么就采用Store Buffer中的值。\nInvalid Queue 同样的问题也会出现在其他线程发送Invalidate Acknowledge消息的时候，通常Invalidate Cacheline操作没有那么快完成,尤其是在Cache繁忙的时候，这时CPU往往进行密集的load和store的操作，而来自其他CPU的， 对本CPU Cache的操作需要和本CPU的操作进行竞争，只有完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。 为了解决这个问题，引入了Invalid Queue,系统架构如下。\n有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候， 那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。\n另外说一下，x86的CPU不含有 invalidate queue,这也是上面提到的，x86平台下只有storeload会发生重排序的原因。\n乱序执行/重排序 了解完上面的这些知识，我们再来整体的总结一下乱序执行或者说重排序的问题。\n重排序从发生的环节上来分，可以分为2大类\n 编译器重排序 处理器重排序  下面我们分别来说一下。\nas-if-serial语义 无论是处理器还是编译器,不管怎么重排都要保证(单线程)程序的执行结果不能被改变,这就是as-if-serial语义。\n编译器重排序 编译器重排序：编译器会对高级语言的代码进行分析，当编译器认为你的代码可以优化的话，编译器会选择对代码进行优化，重新排序，然后生成汇编代码。当然这个优化是有原则的，原则就是在保证单线程下的执行结果不变。\n编译器在编译时候，能够获得最底层的信息，比如要读写哪个寄存器，读写哪块内存。所以编译就根据这些信息对代码进行优化，包括不限于减少无用变量、修改代码执行顺序等等。 优秀的编译器优化能够提升程序在CPU上的运行性能，更好的使用寄存器以及现代处理器的流水线技术，减少汇编指令的数量，降低程序执行需要的CPU周期，减少CPU读写主存的时间。\n当然，编译器在优化的时候，只能保证在单线程下的结果，在多线程情况下，不加限制就可能会导致错误的结果。所以在多线程情况就需要开发者对编译器进行适当的指引，防止编译器进行错误的优化。\n处理器乱序 CPU接受到编译器编译的指令，通常为了为了提高CPU流水线的工作效率，也会对指令进行分析，然后进行乱序执行。当然不同的硬件进行乱序的规则也不大相同，我们还把上面的表格哪来参考一下。\n   处理器 Load-Load Load-Store Store-Store Store-Load 数据依赖     x86 N N N Y N   PowerPC Y Y Y Y N   ia64 Y Y Y Y N    我们对CPU发生乱序执行情况进行一下分类\n 在没有数据依赖的情况下，发生的乱序。 CPU顺序执行，但是因为StoreBuffer和 Invalidate Queue的存在产生了乱序的效果。  关于StoreBuffer和 Invalidate Queue引起的乱序稍微复杂一点，就不在这里展开了，有兴趣的同学可以查看 Why Memory Barriers   同样上面的这些乱序，都是能够保证在单线程的情况下执行结果的正确行。在多线程环境下，如果需要保证有序，那就需要开发者使用CPU提供的内存屏障指令，或者带有内存屏障作用的其他指令，来告诉CPU不要进行乱序执行了。\n伪共享问题 伪共享的意思是，我们在开发中定义了共享变量，然后在多个线程中访问。看起来像是这个变量在内存中，多个CPU共享，但是实际情况是每个CPU都访问自己的缓存，并不是直接访问的整个变量。\n伪共享导致的问题就是，如果几个字段因为局部性原理，被加载到了同一个缓存行中，然后被几个线程分别访问。这时就会因为MESI协议，导 致缓存频繁失效，从而CPU每次只能从内存中加载数据，从而降低程序的执行效率。\n下面我们通过代码验证一下， 在下面代码中我们我们定义了两个长度为2的long数组，其中一个使用volatile关键字修饰，另一个没有。\npublic class FalseShareTest { private final long CYCLE_TIMES = 10_0000_0000L; private volatile long[] array = new long[2]; private long[] array1 = new long[2]; /** * 启动2个线程修改volatile数组的第1，2位 1000w次 */ @Test public void test() throws InterruptedException { Thread t1 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array[0] = i; } }); Thread t2 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\"Duration: \" + (end - start) / 100_0000); } /** * 启动2个线程修改非volatile数组的第1，2位 1000w次 */ @Test public void test1() throws InterruptedException { Thread t1 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array1[0] = i; } }); Thread t2 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array1[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\"Duration: \" + (end - start) / 100_0000); } } 每个方法我们都执行5次看一下耗时\nvolatile数组 Duration: 3281 Duration: 3052 Duration: 3071 Duration: 3079 Duration: 3111 非volatile数组 Duration: 358 Duration: 347 Duration: 552 Duration: 545 Duration: 548 我们发现修改volatile修饰的数组，消耗的时间是没有volatile数组的10倍。 这个时间花在什么地方呢。 我们来分析一下。\n 缓存行的大小一般为64字节 定义的数据长度为2，类型是long，所以数据大小就是16字节。根据局部性原理，所以他们很有可能放到了同一个缓存行中 两个线程并发的读取修改第一个数据和第二个数据，这里我们可以理解为CPU1修改第一个数据X，CPU2修改第二个数据Y CPU1修改了X，因为数据定义为volatile，所以必须保证多线程之间的可见性，所以会强制使用lock前缀指令，让CPU2中对应的缓存行失效 CPU2想要修改Y，这时候发现这个缓存行已经失效了，所以需要重新从内存中读取，然后修改，同时又会导致CPU1的缓存行失效。 所以耗时发生在，volatile的可见性要求导致缓存行一直失效，需要不断的从内存中读取所导致。 而非volatile数据，并没有可见性要求，并且因为store buffer的存在，缓存并不会立即失效，所以效率要高的多。  volatile的优化 知道了上面伪共享和volatile带来的性能问题，那么有没有办法进行优化呢？ 答案肯定是有的，我们思考一下，上面的主要问题是，两个数据都存在于同一个缓存行中，对任何一个字段的读写，都会导致缓存行失效，那么我们把这两个数据分开，放到不同的缓存行呢？\n我们把上面的代码改一下，把数组长度改为16，两个线程分别修改第1个，和第9个，因为缓存行是64字节，long是8个字节，所以第1个和第9个肯定不会再同一个缓存行中。\npublic class FalseShareTest { private final long CYCLE_TIMES = 10_0000_0000L; private volatile long[] array = new long[2]; private volatile long[] array1 = new long[16]; public void test() throws InterruptedException { Thread t1 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array[0] = i; } }); Thread t2 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array[1] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\"Duration: \" + (end - start) / 100_0000); } public void test1() throws InterruptedException { Thread t1 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array1[0] = i; } }); Thread t2 = new Thread(() - { for (long i = 0; i  CYCLE_TIMES; i++) { array1[8] = i; } }); long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.nanoTime(); System.out.println(\"Duration: \" + (end - start) / 100_0000); } public static void main(String[] args) throws InterruptedException { FalseShareTest falseShareTest = new FalseShareTest(); System.out.println(\"未优化\"); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); falseShareTest.test(); System.out.println(\"优化后\"); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); falseShareTest.test1(); } } 执行结果\n未优化 Duration: 6589 Duration: 7006 Duration: 7527 Duration: 7278 Duration: 7813 优化后 Duration: 1961 Duration: 2011 Duration: 1974 Duration: 2056 Duration: 1953 我们发现把数据移动到不同的缓存行之后，运行时间缩短了三分之二左右。\n所以对volatile的优化的主要逻辑就是，让volatile的字段，自己处于一个缓存行中，不要让其他字段的变化，影响volatile变量所处缓存行的状态。\nfalse share的优化案例 这种优化，在很多高性能的框架中还是挺常见的。比如在caffeine中就有这样的应用\n依据JVM对象继承关系中父类属性与子类属性，内存地址连续排列布局,PadReadCounter中的字段会作为前置填充，PadWriteCounter中的字段会作为后置填充。 保证readCounter字段能够独占一个缓存行。\n我们看到这里前后各使用的15个long字段作为填充，这应该是为了防止不同的系统下缓存行大小不一致的情况。\n@sun.misc.Contended注解 参考 [关键字: volatile详解]\n[汇编指令的LOCK指令前缀]\n[一文了解内存屏障]\n[volatile与内存屏障]\n[内存屏障及其在JVM内的应用]\n[CPU缓存一致性协议MESI]\n[x86架构]\n[聊聊缓存一致性协议]\n[浅论Lock与X86 Cache一致性]\n[Why Memory Barriers？中文翻译（上）]\n[Volatile全面解析，实现原理及作用分析]\n[编译器重排序]\n[一篇对伪共享、缓存行填充和CPU缓存讲的很透彻的文章]\n[为什么volatile注释变量，对其下面的变量也会有影响？]\n[一次深入的volatile研究]\n[既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？]\n","wordCount":"2019","inLanguage":"en","datePublished":"2021-05-21T00:00:00Z","dateModified":"2021-05-21T00:00:00Z","author":{"@type":"Person","name":"    \"zhouyang\""},"mainEntityOfPage":{"@type":"WebPage","@id":"https://balvboy.github.io/blog/volatile/"},"publisher":{"@type":"Organization","name":"ZhouYang's Blog","logo":{"@type":"ImageObject","url":"https://balvboy.github.io/img/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://balvboy.github.io accesskey=h title="Home (Alt + H)"><img src=/img/zhouyang.png alt=logo aria-label=logo height=35>Home</a>
<span class=logo-switches><span class=theme-toggle title="(Alt + T)"><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://balvboy.github.io/blog/ title=blogs><span>blogs</span></a></li><li><a href=https://balvboy.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://balvboy.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://balvboy.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav><script>var _hmt=_hmt||[];(function(){var a=document.createElement("script"),b;a.src="https://hm.baidu.com/hm.js?a3d79563dfbd078b66e86495caf11120",b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script><script src=/js/mermaid.js></script></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Java同步机制(二)-Volatile</h1><div class=post-description>volatile</div><div class=post-meta>May 21, 2021&nbsp;·&nbsp;10 min&nbsp;·&nbsp;    "zhouyang"</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#volatile%e5%9c%a8java%e4%b8%ad%e7%9a%84%e8%af%ad%e4%b9%89 aria-label=volatile在Java中的语义>volatile在Java中的语义</a></li><li><a href=#jvm%e5%af%b9volatile%e7%9a%84%e5%ae%9e%e7%8e%b0 aria-label=JVM对volatile的实现>JVM对volatile的实现</a><ul><li><a href=#jvm%e6%8f%90%e4%be%9b%e7%9a%84%e5%86%85%e5%ad%98%e5%b1%8f%e9%9a%9c aria-label=JVM提供的内存屏障>JVM提供的内存屏障</a></li></ul></li><li><a href=#volatile%e5%92%8c%e7%a1%ac%e4%bb%b6%e7%9a%84%e5%85%b3%e7%b3%bb aria-label=volatile和硬件的关系>volatile和硬件的关系</a><ul><li><a href=#linux-x86%e5%86%85%e5%ad%98%e5%b1%8f%e9%9a%9c%e5%ae%9e%e7%8e%b0 aria-label=linux_x86内存屏障实现>linux_x86内存屏障实现</a><ul><li><a href=#%e5%86%85%e5%b5%8c%e6%b1%87%e7%bc%96%e6%8c%87%e4%bb%a4 aria-label=内嵌汇编指令>内嵌汇编指令</a></li><li><a href=#lock%e5%89%8d%e7%bc%80%e6%8c%87%e4%bb%a4 aria-label=Lock前缀指令>Lock前缀指令</a><ul><li><a href=#lock%e5%89%8d%e7%bc%80%e6%8c%87%e4%bb%a4%e7%9a%84%e4%bd%9c%e7%94%a8 aria-label=Lock前缀指令的作用>Lock前缀指令的作用</a></li><li><a href=#lock%e5%89%8d%e7%bc%80%e4%bf%9d%e8%af%81%e5%8f%af%e8%a7%81%e6%80%a7 aria-label=Lock前缀保证可见性>Lock前缀保证可见性</a></li><li><a href=#lock%e5%89%8d%e7%bc%80%e9%98%b2%e6%ad%a2%e6%8c%87%e4%bb%a4%e9%87%8d%e6%8e%92 aria-label=Lock前缀防止指令重排>Lock前缀防止指令重排</a></li></ul></li><li><a href=#lock%e5%89%8d%e7%bc%80%e6%8c%87%e4%bb%a4%e7%9a%84%e5%85%b6%e4%bb%96%e5%ba%94%e7%94%a8 aria-label=Lock前缀指令的其他应用>Lock前缀指令的其他应用</a></li><li><a href=#%e4%b8%ba%e4%bd%95x86%e5%8f%aa%e5%ae%9e%e7%8e%b0%e4%ba%86storeload%e5%86%85%e5%ad%98%e5%b1%8f%e9%9a%9c aria-label=为何x86只实现了storeload内存屏障>为何x86只实现了storeload内存屏障</a></li><li><a href=#%e4%b8%ba%e4%bd%95x86%e4%b8%8bjvm%e4%bd%bf%e7%94%a8lock%e5%89%8d%e7%bc%80%e5%ae%9e%e7%8e%b0%e5%86%85%e5%ad%98%e5%b1%8f%e9%9a%9c aria-label=为何x86下JVM使用LOCK前缀实现内存屏障>为何x86下JVM使用LOCK前缀实现内存屏障</a></li></ul></li><li><a href=#%e7%bc%93%e5%ad%98%e4%b8%80%e8%87%b4%e6%80%a7%e5%8d%8f%e8%ae%ae aria-label=缓存一致性协议>缓存一致性协议</a><ul><li><a href=#%e7%bc%93%e5%ad%98%e8%a1%8c aria-label=缓存行>缓存行</a><ul><li><a href=#%e5%b1%80%e9%83%a8%e6%80%a7%e5%8e%9f%e7%90%86 aria-label=局部性原理>局部性原理</a></li></ul></li><li><a href=#mesi%e5%8d%8f%e8%ae%ae aria-label=MESI协议>MESI协议</a><ul><li><a href=#%e7%9b%91%e5%90%ac%e4%bb%bb%e5%8a%a1 aria-label=监听任务>监听任务</a></li><li><a href=#%e5%97%85%e6%8e%a2%e5%8d%8f%e8%ae%ae aria-label=嗅探协议>嗅探协议</a></li><li><a href=#mesi%e8%af%bb%e5%8f%96%e7%bc%93%e5%ad%98%e6%b5%81%e7%a8%8b aria-label=MESI读取缓存流程>MESI读取缓存流程</a></li><li><a href=#mesi%e5%86%99%e7%bc%93%e5%ad%98%e6%b5%81%e7%a8%8b aria-label=MESI写缓存流程>MESI写缓存流程</a></li><li><a href=#mesi%e7%9a%84%e7%8a%b6%e6%80%81%e5%8f%98%e5%8c%96 aria-label=MESI的状态变化>MESI的状态变化</a></li></ul></li><li><a href=#storebuffer%e5%92%8cinvalidate-queue aria-label="StoreBuffer和Invalidate Queue">StoreBuffer和Invalidate Queue</a><ul><li><a href=#store-forwarding aria-label="Store Forwarding">Store Forwarding</a></li><li><a href=#invalid-queue aria-label="Invalid Queue">Invalid Queue</a></li></ul></li></ul></li><li><a href=#%e4%b9%b1%e5%ba%8f%e6%89%a7%e8%a1%8c-%e9%87%8d%e6%8e%92%e5%ba%8f aria-label=乱序执行/重排序>乱序执行/重排序</a><ul><li><a href=#as-if-serial%e8%af%ad%e4%b9%89 aria-label=as-if-serial语义>as-if-serial语义</a></li><li><a href=#%e7%bc%96%e8%af%91%e5%99%a8%e9%87%8d%e6%8e%92%e5%ba%8f aria-label=编译器重排序>编译器重排序</a></li><li><a href=#%e5%a4%84%e7%90%86%e5%99%a8%e4%b9%b1%e5%ba%8f aria-label=处理器乱序>处理器乱序</a></li></ul></li><li><a href=#%e4%bc%aa%e5%85%b1%e4%ba%ab%e9%97%ae%e9%a2%98 aria-label=伪共享问题>伪共享问题</a></li><li><a href=#volatile%e7%9a%84%e4%bc%98%e5%8c%96 aria-label=volatile的优化>volatile的优化</a><ul><li><a href=#false-share%e7%9a%84%e4%bc%98%e5%8c%96%e6%a1%88%e4%be%8b aria-label="false share的优化案例">false share的优化案例</a></li><li><a href=#sun-misc-contended%e6%b3%a8%e8%a7%a3 aria-label=@sun.misc.Contended注解>@sun.misc.Contended注解</a></li></ul></li></ul></li><li><a href=#%e5%8f%82%e8%80%83 aria-label=参考>参考</a></li></ul></div></details></div><div class=post-content><h1 id=volatile在java中的语义>volatile在Java中的语义<a hidden class=anchor aria-hidden=true href=#volatile在java中的语义>#</a></h1><p>对于volatile我们都比较熟悉，<code>volatile</code>在Java中有两种作用</p><ul><li>保障字段在多线程之间的可见性</li><li>防止指令进行重排序(编译器层面和CPU层面，后面会说明)</li></ul><p>下面我就来看一下jvm是如何实现这两种作用的</p><h1 id=jvm对volatile的实现>JVM对volatile的实现<a hidden class=anchor aria-hidden=true href=#jvm对volatile的实现>#</a></h1><p><code>volatile</code>关键字只能用来修饰属性。对于属性有获取和设置两种操作，所以我们就从这两种操作入手分析一下JVM对volitile的处理。</p><p>上面的两种操作在字节码中对应着 <code>getfield</code>，<code>getstatic</code>和<code>putfield</code>，<code>putfield</code>这四种字节码。</p><p>我们去<code>bytecodeinterpreter.cpp</code>看一下对应的实现逻辑。(说明一下，JVM现在使用的是模板编译器的，但是字节码编译器可读性比较好，用来学习还是比较合适的)</p><p>我们找到上面几个字节码的执行位置</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>...
CASE(_getfield)<span style=color:#f92672>:</span>
CASE(_getstatic)<span style=color:#f92672>:</span>
{
   ...
   <span style=color:#66d9ef>if</span> (cache<span style=color:#f92672>-&gt;</span>is_volatile()) {
     <span style=color:#66d9ef>if</span> (support_IRIW_for_not_multiple_copy_atomic_cpu) {
       OrderAccess<span style=color:#f92672>::</span>fence();
     }
     ...
   }
  ...
}
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>...
CASE(_putfield)<span style=color:#f92672>:</span>
CASE(_putstatic)<span style=color:#f92672>:</span>
{
   ...
  <span style=color:#66d9ef>if</span> (cache<span style=color:#f92672>-&gt;</span>is_volatile()) {
    ...
    OrderAccess<span style=color:#f92672>::</span>storeload();
  } 
  ...
}
</code></pre></div><p>可以看到，在访问对象字段的时候，会先判断它是不是<code>volatile</code>的，如果是的话，并且当前CPU平台支持多核核atomic操作的话（现代的绝大多数的CPU都支持），然后就调用<code>OrderAccess::fence()</code>。
在设置字段的时候，会使用<code>OrderAccess::storeload();</code>
这两个就是JVM提供的内存屏障。</p><h2 id=jvm提供的内存屏障>JVM提供的内存屏障<a hidden class=anchor aria-hidden=true href=#jvm提供的内存屏障>#</a></h2><p>JVM中，所有内存屏障的使用都由OrderAccess来提供。在<code>OrderAccess.hpp</code>中说明了JVM提供的几种内存屏障。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=color:#75715e>//                Memory Access Ordering Model
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// This interface is based on the JSR-133 Cookbook for Compiler Writers.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// In the following, the terms &#39;previous&#39;, &#39;subsequent&#39;, &#39;before&#39;,
</span><span style=color:#75715e>// &#39;after&#39;, &#39;preceding&#39; and &#39;succeeding&#39; refer to program order.  The
</span><span style=color:#75715e>// terms &#39;down&#39; and &#39;below&#39; refer to forward load or store motion
</span><span style=color:#75715e>// relative to program order, while &#39;up&#39; and &#39;above&#39; refer to backward
</span><span style=color:#75715e>// motion.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// We define four primitive memory barrier operations.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// LoadLoad:   Load1(s); LoadLoad; Load2
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// Ensures that Load1 completes (obtains the value it loads from memory)
</span><span style=color:#75715e>// before Load2 and any subsequent load operations.  Loads before Load1
</span><span style=color:#75715e>// may *not* float below Load2 and any subsequent load operations.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// StoreStore: Store1(s); StoreStore; Store2
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// Ensures that Store1 completes (the effect on memory of Store1 is made
</span><span style=color:#75715e>// visible to other processors) before Store2 and any subsequent store
</span><span style=color:#75715e>// operations.  Stores before Store1 may *not* float below Store2 and any
</span><span style=color:#75715e>// subsequent store operations.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// LoadStore:  Load1(s); LoadStore; Store2
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// Ensures that Load1 completes before Store2 and any subsequent store
</span><span style=color:#75715e>// operations.  Loads before Load1 may *not* float below Store2 and any
</span><span style=color:#75715e>// subsequent store operations.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// StoreLoad:  Store1(s); StoreLoad; Load2
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// Ensures that Store1 completes before Load2 and any subsequent load
</span><span style=color:#75715e>// operations.  Stores before Store1 may *not* float below Load2 and any
</span><span style=color:#75715e>// subsequent load operations.
</span><span style=color:#75715e></span>
<span style=color:#75715e>// 省略 acquire and release 部分内容
</span><span style=color:#75715e></span>
<span style=color:#75715e>// Finally, we define a &#34;fence&#34; operation, as a bidirectional barrier.
</span><span style=color:#75715e>// It guarantees that any memory access preceding the fence is not
</span><span style=color:#75715e>// reordered w.r.t. any memory accesses subsequent to the fence in program
</span><span style=color:#75715e>// order. This may be used to prevent sequences of loads from floating up
</span><span style=color:#75715e>// above sequences of stores.
</span></code></pre></div><p>通过上面的注释我们知道，JVM根据<code>JSR-133 Cook Book</code>定义了4种基本的内存屏障操作，并由下面的几种作用。</p><table><thead><tr><th>内存屏障</th><th>使用方法</th><th>作用</th></tr></thead><tbody><tr><td>LoadLoad</td><td>Load1 LoadLoad Load2</td><td>确保Load1一定是在<br>Load2以及其后的指令之前完成</td></tr><tr><td>StoreStore</td><td>Store1 StoreStore Store2</td><td>确保 Store1 一定是在<br>Store2 以及其后的指令之前完成<br>（同时，Store1的写入数据会立即被其他 CPU看到</td></tr><tr><td>LoadStore</td><td>Load1 LoadStore Store2</td><td>确保 Load1 一定是在<br>Store2 以及其后的指令之前完成</td></tr><tr><td>StoreLoad</td><td>Store1 StoreLoad Load2</td><td>确保 Store1 一定在<br>Load2 以及其后的指令之前完成</td></tr></tbody></table><p>我们看到，在常见的4中基本内存屏障之后，还单独定义了<code>fence</code>操作，<code>fence</code>操作的功能可以说涵盖了上面的4中基本屏障。它可以保证<code>fence</code>前的任何操作op1都在op2之前完成。</p><p>JVM为每种屏障类型都定义了一个单独的方法，带代码中如果需要某种屏障可能直接调用。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++>  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>loadload</span>();
  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>storestore</span>();
  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>loadstore</span>();
  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>storeload</span>();

  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>acquire</span>();
  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>release</span>();
  <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span>     <span style=color:#a6e22e>fence</span>();
</code></pre></div><h1 id=volatile和硬件的关系>volatile和硬件的关系<a hidden class=anchor aria-hidden=true href=#volatile和硬件的关系>#</a></h1><p><code>volatile</code>在上面提到的两个功能，都是通过JVM定义的内存屏障来实现的。
而JVM定义的内存屏障可以理解是一个规范，它要求不管在什么平台上都要有同样的效
果。但是最终还是要依靠硬件来实现。所以们可以看到，在JVM中对于各种硬件平台都有对应的内存屏障实现。</p><p><img src=/img/fence.png alt></p><p>因为我们在服务器领域还是使用Linux比较多，而且大部分使用的是Intel的CPU，所以下面我们先关注一下<code>linux_x86</code>的实现</p><h2 id=linux-x86内存屏障实现>linux_x86内存屏障实现<a hidden class=anchor aria-hidden=true href=#linux-x86内存屏障实现>#</a></h2><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=color:#66d9ef>static</span> <span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>compiler_barrier</span>() {
  __asm__ <span style=color:#66d9ef>volatile</span> (<span style=color:#e6db74>&#34;&#34;</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;memory&#34;</span>);
}

<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>loadload()   { compiler_barrier(); }
<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>storestore() { compiler_barrier(); }
<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>loadstore()  { compiler_barrier(); }
<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>storeload()  { fence();            }

<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>acquire()    { compiler_barrier(); }
<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>release()    { compiler_barrier(); }

<span style=color:#66d9ef>inline</span> <span style=color:#66d9ef>void</span> OrderAccess<span style=color:#f92672>::</span>fence() {
  <span style=color:#66d9ef>if</span> (os<span style=color:#f92672>::</span>is_MP()) {
    <span style=color:#75715e>// always use locked addl since mfence is sometimes expensive
</span><span style=color:#75715e></span><span style=color:#75715e>#ifdef AMD64
</span><span style=color:#75715e></span>    __asm__ <span style=color:#66d9ef>volatile</span> (<span style=color:#e6db74>&#34;lock; addl $0,0(%%rsp)&#34;</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;cc&#34;</span>, <span style=color:#e6db74>&#34;memory&#34;</span>);
<span style=color:#75715e>#else
</span><span style=color:#75715e></span>    __asm__ <span style=color:#66d9ef>volatile</span> (<span style=color:#e6db74>&#34;lock; addl $0,0(%%esp)&#34;</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;cc&#34;</span>, <span style=color:#e6db74>&#34;memory&#34;</span>);
<span style=color:#75715e>#endif
</span><span style=color:#75715e></span>  }
  compiler_barrier();
}
</code></pre></div><p>我们看上面用到的<code>fence()</code>和<code>storeload()</code>方法，都其实最终调用的都是<code>fence()</code>方法。其他的都是调用的<code>compiler_barrier()</code>方法。
然后这里两个方法里面都是使用的内嵌汇编指令的方式，所以我们下来分析一下这个内嵌汇编指令的格式。</p><h3 id=内嵌汇编指令>内嵌汇编指令<a hidden class=anchor aria-hidden=true href=#内嵌汇编指令>#</a></h3><p>内嵌汇编指令的格式是</p><p><code>__asm__　__volatile__("Instruction List" : Output : Input : Clobber/Modify);</code></p><ul><li><code>__asm__</code>或<code>asm</code> 用来声明一个内联汇编表达式，所以任何一个内联汇编表达式都是以它开头的，是必不可少的。</li><li><span style=color:red><code>__volatile__</code>或<code>volatile</code> 是可选的。如果用了它，表示防止编译器对代码块进行优化。</span><ul><li>而这里的优化是针对代码块而言的，使用嵌入式汇编的代码分成三块：</li><li>嵌入式汇编之前的代码块</li><li>嵌入式汇编代码块</li><li>嵌入式汇编之后的c代码块</li><li>所以使用了<code>volatile</code>修饰的内嵌汇编的意思是，防止编译器对汇编代码块及前后的代码进行重排序等优化。</li></ul></li><li><code>Instruction List</code> 是要执行的汇编指令序列。它可以是空的。</li><li><code>Output</code>和<code>Input</code>是汇编指令中的输入和输出，都可以为空，这里我们不做过多分析</li><li><code>Clobber/Modify</code>是寄存器/内存修改标示。通知GCC当前内联汇编语句可能会对某些寄存器或内存进行修改,希望GCC在编译时能够将这一点考虑进去,这会对GCC在编译的时候有一些影响，但具体是什么影响我们就不深究了。</li></ul><hr><p>了解了内嵌汇编代码的格式，我们再来看上面的两个方法。</p><p><code>compiler_barrier()</code>：<code>__asm__ volatile ("" : : : "memory");</code></p><p>禁止编译器对汇编代码前后的代码块，进行重排序等优化，并且告诉编译器我修改了memory中的内容</p><p><code>fence()</code>:<code>__asm__ volatile ("lock; addl $0,0(%%esp)" : : : "cc", "memory");</code></p><p>禁止编译器对汇编代码前后的代码块，进行重排序等优化,并且执行</br><code>lock; addl $0,0(%%esp)</code>这条汇编指令，并且告诉编译器我修改了memory中的内容</p><h3 id=lock前缀指令>Lock前缀指令<a hidden class=anchor aria-hidden=true href=#lock前缀指令>#</a></h3><p>通过上面我们已经知道，JVM通过使用带有<code>volatile</code>关键字的内嵌汇编的方便，解决了编译器重排序的问题。那么CPU级别的重排序，和内存间的可见性是怎么实现的呢，下面我们就要用到Lock指令了。</p><p>我们看到在<code>fence()</code>方法内嵌的汇编代码中，使用了<code>lock前缀</code>指令，那<code>lock前缀</code>指令在这里起到的是什么作用呢。</p><h4 id=lock前缀指令的作用>Lock前缀指令的作用<a hidden class=anchor aria-hidden=true href=#lock前缀指令的作用>#</a></h4><p>在Intel 用户开发手册中关于<code>lock前缀</code>有这样的描述。</p><p><a href=https://www.intel.cn/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-system-programming-manual-325384.pdf>Intel开发手册下载地址</a></p><p><code>8.1- LOCKED ATOMIC OPERATIONS</code></p><blockquote><p>The processor uses three interdependent mechanisms for carrying out locked atomic operations:</p><p>• Guaranteed atomic operations</p><p>• Bus locking, using the LOCK# signal and the LOCK instruction prefix</p><p>• Cache coherency protocols that ensure that atomic operations can be carried out on cached data structures (cache lock); this mechanism is present in the Pentium 4, Intel Xeon, and P6 family processors</p></blockquote><p>意思是，我们有3种方式可以实现CPU的原子操作</p><ol><li>使用被保证的原子操作，比如读写1byte等</li><li>使用<code>lock</code>指令作为指令前缀</li><li>使用缓存一致性协议</li></ol><p>所以使用<code>lock</code>指令作为前缀，能够把它后面的一个或者几个操作&rsquo;包装&rsquo;为一个原子操作。不过你可能会想，那这么说来<code>lock</code>的作用和我们使用它的目前好像不大一样啊，可见性呢？重排序呢？别急我们继续看。</p><h4 id=lock前缀保证可见性>Lock前缀保证可见性<a hidden class=anchor aria-hidden=true href=#lock前缀保证可见性>#</a></h4><p><code>lock前缀</code>指令的实现方法，在早期CPU和现代CPU中有很大不同,我们还是引用开发手册中的描述</p><p><code>8.1.2-Bus Locking</code></p><blockquote><p>In the case of the Intel386, Intel486, and Pentium processors, explicitly locked instructions will result in the asser- tion of the LOCK# signal. It is the responsibility
of the hardware designer to make the LOCK# signal available in system hardware to control memory accesses among processors.</p><p>For the P6 and more recent processor families, if the memory area being accessed is cached internally in the processor, the LOCK# signal is generally not asserted;
instead, locking is only applied to the processor’s caches</p></blockquote><p>意思是，在早期的CPU中，当使用<code>lock前缀</code>指令时候，会导致产生一个<code>LOCK#</code>信号，通过总线锁定对应的内存，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放。
在后来的处理器的处理逻辑中，如果要操作的内存，已经cache到了处理器的缓存中，那么将不会产生<code>LOCK#</code>信号，则通过缓存一致性协议来完成原子性的保证。</p><p><code>8.1.4-Effects of a LOCK Operation on Internal Processor Caches</code></p><blockquote><p>For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is
cached in the processor that is performing the LOCK operation as write-back memory and is completely contained
in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow it’s cache coherency mechanism to ensure that the operation is carried out atomically. This
operation is called “cache locking.” The cache coherency mechanism automatically prevents two or more processors that have cached the same area of memory from simultaneously modifying data in that area.</p></blockquote><p>意思是：<span style=color:red>在LOCK操作中被锁定的内存区域是缓存在执行<code>LOCK</code>操作的处理器中，作为回写存储器，并且完全包含在缓存行中。在一个缓存行中，处理器可能不会在总线上发出<code>LOCK#</code>信号。相反，它将在内部修改内存位置，并允许它的缓存一致性机制确保该操作是原子式进行的。这种操作被称为&rdquo;高速缓存锁定&rdquo;。缓存一致性机制会自动防止两个或更多的处理器在缓存同一区域的内存上同时修改该区域的数据。</span></p><p>显而易见，使用<code>总线锁定</code>的方式代价要大得多。不过目前在大多数情况下，我们在使用<code>lock</code>指令的时候，都是通过缓存一致性协议来保证的后面操作的原子性操作。但是有一些情况同样也会导致不能使用<code>高速缓存锁定</code>，而只能使用<code>总线锁定</code>，比如涉及到的数据跨越多个CacheLine，CPU不支持缓存锁定等。</p><ul><li>在 Pentium 和早期的 IA-32 处理器中，lock 前缀会使处理器执行当前指令时产生一个 LOCK# 信号，会对总线进行锁定，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放</li><li>后来的处理器，加锁操作是由高速缓存锁代替总线锁来处理。 因为锁总线的开销比较大，锁总线期间其他CPU没法访问内存。 这种场景多缓存的数据一致通过缓存一致性协议(MESI)来保证。</li></ul><p>所以总结一下，当我们使用<code>lock前缀</code>指令的时候会发生这两件事</p><ul><li>要操作的数据在缓存中，会导致其他CPU的缓存行失效</li><li>如果数据不再内存中，则会使用总线锁定，把内存中的数据读入或者写出到内存。同时也会导致其他CPU的缓存行失效。</li></ul><p>所以使用<code>lock前缀</code>指令，会通过触发缓存一致性协议导致关联的缓存行失效，从而保证可见性。</p><p>可见性我们知道了，那么防止指令重排序的作用呢？我们继续在用户手册中寻找一下答案。</p><h4 id=lock前缀防止指令重排>Lock前缀防止指令重排<a hidden class=anchor aria-hidden=true href=#lock前缀防止指令重排>#</a></h4><p><code>8.2.5 Strengthening or Weakening the Memory-Ordering Model</code></p><blockquote><p>The Intel 64 and IA-32 architectures provide several mechanisms for strengthening or weakening the memory-
ordering model to handle special programming situations. These mechanisms include:</p><p>• The I/O instructions, locking instructions, the LOCK prefix, and serializing instructions force stronger
ordering on the processor.</p><p>• The SFENCE instruction (introduced to the IA-32 architecture in the Pentium III processor) and the LFENCE
and MFENCE instructions (introduced in the Pentium 4 processor) provide memory-ordering and serialization
capabilities for specific types of memory operations.</p><p>&mldr; 省略部分</p><p>Synchronization mechanisms in multiple-processor systems may depend upon a strong memory-ordering model.
Here, a program can use a locking instruction such as the XCHG instruction or the LOCK prefix to ensure that
a read-modify-write operation on memory is carried out atomically. Locking operations typically operate like
I/O operations in that they wait for all previous instructions to complete and for all buffered writes to
drain to memory</p></blockquote><p>意思是，Intel处理器提供了几种机制用来加强或者削弱内存排序。其中使用IO相关指令、锁定指令、LOCK前缀指令、序列化相关指令都能够强化
排序。(<span style=color:red>这里强化的意思是，更加按照指令流的顺序来执行,也就是减少处理器的重排序</span>)</p><p>在程序中可以使用锁定指令，或者<code>lock前缀</code>指令来强化排序，它们会等待所有先前的指令完成，并等待所有缓冲的写操作耗尽到内存中。</p><p>所以我们看到，JVM通过内嵌<code>lock前缀</code>的汇编指令，保证了可见性和防止了内存重排序。</p><h3 id=lock前缀指令的其他应用>Lock前缀指令的其他应用<a hidden class=anchor aria-hidden=true href=#lock前缀指令的其他应用>#</a></h3><p>我们经常使用的CAS的底层，也是使用<code>lock前缀</code>实现的，使用<code>lock</code>指令保证了后面的操作的原子性。</p><h3 id=为何x86只实现了storeload内存屏障>为何x86只实现了storeload内存屏障<a hidden class=anchor aria-hidden=true href=#为何x86只实现了storeload内存屏障>#</a></h3><p>还有一点我们在上面的x86的实现中看到，只有<code>fence()</code>方法，和<code>storeload()</code>方法使用<code>lock前缀</code>指令，其他的几种都是只是实现了编译器级别的内存屏障，也就是只能防止编译器的指令重排序。这是为什么呢？</p><p>同样我们在操作手册中寻找一下答案，在操作手册的 <code>8.2.3-Examples Illustrating the Memory-Ordering</code>章节，说明x86处理器对<code>store</code>和<code>load</code>指令的重排序情况</p><ul><li>8.2.3.2 Neither Loads Nor Stores Are Reordered with Like Operations</li><li>8.2.3.3 Stores Are Not Reordered With Earlier Loads</li><li>8.2.3.4 Loads May Be Reordered with Earlier Stores to Different Locations</li></ul><p>意思是
- <code>load</code>指令和<code>store</code>指令，都不能喝同类型的指令之间发生重排序，也就是 load1,load2 和 store1，store2 是不会发生重排序的
- <code>store</code>指令和前面出现的<code>load</code>指令，不会重排序，也就是 load1,store2 不会发生重排序。
- <code>load</code>指令，和它前面出现的<code>store</code>指令之间可能会发生重排序。</p><p>看到这，我们能知道，x86的CPU，在不添加任何内存屏障的情况下，已经支持了<code>loadload</code>,<code>storestore</code>,<code>loadstore</code>屏障了。只有<code>storeload</code>这种需要单独添加内存屏障来保证不会重排序。</p><p>所以对于x86处理器原生支持的3种屏障，只需要保证编译器不会发生重排序即可。</p><p>所以说，volatile的实现和硬件平台关系非常密切。下面这个是在不同硬件下，发生重排序的情况。</p><table><thead><tr><th>处理器</th><th>Load-Load</th><th>Load-Store</th><th>Store-Store</th><th>Store-Load</th><th>数据依赖</th></tr></thead><tbody><tr><td>x86</td><td>N</td><td>N</td><td>N</td><td>Y</td><td>N</td></tr><tr><td>PowerPC</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>ia64</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr></tbody></table><p>我们看到，x86在<code>loadload</code>,<code>loadStore</code>.<code>storestore</code> 和有数据依赖的时候不会发生重排序。
另外两种平台，只有在有数据依赖的时候不会发生重排序。</p><p>所以JVM需要根据不同平台来进行不同的处理。</p><h3 id=为何x86下jvm使用lock前缀实现内存屏障>为何x86下JVM使用LOCK前缀实现内存屏障<a hidden class=anchor aria-hidden=true href=#为何x86下jvm使用lock前缀实现内存屏障>#</a></h3><p>在Intel的处理器平台下内存屏障分为两类：</p><ul><li>本身是内存屏障，比如“lfence”，“sfence”和“mfence”汇编指令</li><li>本身不是内存屏障，但是被LOCK指令前缀修饰，其组合成为一个内存屏障。在X86指令体系中，其中一类内存屏障常使用“LOCK指令前缀加上一个空操作”方式实现，比如<code>lock addl $0x0,(%esp)</code></li></ul><p>所以有一个疑问，为什么JVM选择使用<code>lock前缀</code>指令来实现内存屏障而不使用专门的内存屏障指令呢？</p><p>我在JVM的源码中搜索了一下<code>mfence</code>,搜索到了下面几段注释</p><p><code>macroAssembler_x86.cpp</code></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=color:#75715e>// We have a classic Dekker-style idiom:
</span><span style=color:#75715e>//    ST m-&gt;_owner = 0 ; MEMBAR; LD m-&gt;_succ
</span><span style=color:#75715e>// There are a number of ways to implement the barrier:
</span><span style=color:#75715e>// (1) lock:andl &amp;m-&gt;_owner, 0
</span><span style=color:#75715e>//     is fast, but mask doesn&#39;t currently support the &#34;ANDL M,IMM32&#34; form.
</span><span style=color:#75715e>//     LOCK: ANDL [ebx+Offset(_Owner)-2], 0
</span><span style=color:#75715e>//     Encodes as 81 31 OFF32 IMM32 or 83 63 OFF8 IMM8
</span><span style=color:#75715e>// (2) If supported, an explicit MFENCE is appealing.
</span><span style=color:#75715e>//     In older IA32 processors MFENCE is slower than lock:add or xchg
</span><span style=color:#75715e>//     particularly if the write-buffer is full as might be the case if
</span><span style=color:#75715e>//     if stores closely precede the fence or fence-equivalent instruction.
</span><span style=color:#75715e>//     See https://blogs.oracle.com/dave/entry/instruction_selection_for_volatile_fences
</span><span style=color:#75715e>//     as the situation has changed with Nehalem and Shanghai.
</span><span style=color:#75715e>// (3) In lieu of an explicit fence, use lock:addl to the top-of-stack
</span><span style=color:#75715e>//     The $lines underlying the top-of-stack should be in M-state.
</span><span style=color:#75715e>//     The locked add instruction is serializing, of course.
</span><span style=color:#75715e>// (4) Use xchg, which is serializing
</span><span style=color:#75715e>//     mov boxReg, 0; xchgl boxReg, [tmpReg + Offset(_owner)-2] also works
</span><span style=color:#75715e>// (5) ST m-&gt;_owner = 0 and then execute lock:orl &amp;m-&gt;_succ, 0.
</span><span style=color:#75715e>//     The integer condition codes will tell us if succ was 0.
</span><span style=color:#75715e>//     Since _succ and _owner should reside in the same $line and
</span><span style=color:#75715e>//     we just stored into _owner, it&#39;s likely that the $line
</span><span style=color:#75715e>//     remains in M-state for the lock:orl.
</span><span style=color:#75715e>//
</span><span style=color:#75715e>// We currently use (3), although it&#39;s likely that switching to (2)
</span><span style=color:#75715e>// is correct for the future.
</span></code></pre></div><p><code>orderAccess_linux_x86.inline.hpp</code></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=color:#75715e>// always use locked addl since mfence is sometimes expensive
</span></code></pre></div><p>大概意思就是说，<code>mfence</code>目前有几个缺点</p><p>1.并不是所有cpu都支持这个指令。
2. 在最早前的CPU中性能比<code>lock前缀</code>差一些。
3. 有时<code>mfence</code>的性能损耗比较严重</p><p>所以基于以上考虑，目前还是使用<code>lock前缀</code>(我查看的jvm源码是jdk11的)，但是未来很有可能改为使用<code>mfence</code>指令。</p><p><a href=https://blogs.oracle.com/dave/instruction-selection-for-volatile-fences-%3a-mfence-vs-lock%3aadd>Instruction selection for volatile fences : MFENCE vs LOCK:ADD</a></p><h2 id=缓存一致性协议>缓存一致性协议<a hidden class=anchor aria-hidden=true href=#缓存一致性协议>#</a></h2><p>在上面我们不止一次的提到了缓存一致性协议，那么缓存一致性协议具体是什么样的呢？下面我们来简单的了解一下。</p><p>现在处理器处理能力上要远胜于主内存（DRAM），主内存执行一次内存读写操作，所需的时间可能足够处理器执行上百条的指令，为了弥补处理器与主内存处理能力之间的鸿沟，引入了高速缓（Cache),来保存一些CPU从内存读取的数据，下次用到该数据直接从缓存中获取即可，以加快读取速度，随着多核时代的到来,每块CPU都有多个内核，每个内核都有自己的缓存，这样就会出现同一个数据的副本就会存在于多个缓存中，在读写的时候就会出现数据 不一致的情况。</p><h3 id=缓存行>缓存行<a hidden class=anchor aria-hidden=true href=#缓存行>#</a></h3><p>数据在缓存中不是以独立的项来存储的，它不是一个单独的变量，也不是一个单独的指针,它在数据缓存中以缓存行存在的，也称缓存行为缓存条目。目前主流的CPU Cache的Cache Line大小通常是<code>64字节</code>，并且它有效地引用主内存中的一块地址。</p><h4 id=局部性原理>局部性原理<a hidden class=anchor aria-hidden=true href=#局部性原理>#</a></h4><p>局部性原理：在CPU访问存储设备时，无论是存取数据或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。</p><ul><li>时间局部性（<code>Temporal Locality</code>）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如程序中的循环、递归对数据的循环访问，
主要体现在指令读取的局部性</li><li>空间局部性（<code>Spatial Locality</code>）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如程序中的数据组的读取或者对象的连续创建，
对内存都是顺序的读写，主要体现在对程序数据引用的局部性</li></ul><h3 id=mesi协议>MESI协议<a hidden class=anchor aria-hidden=true href=#mesi协议>#</a></h3><p><code>MESI</code>是众多缓存一致性协议中的一种，也在Intel系列中广泛使用的缓存一致性协议
缓存行（Cache line）的状态有<code>Modified</code>、<code>Exclusive</code>、 <code>Share</code> 、<code>Invalid</code>，而MESI
命名正是以这4中状态的首字母来命名的。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一。</p><table><thead><tr><th>状态</th><th>描述</th><th align=center>监听任务</th></tr></thead><tbody><tr><td>M</td><td>该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</td><td align=center>缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</td></tr><tr><td>E</td><td>该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。</td><td align=center>缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</td></tr><tr><td>S</td><td>该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。</td><td align=center>缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）</td></tr><tr><td>I</td><td>该Cache line无效。</td><td align=center>无</td></tr></tbody></table><h4 id=监听任务>监听任务<a hidden class=anchor aria-hidden=true href=#监听任务>#</a></h4><ul><li>一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回主内存</li><li>一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。</li><li>一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S</li></ul><h4 id=嗅探协议>嗅探协议<a hidden class=anchor aria-hidden=true href=#嗅探协议>#</a></h4><p>上面提到的监听任务大多数都是通过嗅探(snooping)协议来完成的</p><blockquote><p>“窥探”背后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源，
所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道，
而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知，
它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。</p></blockquote><h4 id=mesi读取缓存流程>MESI读取缓存流程<a hidden class=anchor aria-hidden=true href=#mesi读取缓存流程>#</a></h4><p>CPU1需要读取数据X，会根据数据的地址在自己的缓存L1A中找到对应的缓存行,然后判断缓存行的状态</p><ul><li>如果缓存行的状态是<code>M、E、S</code>，说明该缓存行的数据对于当前读请求是可用的，则可以直接使用</li><li>如果缓存行的状态是I，则说明该缓存行的数据是无效的，则CPU1会向总线发送<code>Read</code>消息，说’我现在需要地址A的数据，谁可以提供？‘，其它处理器会CPU2监听总线上的消息，收到消息后，会从消息中解析出需要读取的地址，
然后在自己缓存中查找缓存行，这时候根据找到缓存行的状态会有以下几种情况<ul><li>状态为<code>S/E</code> , CPU2会构造<code>Read Response</code>消息，将相应缓存行中的数据放到消息中，发送到总线同时更新自己缓存行的状态为<code>S</code>，CPU1收到响应消息后，会将消息中的数据存入相应的缓存行中，同时更新缓存行的状态为<code>S</code></li><li>状态为<code>M</code>，会先将自己缓存行中的数据写入主内存，并响应<code>Read Response</code>消息同时将L1B中的相应的缓存行状态更新为<code>S</code></li><li>状态为I或者在自己的缓存中不存在X的数据，那么主内存会构造<code>Read Response</code>消息，从主内存读取包含指定地址的块号数据放入消息（缓存行大小和内存块大小一致所以可以存放的下），并将消息发送到总线</li></ul></li><li>CPU1获接收到总线消息之后，解析出数据保存在自己的缓存中</li></ul><h4 id=mesi写缓存流程>MESI写缓存流程<a hidden class=anchor aria-hidden=true href=#mesi写缓存流程>#</a></h4><p>CPU1 需要写入数据X</p><ul><li>为<code>E/M</code>时，说明当前CPU1已经拥有了相应数据的所有权，此时CPU1会直接将数据写入缓存行中，并更新缓存行状态为<code>M</code>，此时不需要向总线发送任何消息。</li><li><code>S</code>时，说明数据被共享，其它CPU中有可能存有该数据的副本，则CPUA向总线发送<code>Invalidate</code> 消息以获取数据的所有权，其它处理器（CPU2)收到<code>Invalidate</code>消息后,会将其高速缓存中相应的缓存行状态更新为<code>I</code>，表示已经逻辑删除相应的副本数据，
并回复<code>Invalidate Acknowledge</code>消息，CPU1收到所有处理器的响应消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为<code>E</code>，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为<code>M</code></li><li><code>I</code>时，说明当前处理器中不包含该数据的有效副本，则CPU1向总线发送<code>Read Invalidate</code>消息<code>，表明</code>我要读数据X，希望主存告诉我X的值，同时请示其它处理器将自己缓存中包含该数据的缓存行并且状态不是I的缓存行置为无效`</li><li>其它处理器（CPUB)收到<code>Invalidate</code>消息后，如果缓存行不为<code>I</code>的话，会将其高速缓存中相应的缓存行状态更新为<code>I</code>，表示已经逻辑删除相应的副本数据，并回复<code>Invalidate Acknowledge消息</code></li><li>主内存收到<code>Read</code>消息后，会响应<code>Read Response</code>消息将需要读取的数据告诉CPU1</li><li>CPU1收到所有处理器的<code>Invalidate Acknowledge</code>消息和主内存的<code>Read Response</code>消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为<code>E</code>，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为<code>M</code></li></ul><h4 id=mesi的状态变化>MESI的状态变化<a hidden class=anchor aria-hidden=true href=#mesi的状态变化>#</a></h4><p><img src=/img/20200220235854870.png alt></p><ul><li>Local Read：表示本内核读本Cache中的值</li><li>Local Write：表示本内核写本Cache中的值</li><li>Remote Read：表示其它内核读其Cache中的值</li><li>Remote Write：表示其它内核写其Cache中的值</li><li>箭头表示本Cache line状态的迁移，环形箭头表示状态不变</li></ul><h3 id=storebuffer和invalidate-queue>StoreBuffer和Invalidate Queue<a hidden class=anchor aria-hidden=true href=#storebuffer和invalidate-queue>#</a></h3><p><img src=/img/aHR0cDovL3d3dy53b3dvdGVjaC5uZXQvY29udGVudC91cGxvYWRmaWxlLzIwMTUxMi85N2FiZTRkOTNlNmYwNjM5N2FjMWNjZDQ1OWNhNzVlOTIwMTUxMjEwMTExMDM3LmdpZg.png alt></p><p>说了缓存一致性协议，好像就能够解决问题了，但是，在这里你会发现，又有新的问题出现了。MESI协议中：当cpu0写数据到本地cache的时候，如果不是M或者E状态，需要发送一个<code>invalidate</code>消息给cpu1，只有收到cpu1的ack之后cpu0才能继续执行，
在这个过程中cpu0需要等待，这大大影响了性能。于是CPU设计者引入了<code>Store Buffer</code>，这个buffer处于CPU与cache之间。</p><p><img src=/img/storebuffer1.png alt></p><p><code>Store Buffer</code>增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给缓存一致性协议。但是<code>Store Buffer</code>仍然引入了一些复杂性,那就是缓存数据和<code>Store Buffer</code>数据不一致的问题。</p><h4 id=store-forwarding>Store Forwarding<a hidden class=anchor aria-hidden=true href=#store-forwarding>#</a></h4><p>为了解决上面的问题，修改为了下面的架构，这种设计叫做<code>Store forwarding</code>，当CPU执行load操作的时候，不但要看cache，还有看<code>Store Buffer</code>是否有内容，如果<code>Store Buffer</code>有该数据，那么就采用<code>Store Buffer</code>中的值。</p><p><img src=/img/20200221154806152.png alt></p><h4 id=invalid-queue>Invalid Queue<a hidden class=anchor aria-hidden=true href=#invalid-queue>#</a></h4><p>同样的问题也会出现在其他线程发送<code>Invalidate Acknowledge</code>消息的时候，通常<code>Invalidate Cacheline</code>操作没有那么快完成,尤其是在Cache繁忙的时候，这时CPU往往进行密集的<code>load</code>和<code>store</code>的操作，而来自其他CPU的，
对本CPU Cache的操作需要和本CPU的操作进行竞争，只有完成了<code>invalidate</code>操作之后，本CPU才会发生<code>invalidate acknowledge</code>。此外，如果短时间内收到大量的<code>invalidate</code>消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。
为了解决这个问题，引入了<code>Invalid Queue</code>,系统架构如下。</p><p><img src=/img/invaidQueue.png alt></p><p>有了<code>Invalidate Queue</code>的CPU，在收到<code>invalidate</code>消息的时候首先把它放入<code>Invalidate Queue</code>，同时立刻回送<code>acknowledge</code> 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候，
那么CPU必须首先去<code>Invalidate Queue</code>中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到<code>Invalidate Queue</code>中的cacheline被处理完之后再发送。</p><p>另外说一下，x86的CPU不含有 <code>invalidate queue</code>,这也是上面提到的，x86平台下只有<code>storeload</code>会发生重排序的原因。</p><h2 id=乱序执行-重排序>乱序执行/重排序<a hidden class=anchor aria-hidden=true href=#乱序执行-重排序>#</a></h2><p>了解完上面的这些知识，我们再来整体的总结一下乱序执行或者说重排序的问题。</p><p>重排序从发生的环节上来分，可以分为2大类</p><ul><li>编译器重排序</li><li>处理器重排序</li></ul><p>下面我们分别来说一下。</p><h3 id=as-if-serial语义>as-if-serial语义<a hidden class=anchor aria-hidden=true href=#as-if-serial语义>#</a></h3><p>无论是处理器还是编译器,不管怎么重排都要保证(单线程)程序的执行结果不能被改变,这就是as-if-serial语义。</p><h3 id=编译器重排序>编译器重排序<a hidden class=anchor aria-hidden=true href=#编译器重排序>#</a></h3><p>编译器重排序：编译器会对高级语言的代码进行分析，当编译器认为你的代码可以优化的话，编译器会选择对代码进行优化，重新排序，然后生成汇编代码。当然这个优化是有原则的，原则就是在保证单线程下的执行结果不变。</p><p>编译器在编译时候，能够获得最底层的信息，比如要读写哪个寄存器，读写哪块内存。所以编译就根据这些信息对代码进行优化，包括不限于减少无用变量、修改代码执行顺序等等。
<code>优秀的编译器优化能够提升程序在CPU上的运行性能，更好的使用寄存器以及现代处理器的流水线技术，减少汇编指令的数量，降低程序执行需要的CPU周期，减少CPU读写主存的时间</code>。</p><p>当然，编译器在优化的时候，只能保证在单线程下的结果，在多线程情况下，不加限制就可能会导致错误的结果。所以在多线程情况就需要开发者对编译器进行适当的指引，防止编译器进行错误的优化。</p><h3 id=处理器乱序>处理器乱序<a hidden class=anchor aria-hidden=true href=#处理器乱序>#</a></h3><p>CPU接受到编译器编译的指令，通常为了为了提高<code>CPU流水线的工作效率</code>，也会对指令进行分析，然后进行乱序执行。当然不同的硬件进行乱序的规则也不大相同，我们还把上面的表格哪来参考一下。</p><table><thead><tr><th>处理器</th><th>Load-Load</th><th>Load-Store</th><th>Store-Store</th><th>Store-Load</th><th>数据依赖</th></tr></thead><tbody><tr><td>x86</td><td>N</td><td>N</td><td>N</td><td>Y</td><td>N</td></tr><tr><td>PowerPC</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>ia64</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr></tbody></table><p>我们对CPU发生乱序执行情况进行一下分类</p><ul><li>在没有数据依赖的情况下，发生的乱序。</li><li>CPU顺序执行，但是因为<code>StoreBuffer</code>和 <code>Invalidate Queue</code>的存在产生了乱序的效果。<ul><li>关于<code>StoreBuffer</code>和 <code>Invalidate Queue</code>引起的乱序稍微复杂一点，就不在这里展开了，有兴趣的同学可以查看 <a href="https://blog.csdn.net/reliveIT/article/details/105902477?spm=1001.2014.3001.5501">Why Memory Barriers</a></li></ul></li></ul><p>同样上面的这些乱序，都是能够保证在单线程的情况下执行结果的正确行。在多线程环境下，如果需要保证有序，那就需要开发者使用CPU提供的<code>内存屏障</code>指令，或者带有内存屏障作用的其他指令，来告诉CPU不要进行乱序执行了。</p><h2 id=伪共享问题>伪共享问题<a hidden class=anchor aria-hidden=true href=#伪共享问题>#</a></h2><p>伪共享的意思是，我们在开发中定义了共享变量，然后在多个线程中访问。看起来像是这个变量在内存中，多个CPU共享，但是实际情况是每个CPU都访问自己的缓存，并不是直接访问的整个变量。</p><p>伪共享导致的问题就是，如果几个字段因为局部性原理，被加载到了同一个缓存行中，然后被几个线程分别访问。这时就会因为MESI协议，导
致缓存频繁失效，从而CPU每次只能从内存中加载数据，从而降低程序的执行效率。</p><p>下面我们通过代码验证一下，
在下面代码中我们我们定义了两个长度为2的long数组，其中一个使用<code>volatile</code>关键字修饰，另一个没有。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>FalseShareTest</span> <span style=color:#f92672>{</span>
    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>final</span> <span style=color:#66d9ef>long</span> CYCLE_TIMES <span style=color:#f92672>=</span> 10_0000_0000L<span style=color:#f92672>;</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>volatile</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[]</span> array <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[</span>2<span style=color:#f92672>];</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[]</span> array1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[</span>2<span style=color:#f92672>];</span>

    <span style=color:#75715e>/**
</span><span style=color:#75715e>     * 启动2个线程修改volatile数组的第1，2位 1000w次
</span><span style=color:#75715e>     */</span>
    <span style=color:#a6e22e>@Test</span>
    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>test</span><span style=color:#f92672>()</span> <span style=color:#66d9ef>throws</span> InterruptedException <span style=color:#f92672>{</span>
        Thread t1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array<span style=color:#f92672>[</span>0<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        Thread t2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array<span style=color:#f92672>[</span>1<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        <span style=color:#66d9ef>long</span> start <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        <span style=color:#66d9ef>long</span> end <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;Duration: &#34;</span> <span style=color:#f92672>+</span> <span style=color:#f92672>(</span>end <span style=color:#f92672>-</span> start<span style=color:#f92672>)</span> <span style=color:#f92672>/</span> 100_0000<span style=color:#f92672>);</span>
    <span style=color:#f92672>}</span>


    <span style=color:#75715e>/**
</span><span style=color:#75715e>     * 启动2个线程修改非volatile数组的第1，2位 1000w次
</span><span style=color:#75715e>     */</span>
    <span style=color:#a6e22e>@Test</span>
    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>test1</span><span style=color:#f92672>()</span> <span style=color:#66d9ef>throws</span> InterruptedException <span style=color:#f92672>{</span>
        Thread t1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array1<span style=color:#f92672>[</span>0<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        Thread t2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array1<span style=color:#f92672>[</span>1<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        <span style=color:#66d9ef>long</span> start <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        <span style=color:#66d9ef>long</span> end <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;Duration: &#34;</span> <span style=color:#f92672>+</span> <span style=color:#f92672>(</span>end <span style=color:#f92672>-</span> start<span style=color:#f92672>)</span> <span style=color:#f92672>/</span> 100_0000<span style=color:#f92672>);</span>
    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span></code></pre></div><p>每个方法我们都执行5次看一下耗时</p><pre><code>volatile数组
Duration: 3281
Duration: 3052
Duration: 3071
Duration: 3079
Duration: 3111
非volatile数组
Duration: 358
Duration: 347
Duration: 552
Duration: 545
Duration: 548</code></pre><p>我们发现修改volatile修饰的数组，消耗的时间是没有volatile数组的10倍。
这个时间花在什么地方呢。
我们来分析一下。</p><ul><li>缓存行的大小一般为64字节</li><li>定义的数据长度为2，类型是long，所以数据大小就是16字节。根据局部性原理，所以他们很有可能放到了同一个缓存行中</li><li>两个线程并发的读取修改第一个数据和第二个数据，这里我们可以理解为CPU1修改第一个数据X，CPU2修改第二个数据Y</li><li>CPU1修改了X，因为数据定义为volatile，所以必须保证多线程之间的可见性，所以会强制使用<code>lock前缀</code>指令，让CPU2中对应的缓存行失效</li><li>CPU2想要修改Y，这时候发现这个缓存行已经失效了，所以需要重新从内存中读取，然后修改，同时又会导致CPU1的缓存行失效。</li><li>所以耗时发生在，volatile的可见性要求导致缓存行一直失效，需要不断的从内存中读取所导致。</li><li>而非volatile数据，并没有可见性要求，并且因为store buffer的存在，缓存并不会立即失效，所以效率要高的多。</li></ul><h2 id=volatile的优化>volatile的优化<a hidden class=anchor aria-hidden=true href=#volatile的优化>#</a></h2><p>知道了上面伪共享和volatile带来的性能问题，那么有没有办法进行优化呢？
答案肯定是有的，我们思考一下，上面的主要问题是，两个数据都存在于同一个缓存行中，对任何一个字段的读写，都会导致缓存行失效，那么我们把这两个数据分开，放到不同的缓存行呢？</p><p>我们把上面的代码改一下，把数组长度改为16，两个线程分别修改第1个，和第9个，因为缓存行是64字节，long是8个字节，所以第1个和第9个肯定不会再同一个缓存行中。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>FalseShareTest</span> <span style=color:#f92672>{</span>
    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>final</span> <span style=color:#66d9ef>long</span> CYCLE_TIMES <span style=color:#f92672>=</span> 10_0000_0000L<span style=color:#f92672>;</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>volatile</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[]</span> array <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[</span>2<span style=color:#f92672>];</span>

    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>volatile</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[]</span> array1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> <span style=color:#66d9ef>long</span><span style=color:#f92672>[</span>16<span style=color:#f92672>];</span>

    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>test</span><span style=color:#f92672>()</span> <span style=color:#66d9ef>throws</span> InterruptedException <span style=color:#f92672>{</span>
        Thread t1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array<span style=color:#f92672>[</span>0<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        Thread t2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array<span style=color:#f92672>[</span>1<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        <span style=color:#66d9ef>long</span> start <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        <span style=color:#66d9ef>long</span> end <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;Duration: &#34;</span> <span style=color:#f92672>+</span> <span style=color:#f92672>(</span>end <span style=color:#f92672>-</span> start<span style=color:#f92672>)</span> <span style=color:#f92672>/</span> 100_0000<span style=color:#f92672>);</span>
    <span style=color:#f92672>}</span>


    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>test1</span><span style=color:#f92672>()</span> <span style=color:#66d9ef>throws</span> InterruptedException <span style=color:#f92672>{</span>
        Thread t1 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array1<span style=color:#f92672>[</span>0<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        Thread t2 <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> Thread<span style=color:#f92672>(()</span> <span style=color:#f92672>-&gt;</span> <span style=color:#f92672>{</span>
            <span style=color:#66d9ef>for</span> <span style=color:#f92672>(</span><span style=color:#66d9ef>long</span> i <span style=color:#f92672>=</span> 0<span style=color:#f92672>;</span> i <span style=color:#f92672>&lt;</span> CYCLE_TIMES<span style=color:#f92672>;</span> i<span style=color:#f92672>++)</span> <span style=color:#f92672>{</span>
                array1<span style=color:#f92672>[</span>8<span style=color:#f92672>]</span> <span style=color:#f92672>=</span> i<span style=color:#f92672>;</span>
            <span style=color:#f92672>}</span>
        <span style=color:#f92672>});</span>
        <span style=color:#66d9ef>long</span> start <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>start</span><span style=color:#f92672>();</span>
        t1<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        t2<span style=color:#f92672>.</span><span style=color:#a6e22e>join</span><span style=color:#f92672>();</span>
        <span style=color:#66d9ef>long</span> end <span style=color:#f92672>=</span> System<span style=color:#f92672>.</span><span style=color:#a6e22e>nanoTime</span><span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;Duration: &#34;</span> <span style=color:#f92672>+</span> <span style=color:#f92672>(</span>end <span style=color:#f92672>-</span> start<span style=color:#f92672>)</span> <span style=color:#f92672>/</span> 100_0000<span style=color:#f92672>);</span>
    <span style=color:#f92672>}</span>

    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>main</span><span style=color:#f92672>(</span>String<span style=color:#f92672>[]</span> args<span style=color:#f92672>)</span> <span style=color:#66d9ef>throws</span> InterruptedException <span style=color:#f92672>{</span>
        FalseShareTest falseShareTest <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> FalseShareTest<span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;未优化&#34;</span><span style=color:#f92672>);</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test</span><span style=color:#f92672>();</span>
        System<span style=color:#f92672>.</span><span style=color:#a6e22e>out</span><span style=color:#f92672>.</span><span style=color:#a6e22e>println</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;优化后&#34;</span><span style=color:#f92672>);</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test1</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test1</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test1</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test1</span><span style=color:#f92672>();</span>
        falseShareTest<span style=color:#f92672>.</span><span style=color:#a6e22e>test1</span><span style=color:#f92672>();</span>
    <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span></code></pre></div><p>执行结果</p><pre><code>未优化
Duration: 6589
Duration: 7006
Duration: 7527
Duration: 7278
Duration: 7813
优化后
Duration: 1961
Duration: 2011
Duration: 1974
Duration: 2056
Duration: 1953</code></pre><p>我们发现把数据移动到不同的缓存行之后，运行时间缩短了三分之二左右。</p><p>所以对volatile的优化的主要逻辑就是，让volatile的字段，自己处于一个缓存行中，不要让其他字段的变化，影响volatile变量所处缓存行的状态。</p><h3 id=false-share的优化案例>false share的优化案例<a hidden class=anchor aria-hidden=true href=#false-share的优化案例>#</a></h3><p>这种优化，在很多高性能的框架中还是挺常见的。比如在caffeine中就有这样的应用</p><p><img src=/img/falseshare.png alt></p><p>依据JVM对象继承关系中父类属性与子类属性，内存地址连续排列布局,PadReadCounter中的字段会作为前置填充，PadWriteCounter中的字段会作为后置填充。
保证readCounter字段能够独占一个缓存行。</p><p>我们看到这里前后各使用的15个long字段作为填充，这应该是为了防止不同的系统下缓存行大小不一致的情况。</p><h3 id=sun-misc-contended注解>@sun.misc.Contended注解<a hidden class=anchor aria-hidden=true href=#sun-misc-contended注解>#</a></h3><h1 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h1><p><a href=https://www.pdai.tech/md/java/thread/java-thread-x-key-volatile.html>[关键字: volatile详解]</a></p><p><a href=https://dslztx.github.io/blog/2019/06/08/%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4%E7%9A%84LOCK%E6%8C%87%E4%BB%A4%E5%89%8D%E7%BC%80/>[汇编指令的LOCK指令前缀]</a></p><p><a href=https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/>[一文了解内存屏障]</a></p><p><a href=https://blog.csdn.net/qq_26222859/article/details/52240256>[volatile与内存屏障]</a></p><p><a href=https://segmentfault.com/a/1190000022508589>[内存屏障及其在JVM内的应用]</a></p><p><a href=https://www.cnblogs.com/yanlong300/p/8986041.html>[CPU缓存一致性协议MESI]</a></p><p><a href=https://zh.wikipedia.org/wiki/X86>[x86架构]</a></p><p><a href=https://albk.tech/%E8%81%8A%E8%81%8A%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE.html>[聊聊缓存一致性协议]</a></p><p><a href=https://zhuanlan.zhihu.com/p/24146167>[浅论Lock与X86 Cache一致性]</a></p><p><a href="https://blog.csdn.net/reliveIT/article/details/105902477?spm=1001.2014.3001.5501">[Why Memory Barriers？中文翻译（上）]</a></p><p><a href=https://blog.csdn.net/b_x_p/article/details/104382767>[Volatile全面解析，实现原理及作用分析]</a></p><p><a href=https://blog.csdn.net/CringKong/article/details/99759216>[编译器重排序]</a></p><p><a href=https://blog.csdn.net/qq_27680317/article/details/78486220>[一篇对伪共享、缓存行填充和CPU缓存讲的很透彻的文章]</a></p><p><a href=https://www.zhihu.com/question/348513270>[为什么volatile注释变量，对其下面的变量也会有影响？]</a></p><p><a href=https://createchance.github.io/post/%E4%B8%80%E6%AC%A1%E6%B7%B1%E5%85%A5%E9%AA%A8%E9%AB%93%E7%9A%84-volatile-%E7%A0%94%E7%A9%B6/>[一次深入的volatile研究]</a></p><p><a href=https://www.zhihu.com/question/296949412>[既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？]</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://balvboy.github.io/tags/volatile/>volatile</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on twitter" href="https://twitter.com/intent/tweet/?text=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile&url=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f&hashtags=volatile"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f&title=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile&summary=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile&source=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f&title=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on whatsapp" href="https://api.whatsapp.com/send?text=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile%20-%20https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Java同步机制(二)-Volatile on telegram" href="https://telegram.me/share/url?text=Java%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6%28%e4%ba%8c%29-Volatile&url=https%3a%2f%2fbalvboy.github.io%2fblog%2fvolatile%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//balvboy.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2021 <a href=https://balvboy.github.io>ZhouYang's Blog</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button>
</a><link rel=stylesheet type=text/css href=/css/table.css><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script><script defer src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})});var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>